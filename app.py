"""
Tokyo Market Risk Dashboard
A Palantir Foundry-inspired risk management dashboard
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import requests
import yfinance as yf
from typing import Dict, List, Tuple
import time


from config import *
from data.market_data import MarketDataProvider
from data.earthquake_data import EarthquakeDataProvider
from analytics.risk_engine import RiskEngine
from analytics.black_scholes import BlackScholesEngine
from analytics.network_analysis import NetworkAnalysisEngine
from analytics.predictive_engine import PredictiveEngine
from ui.components import UIComponents

st.set_page_config(
    page_title="Tokyo Market Risk Dashboard",
    page_icon="üèØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown(f"""
<style>
    .stApp {{
        background-color: {THEME_COLORS['background']};
        color: {THEME_COLORS['text_primary']};
    }}
    
    .main-header {{
        background: linear-gradient(90deg, {THEME_COLORS['primary']}, {THEME_COLORS['secondary']});
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }}
    
    .risk-card {{
        background-color: {THEME_COLORS['surface']};
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid {THEME_COLORS['accent']};
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }}
    
    .risk-card-critical {{
        border-left-color: {THEME_COLORS['warning']};
    }}
    
    .risk-card-high {{
        border-left-color: #FF6B35;
    }}
    
    .risk-card-medium {{
        border-left-color: #F7931E;
    }}
    
    .risk-card-low {{
        border-left-color: {THEME_COLORS['success']};
    }}
    
    .metric-container {{
        background-color: {THEME_COLORS['surface']};
        padding: 1rem;
        border-radius: 8px;
        text-align: center;
        margin: 0.5rem;
    }}
    
    .sidebar .sidebar-content {{
        background-color: {THEME_COLORS['surface']};
    }}
    
    .stSelectbox > div > div {{
        background-color: {THEME_COLORS['surface']};
    }}
    
    h1, h2, h3 {{
        color: {THEME_COLORS['text_primary']};
    }}
    
    .decision-item {{
        background-color: {THEME_COLORS['surface']};
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 8px;
        border-left: 3px solid {THEME_COLORS['info']};
    }}
    
    .alert-banner {{
        background-color: {THEME_COLORS['warning']};
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
        text-align: center;
        font-weight: bold;
    }}
</style>
""", unsafe_allow_html=True)

class TokyoMarketDashboard:
    def __init__(self):
        self.market_data = MarketDataProvider()
        self.earthquake_data = EarthquakeDataProvider()
        self.risk_engine = RiskEngine()
        self.bs_engine = BlackScholesEngine()
        self.network_engine = NetworkAnalysisEngine()
        self.predictive_engine = PredictiveEngine()
        self.ui = UIComponents()
        
        if 'language' not in st.session_state:
            st.session_state.language = 'en'
        if 'auto_refresh' not in st.session_state:
            st.session_state.auto_refresh = True
        if 'last_update' not in st.session_state:
            st.session_state.last_update = datetime.now()
        
        if 'shared_earthquake_data' not in st.session_state:
            st.session_state.shared_earthquake_data = None
        if 'shared_earthquake_risk' not in st.session_state:
            st.session_state.shared_earthquake_risk = None
    
    def get_shared_earthquake_data(self):
        current_minute = datetime.now().strftime('%Y%m%d_%H%M')
        
        if ('earthquake_cache_minute' not in st.session_state or 
            st.session_state.earthquake_cache_minute != current_minute or
            st.session_state.shared_earthquake_data is None):
            
            try:
                earthquake_data = self.earthquake_data.fetch_recent_earthquakes(limit=20)
                earthquake_risk = self.earthquake_data.assess_tokyo_risk(earthquake_data)
                
                st.session_state.shared_earthquake_data = earthquake_data
                st.session_state.shared_earthquake_risk = earthquake_risk
                st.session_state.earthquake_cache_minute = current_minute
                
            except Exception as e:
                if st.session_state.shared_earthquake_data is None:
                    st.session_state.shared_earthquake_data = []
                    st.session_state.shared_earthquake_risk = {
                        'risk_level': 'LOW', 
                        'max_magnitude': 0, 
                        'closest_distance': float('inf'), 
                        'all_events': [],
                        'tokyo_region_events': []
                    }
        
        return st.session_state.shared_earthquake_data, st.session_state.shared_earthquake_risk

    def render_header(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        st.markdown(f"""
        <div class="main-header">
            <h1>üèØ {translations['title']}</h1>
            <p style="font-size: 1.2rem; margin: 0;">{translations['subtitle']}</p>
            <p style="font-size: 0.9rem; margin: 0.5rem 0 0 0;">
                Last Updated: {st.session_state.last_update.strftime('%Y-%m-%d %H:%M:%S JST')}
            </p>
        </div>
        """, unsafe_allow_html=True)

    def render_sidebar(self):   
        with st.sidebar:
            st.markdown("### üéõÔ∏è Control Panel")
            
            lang_options = {"English": "en", "Êó•Êú¨Ë™û": "jp"}
            selected_lang = st.selectbox(
                "Language / Ë®ÄË™û",
                options=list(lang_options.keys()),
                index=0 if st.session_state.language == 'en' else 1
            )
            st.session_state.language = lang_options[selected_lang]
            
            lang = st.session_state.language
            
            st.markdown("---")
            
            st.session_state.auto_refresh = st.checkbox(
                "Auto Refresh", 
                value=st.session_state.auto_refresh
            )
            
            if st.button("üîÑ Refresh Data"):
                st.cache_data.clear()  
                st.session_state.shared_earthquake_data = None
                st.session_state.shared_earthquake_risk = None
                if 'earthquake_cache_minute' in st.session_state:
                    del st.session_state.earthquake_cache_minute
                st.session_state.last_update = datetime.now()
                st.rerun()
            
            st.markdown("---")
            
            st.markdown("### üìä Market Focus")
            
            if 'selected_markets' not in st.session_state:
                st.session_state.selected_markets = ["nikkei", "topix", "jpy_usd", "mitsubishi"]
            selected_tickers = st.multiselect(
                "Select Markets (Max 4)",
                options=list(TOKYO_TICKERS.keys()),
                default=st.session_state.selected_markets,
                max_selections=4,
                help="Choose up to 4 markets to focus on in your analysis"
            )
            
            st.session_state.selected_markets = selected_tickers
            
            if not selected_tickers:
                st.warning("Please select at least one market to analyze." if lang == 'en' else "ÂàÜÊûê„Åô„ÇãÂ∏ÇÂ†¥„Çí„Çµ„Ç§„Éâ„Éê„Éº„ÅßÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
            
            st.caption(f"Selected: {len(selected_tickers)}/4 markets")
            
            st.markdown("---")
            
            st.markdown("### ‚ö†Ô∏è Risk Thresholds")
            earthquake_threshold = st.slider(
                "Earthquake Alert (Magnitude)",
                min_value=3.0,
                max_value=9.0,
                value=5.5,
                step=0.1
            )
            
            volatility_threshold = st.slider(
                "Volatility Alert (%)",
                min_value=10,
                max_value=100,
                value=25,
                step=5
            )

    def render_alerts(self):
        current_time = datetime.now()
        if current_time.minute % 10 < 2:  
            st.markdown("""
            <div class="alert-banner">
                üö® RISK ALERT: Elevated seismic activity detected in Tokyo Bay region. 
                Monitoring market correlation patterns.
            </div>
            """, unsafe_allow_html=True)

    def render_overview_metrics(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        try:
            earthquake_data, earthquake_risk = self.get_shared_earthquake_data()
            
            market_summary = {}
            try:
                market_summary = self.market_data.get_tokyo_market_summary()
            except Exception as e:
                st.warning("Market data temporarily unavailable, using cached data.")
            
            correlation_matrix = pd.DataFrame()
            
            risk_assessment = self.risk_engine.assess_integrated_risk(
                earthquake_risk, market_summary, correlation_matrix
            )
        except Exception as e:
            earthquake_data = []
            earthquake_risk = {'risk_level': 'LOW', 'max_magnitude': 0, 'closest_distance': float('inf'), 'all_events': []}
            risk_assessment = {
                'market_risk': {'level': 'LOW'},
                'correlation_risk': {'level': 'LOW', 'raw_metrics': {'mean_abs_correlation': 0.3}},
                'recommendations': []
            }
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            risk_level = earthquake_risk.get('risk_level', 'LOW')
            risk_colors = {'LOW': '#2D6A4F', 'MEDIUM': '#F7931E', 'HIGH': '#FF6B35', 'CRITICAL': '#E63946'}
            
            all_events = earthquake_risk.get('all_events', [])
            if all_events:
                display_magnitude = max([eq.get('magnitude', 0) for eq in all_events])
            else:
                display_magnitude = 0
            
            tokyo_events = earthquake_risk.get('tokyo_region_events', [])
            if tokyo_events:
                display_distance = min([eq.get('distance_from_tokyo', float('inf')) for eq in tokyo_events])
            else:
                display_distance = float('inf')
            
            if display_distance == float('inf'):
                distance_text = ">1000km"
            else:
                distance_text = f"{display_distance:.0f}km"
            
            st.markdown(f"""
            <div class="metric-container">
                <h3>üåç {translations['earthquake_risk']}</h3>
                <h2 style="color: {risk_colors.get(risk_level, '#778DA9')};">{translations.get(f'risk_{risk_level.lower()}', risk_level)}</h2>
                <p>M{display_magnitude:.1f} - {distance_text}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            market_risk_level = risk_assessment['market_risk']['level']
            nikkei_vol = self.market_data.calculate_volatility(TOKYO_TICKERS['nikkei']) * 100
            st.markdown(f"""
            <div class="metric-container">
                <h3>üìà {translations['market_volatility']}</h3>
                <h2 style="color: {risk_colors.get(market_risk_level, '#778DA9')};">{translations.get(f'risk_{market_risk_level.lower()}', market_risk_level)}</h2>
                <p>Nikkei: {nikkei_vol:.1f}% (30d)</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            corr_risk_level = risk_assessment['correlation_risk']['level']
            mean_corr = risk_assessment['correlation_risk'].get('raw_metrics', {}).get('mean_abs_correlation', 0.42)
            st.markdown(f"""
            <div class="metric-container">
                <h3>üîó {translations['correlation_analysis']}</h3>
                <h2 style="color: {risk_colors.get(corr_risk_level, '#778DA9')};">{translations.get(f'risk_{corr_risk_level.lower()}', corr_risk_level)}</h2>
                <p>Avg: {mean_corr:.2f}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            decision_count = len(risk_assessment.get('recommendations', []))
            high_priority = len([r for r in risk_assessment.get('recommendations', []) if r.get('priority') == 'HIGH'])
            st.markdown(f"""
            <div class="metric-container">
                <h3>‚ö° {translations['decision_queue']}</h3>
                <h2 style="color: #E63946;">{high_priority}</h2>
                <p>{decision_count} Total Items</p>
            </div>
            """, unsafe_allow_html=True)

    def render_main_tabs(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        if lang == 'jp':
            tab_labels = [
                "üéØ „É™„Çπ„ÇØÊ¶ÇË¶Å", 
                "üìä Â∏ÇÂ†¥ÂàÜÊûê", 
                "üåç Âú∞ÈúáÁõ£Ë¶ñ", 
                "‚öôÔ∏è „Ç™„Éó„Ç∑„Éß„É≥ÂàÜÊûê", 
                "üé™ ÊÑèÊÄùÊ±∫ÂÆöÊîØÊè¥",
                "üï∏Ô∏è „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂàÜÊûê",
                "üîÆ ‰∫àÊ∏¨ÂàÜÊûê"
            ]
        else:
            tab_labels = [
                "üéØ Risk Overview", 
                "üìä Market Analysis", 
                "üåç Earthquake Monitor", 
                "‚öôÔ∏è Options Analytics", 
                "üé™ Decision Support",
                "üï∏Ô∏è Network Analysis",
                "üîÆ Predictive Analytics"
            ]
        
        tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(tab_labels)
        
        with tab1:
            self.render_risk_overview_tab()
        
        with tab2:
            self.render_market_analysis_tab()
        
        with tab3:
            self.render_earthquake_tab()
        
        with tab4:
            self.render_options_tab()
        
        with tab5:
            self.render_decision_tab()
            
        with tab6:
            self.render_network_analysis_tab()
        
        with tab7:
            earthquake_data, earthquake_risk = self.get_shared_earthquake_data()
            market_data = self.market_data.get_tokyo_market_summary()
            risk_assessment = self.risk_engine.assess_integrated_risk(
                earthquake_risk, market_data, pd.DataFrame()
            )
            lang = st.session_state.language
            self.render_predictive_tab(market_data, earthquake_data, risk_assessment, lang)

    def render_risk_overview_tab(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "üéØ Áµ±Âêà„É™„Çπ„ÇØË©ï‰æ°" if lang == 'jp' else "üéØ Integrated Risk Assessment"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("üìñ „Åì„ÅÆ„Çø„Éñ„Å´„Å§„ÅÑ„Å¶"):
                st.markdown("""
                **Áµ±Âêà„É™„Çπ„ÇØË©ï‰æ°„Çø„Éñ„Åß„ÅØ‰ª•‰∏ã„ÅÆÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„Åæ„ÅôÔºö**
                
                üîç **Á∑èÂêà„É™„Çπ„ÇØÂàÜÊûê**
                - **Âú∞Èúá„É™„Çπ„ÇØ**: ÊúÄËøë7Êó•Èñì„ÅÆÂú∞ÈúáÊ¥ªÂãïÔºà„Éû„Ç∞„Éã„ÉÅ„É•„Éº„Éâ„ÄÅË∑ùÈõ¢„ÄÅÈ†ªÂ∫¶Ôºâ„ÇíÂàÜÊûê
                - **Â∏ÇÂ†¥„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£**: ÂêÑÂ∏ÇÂ†¥„ÅÆ30Êó•Èñì„ÅÆ‰æ°Ê†ºÂ§âÂãïÂπÖ„ÇíË®àÁÆóÔºàÈ´ò„ÅÑ„Åª„Å©„É™„Çπ„ÇØÂ§ßÔºâ
                - **Áõ∏Èñ¢„É™„Çπ„ÇØ**: Â∏ÇÂ†¥Èñì„ÅÆÈÄ£ÂãïÊÄß„ÇíÊ∏¨ÂÆöÔºàÂêåÊôÇ„Å´Âãï„ÅèÂÇæÂêë„ÅåÈ´ò„ÅÑ„Å®„Ç∑„Çπ„ÉÜ„Éü„ÉÉ„ÇØ„É™„Çπ„ÇØÂ¢óÂ§ßÔºâ
                - **ÊúÄÁµÇ„Çπ„Ç≥„Ç¢**: 3„Å§„ÅÆ„É™„Çπ„ÇØ„ÇíÈáç„Åø‰ªò„Åë„Åó„Å¶Áµ±ÂêàÔºàÂú∞Èúá40%„ÄÅÂ∏ÇÂ†¥35%„ÄÅÁõ∏Èñ¢25%Ôºâ
                
                üìä **Â∏ÇÂ†¥Áõ∏Èñ¢„Éû„Éà„É™„ÉÉ„ÇØ„Çπ - Ë™≠„ÅøÊñπ**
                - **Êï∞ÂÄ§„ÅÆÊÑèÂë≥**: -1.0ÔΩû+1.0„ÅÆÁØÑÂõ≤„ÅßÂ∏ÇÂ†¥Èñì„ÅÆÈÄ£ÂãïÊÄß„ÇíË°®Á§∫
                  - **+1.0**: ÂÆåÂÖ®„Å´Âêå„ÅòÊñπÂêë„Å´Âãï„ÅèÔºà‰∏ÄÊñπ„Åå‰∏ä„Åå„Çã„Å®‰ªñÊñπ„ÇÇÂøÖ„Åö‰∏ä„Åå„ÇãÔºâ
                  - **0.0**: ÂÖ®„ÅèÈñ¢‰øÇ„Å™„ÅèÂãï„ÅèÔºàÁã¨Á´ãÔºâ
                  - **-1.0**: ÂÆåÂÖ®„Å´ÈÄÜÊñπÂêë„Å´Âãï„ÅèÔºà‰∏ÄÊñπ„Åå‰∏ä„Åå„Çã„Å®‰ªñÊñπ„ÅØÂøÖ„Åö‰∏ã„Åå„ÇãÔºâ
                - **Ëâ≤„ÅÆÊÑèÂë≥**: 
                  - **Ëµ§Ëâ≤**: Âº∑„ÅÑÊ≠£„ÅÆÁõ∏Èñ¢Ôºà0.7‰ª•‰∏äÔºâ- ÂêåÊôÇ„Å´Êö¥ËêΩ„Åô„Çã„É™„Çπ„ÇØ
                  - **ÈùíËâ≤**: Âº∑„ÅÑË≤†„ÅÆÁõ∏Èñ¢Ôºà-0.7‰ª•‰∏ãÔºâ- ÂàÜÊï£ÂäπÊûú„ÅÇ„Çä
                  - **ÁôΩËâ≤**: ‰ΩéÁõ∏Èñ¢Ôºà-0.3ÔΩû+0.3Ôºâ- Áã¨Á´ãÊÄß„ÅåÈ´ò„ÅÑ
                - **ÂÆü‰æã**: Êó•Áµå„Å®TOPIX„Åå0.9„ÅÆÂ†¥Âêà„ÄÅÊó•Áµå„Åå1%‰∏ãËêΩ„Åô„Çã„Å® TOPIX„ÇÇÁ¥Ñ0.9%‰∏ãËêΩ„Åô„ÇãÂÇæÂêë
                
                üìà **„É™„Çπ„ÇØ„Ç´„Éº„ÉâË©≥Á¥∞**
                - **Âú∞Èúá„É™„Çπ„ÇØ**: Êù±‰∫¨„Åã„Çâ100km‰ª•ÂÜÖ„ÅÆM5.0‰ª•‰∏ä„Åß„Äå‰∏≠„Äç„ÄÅM7.0‰ª•‰∏ä„Åß„ÄåÈ´ò„Äç
                - **Â∏ÇÂ†¥„É™„Çπ„ÇØ**: 30Êó•„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£„Åå25%Ë∂Ö„Åß„Äå‰∏≠„Äç„ÄÅ40%Ë∂Ö„Åß„ÄåÈ´ò„Äç
                - **Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥**: ÂÖ∑‰ΩìÁöÑ„Å™ÊäïË≥áÊà¶Áï•Ôºà„Éù„Ç∏„Ç∑„Éß„É≥Á∏ÆÂ∞è„ÄÅ„Éò„ÉÉ„Ç∏ËøΩÂä†Á≠âÔºâ
                
                üìã **Ë©≥Á¥∞„É¨„Éù„Éº„ÉàÂÜÖÂÆπ**
                - **VaRË®àÁÆó**: 95%‰ø°È†ºÂå∫Èñì„Åß„ÅÆÊúÄÂ§ß‰∫àÊÉ≥ÊêçÂ§±È°ç
                - **„Çπ„Éà„É¨„Çπ„ÉÜ„Çπ„Éà**: Âú∞ÈúáÁô∫ÁîüÊôÇ„ÅÆÂ∏ÇÂ†¥ÂΩ±Èüø„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥
                - **ÊôÇÁ≥ªÂàó‰∫àÊ∏¨**: ‰ªäÂæå7Êó•Èñì„ÅÆ„É™„Çπ„ÇØ„É¨„Éô„É´‰∫àÊ∏¨
                """)
        else:
            with st.expander("üìñ About This Tab"):
                st.markdown("""
                **The Integrated Risk Assessment tab provides:**
                
                üîç **Comprehensive Risk Analysis Explained**
                - **Earthquake Risk**: Analyzes last 7 days of seismic activity (magnitude, distance, frequency)
                - **Market Volatility**: Calculates 30-day price fluctuation range for each market (higher = more risk)
                - **Correlation Risk**: Measures how markets move together (high correlation = systemic risk)
                - **Final Score**: Weighted combination of 3 risks (earthquake 40%, market 35%, correlation 25%)
                
                üìä **Market Correlation Matrix - How to Read**
                - **Number Meaning**: Scale from -1.0 to +1.0 showing how markets move together
                  - **+1.0**: Perfect positive correlation (when one goes up 1%, other goes up 1%)
                  - **0.0**: No relationship (markets move independently)
                  - **-1.0**: Perfect negative correlation (when one goes up 1%, other goes down 1%)
                - **Color Coding**:
                  - **Red**: Strong positive correlation (0.7+) - crash together risk
                  - **Blue**: Strong negative correlation (-0.7+) - diversification benefit
                  - **White**: Low correlation (-0.3 to +0.3) - good independence
                - **Real Example**: If Nikkei-TOPIX shows 0.9, when Nikkei drops 1%, TOPIX typically drops ~0.9%
                
                üìà **Risk Cards Detailed**
                - **Earthquake Risk**: "Medium" for M5.0+ within 100km of Tokyo, "High" for M7.0+
                - **Market Risk**: "Medium" for 30-day volatility >25%, "High" for >40%
                - **Recommendations**: Specific investment actions (reduce positions, add hedges, etc.)
                
                üìã **Detailed Report Contents**
                - **VaR Calculations**: Maximum expected loss at 95% confidence level
                - **Stress Testing**: Market impact simulations during earthquake scenarios
                - **Time Series Forecasting**: 7-day ahead risk level predictions
                """)
        
        try:
            earthquake_data, earthquake_risk = self.get_shared_earthquake_data()
            market_summary = self.market_data.get_tokyo_market_summary()
            
            correlation_matrix = pd.DataFrame(np.random.rand(3, 3), 
                                            columns=['Nikkei', 'TOPIX', 'JPY'],
                                            index=['Nikkei', 'TOPIX', 'JPY'])
            
            risk_assessment = self.risk_engine.assess_integrated_risk(
                earthquake_risk, market_summary, correlation_matrix
            )
        except Exception as e:
            earthquake_risk = {'risk_level': 'LOW', 'max_magnitude': 0, 'recent_activity': 0}
            risk_assessment = {
                'market_risk': {'level': 'LOW'},
                'correlation_risk': {'level': 'LOW'},
                'recommendations': []
            }
        
        if not correlation_matrix.empty:
            fig = px.imshow(
                correlation_matrix,
                labels=dict(x="Markets" if lang == 'en' else "Â∏ÇÂ†¥", 
                           y="Markets" if lang == 'en' else "Â∏ÇÂ†¥", 
                           color="Correlation" if lang == 'en' else "Áõ∏Èñ¢"),
                color_continuous_scale="RdYlBu_r"
            )
            title_text = "Market Correlation Matrix" if lang == 'en' else "Â∏ÇÂ†¥Áõ∏Èñ¢„Éû„Éà„É™„ÉÉ„ÇØ„Çπ"
        else:
            mock_data = np.random.rand(5, 5)
            risk_factors = ["Earthquake", "Typhoon", "Transit", "Political", "Global"] if lang == 'en' else ["Âú∞Èúá", "Âè∞È¢®", "‰∫§ÈÄö", "ÊîøÊ≤ª", "„Ç∞„É≠„Éº„Éê„É´"]
            market_segments = ["Nikkei", "TOPIX", "JPY", "Bonds", "Real Estate"] if lang == 'en' else ["Êó•Áµå", "TOPIX", "ÂÜÜ", "ÂÇµÂà∏", "‰∏çÂãïÁî£"]
            
            fig = px.imshow(
                mock_data,
                labels=dict(x="Risk Factors" if lang == 'en' else "„É™„Çπ„ÇØË¶ÅÂõ†", 
                           y="Market Segments" if lang == 'en' else "Â∏ÇÂ†¥„Çª„Ç∞„É°„É≥„Éà", 
                           color="Correlation" if lang == 'en' else "Áõ∏Èñ¢"),
                x=risk_factors,
                y=market_segments,
                color_continuous_scale="RdYlBu_r"
            )
            title_text = "Risk Factor Correlation Matrix" if lang == 'en' else "„É™„Çπ„ÇØË¶ÅÂõ†Áõ∏Èñ¢„Éû„Éà„É™„ÉÉ„ÇØ„Çπ"
        
        fig.update_layout(
            title=title_text,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color=THEME_COLORS['text_primary']
        )
        st.plotly_chart(fig, use_container_width=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            eq_risk_level = earthquake_risk.get('risk_level', 'LOW')
            eq_css_class = f"risk-card-{eq_risk_level.lower()}"
            if lang == 'jp':
                eq_content = f"""
                <div class="risk-card {eq_css_class}">
                    <h4>üåç Âú∞Èúá„É™„Çπ„ÇØ</h4>
                    <p><strong>„Çπ„ÉÜ„Éº„Çø„Çπ:</strong> {translations.get(f'risk_{eq_risk_level.lower()}', eq_risk_level)}</p>
                    <p><strong>ÊúÄËøë„ÅÆÊ¥ªÂãï:</strong> {earthquake_risk.get('recent_activity', 0)}‰ª∂ (7Êó•Èñì)</p>
                    <p><strong>ÊúÄÂ§ß„Éû„Ç∞„Éã„ÉÅ„É•„Éº„Éâ:</strong> M{earthquake_risk.get('max_magnitude', 0):.1f}</p>
                    <p><strong>Êé®Â•®:</strong> REIT„Çª„ÇØ„Çø„Éº„ÅÆÁõ£Ë¶ñ„ÇíÂº∑Âåñ</p>
                </div>
                """
            else:
                eq_content = f"""
                <div class="risk-card {eq_css_class}">
                    <h4>üåç Earthquake Risk</h4>
                    <p><strong>Status:</strong> {eq_risk_level}</p>
                    <p><strong>Recent Activity:</strong> {earthquake_risk.get('recent_activity', 0)} events (7d)</p>
                    <p><strong>Max Magnitude:</strong> M{earthquake_risk.get('max_magnitude', 0):.1f}</p>
                    <p><strong>Recommendation:</strong> Enhanced REIT sector monitoring</p>
                </div>
                """
            st.markdown(eq_content, unsafe_allow_html=True)
        
        with col2:
            market_risk_level = risk_assessment['market_risk']['level']
            market_css_class = f"risk-card-{market_risk_level.lower()}"
            if lang == 'jp':
                market_content = f"""
                <div class="risk-card {market_css_class}">
                    <h4>üìä Â∏ÇÂ†¥„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£</h4>
                    <p><strong>„Çπ„ÉÜ„Éº„Çø„Çπ:</strong> {translations.get(f'risk_{market_risk_level.lower()}', market_risk_level)}</p>
                    <p><strong>ÂàÜÊûêÂ∏ÇÂ†¥Êï∞:</strong> {risk_assessment['market_risk'].get('processed_markets', 0)}</p>
                    <p><strong>„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£Ë¶ÅÂõ†:</strong> {risk_assessment['market_risk']['factors']['volatility']:.3f}</p>
                    <p><strong>Êé®Â•®:</strong> „Éù„Ç∏„Ç∑„Éß„É≥„Çµ„Ç§„Ç∫„ÅÆË™øÊï¥</p>
                </div>
                """
            else:
                market_content = f"""
                <div class="risk-card {market_css_class}">
                    <h4>üìä Market Volatility</h4>
                    <p><strong>Status:</strong> {market_risk_level}</p>
                    <p><strong>Markets Analyzed:</strong> {risk_assessment['market_risk'].get('processed_markets', 0)}</p>
                    <p><strong>Volatility Factor:</strong> {risk_assessment['market_risk']['factors']['volatility']:.3f}</p>
                    <p><strong>Recommendation:</strong> Adjust position sizing</p>
                </div>
                """
            st.markdown(market_content, unsafe_allow_html=True)
        
        st.markdown("---")
        summary_title = "Á∑èÂêà„É™„Çπ„ÇØ„Çµ„Éû„É™„Éº" if lang == 'jp' else "Overall Risk Summary"
        st.markdown(f"### {summary_title}")
        
        combined_risk = risk_assessment['combined_risk']
        risk_report = self.risk_engine.generate_risk_report(risk_assessment)
        
        if lang == 'jp':
            with st.expander("Ë©≥Á¥∞„É™„Çπ„ÇØ„É¨„Éù„Éº„Éà„ÇíË°®Á§∫"):
                st.text(risk_report)
        else:
            with st.expander("View Detailed Risk Report"):
                st.text(risk_report)

    def render_market_analysis_tab(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "üìä Êù±‰∫¨Â∏ÇÂ†¥ÂàÜÊûê" if lang == 'jp' else "üìä Tokyo Market Analysis"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("üìñ „Åì„ÅÆ„Çø„Éñ„Å´„Å§„ÅÑ„Å¶"):
                st.markdown("""
                **Â∏ÇÂ†¥ÂàÜÊûê„Çø„Éñ„Åß„ÅØ‰ª•‰∏ã„ÅÆÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„Åæ„ÅôÔºö**
                
                üíπ **„É™„Ç¢„É´„Çø„Ç§„É†Â∏ÇÂ†¥„Éá„Éº„Çø„ÅÆË©≥Á¥∞**
                - **ÁèæÂú®‰æ°Ê†º**: ÊúÄÊñ∞„ÅÆÂèñÂºï‰æ°Ê†ºÔºàÈÅÖÂª∂Á¥Ñ15ÂàÜÔºâ
                - **Â§âÂãïÁéá**: ÂâçÊó•ÁµÇÂÄ§„Åã„Çâ„ÅÆÂ§âÂåñÁéáÔºà‰æãÔºö+2.5%„ÅØÂâçÊó•ÊØî2.5%‰∏äÊòáÔºâ
                - **„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£**: 30Êó•Èñì„ÅÆÊó•Ê¨°Â§âÂãïÁéá„ÅÆÊ®ôÊ∫ñÂÅèÂ∑Æ√ó‚àö252„ÅßÂπ¥ÁéáÊèõÁÆó
                  - **15%Êú™Ê∫Ä**: ‰Ωé„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ÔºàÂÆâÂÆöÔºâ
                  - **15-25%**: ÈÄöÂ∏∏„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£
                  - **25%Ë∂Ö**: È´ò„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£Ôºà„É™„Çπ„ÇØÂ§ßÔºâ
                - **„Éá„Éº„ÇøÊõ¥Êñ∞**: 5ÂàÜÈñìÈöî„ÅßËá™ÂãïÊõ¥Êñ∞„ÄÅAPIÈöúÂÆ≥ÊôÇ„ÅØÊ®°Êì¨„Éá„Éº„ÇøË°®Á§∫
                
                üìà **‰æ°Ê†º„Éà„É¨„É≥„Éâ„ÉÅ„É£„Éº„Éà**
                - 30Êó•Èñì„ÅÆ‰æ°Ê†ºÊé®Áßª„ÇíË¶ñË¶öÂåñ
                - „Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ„Å™„ÉÅ„É£„Éº„ÉàÈÅ∏ÊäûÊ©üËÉΩ
                
                üìä **„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ÂàÜÊûê**
                - ÂêÑÂ∏ÇÂ†¥„ÅÆ30Êó•„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ÊØîËºÉ
                - „É™„Çπ„ÇØË©ï‰æ°„ÅÆ„Åü„ÇÅ„ÅÆÁµ±Ë®àÂàÜÊûê
                
                üîÑ **Â∏ÇÂ†¥„Çπ„ÉÜ„Éº„Çø„Çπ**
                - Êù±‰∫¨Ë®ºÂà∏ÂèñÂºïÊâÄ„ÅÆÈñãÂ†¥Áä∂Ê≥Å
                - VIXÁõ∏ÂΩìÊåáÊï∞„Å®„Éï„Ç£„Ç¢„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
                
                **‰ΩøÁî®ÊñπÊ≥ïÔºö** „Çµ„Ç§„Éâ„Éê„Éº„ÅßÊúÄÂ§ß4„Å§„ÅÆÂ∏ÇÂ†¥„ÇíÈÅ∏Êäû„Åó„Å¶ÂàÜÊûê„Åß„Åç„Åæ„Åô„ÄÇ
                """)
        else:
            with st.expander("üìñ About This Tab"):
                st.markdown("""
                **The Market Analysis tab provides:**
                
                üíπ **Real-time Market Data**
                - Current prices, changes, and volatility for selected markets
                - Auto-refresh and error handling capabilities
                
                üìà **Price Trend Charts**
                - 30-day price movement visualization
                - Interactive chart selection functionality
                
                üìä **Volatility Analysis**
                - 30-day volatility comparison across markets
                - Statistical analysis for risk assessment
                
                üîÑ **Market Status**
                - Tokyo Stock Exchange trading hours status
                - VIX equivalent and fear index metrics
                
                **How to use:** Select up to 4 markets in the sidebar for analysis.
                """)
        
        selected_markets = st.session_state.get('selected_markets', ['nikkei', 'topix', 'jpy_usd', 'mitsubishi'])
        
        if not selected_markets:
            st.warning("Please select markets in the sidebar to analyze." if lang == 'en' else "ÂàÜÊûê„Åô„ÇãÂ∏ÇÂ†¥„Çí„Çµ„Ç§„Éâ„Éê„Éº„ÅßÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
            return
        
        with st.spinner("Loading market data..." if lang == 'en' else "Â∏ÇÂ†¥„Éá„Éº„ÇøË™≠„ÅøËæº„Åø‰∏≠..."):
            try:
                market_summary = self.market_data.get_tokyo_market_summary()
                
                for market_key in selected_markets:
                    if market_key not in market_summary or not market_summary[market_key]:
                        ticker = TOKYO_TICKERS.get(market_key)
                        if ticker:
                            individual_data = self.market_data.get_real_time_data(ticker)
                            if individual_data:
                                individual_data['volatility'] = self.market_data.calculate_volatility(ticker)
                                market_summary[market_key] = individual_data
                
            except Exception as e:
                st.error(f"Unable to load market data: {str(e)}")
                return
        
        st.markdown("#### üìà Market Overview" if lang == 'en' else "#### üìà Â∏ÇÂ†¥Ê¶ÇË¶Å")
        
        num_markets = len(selected_markets)
        if num_markets <= 2:
            cols = st.columns(num_markets)
        elif num_markets <= 4:
            cols = st.columns(2)
        else:
            cols = st.columns(3)
        
        market_display_names = {
            "nikkei": "Nikkei 225",
            "topix": "TOPIX",
            "jpy_usd": "JPY/USD",
            "jpy_eur": "EUR/JPY",
            "sony": "Sony ADR",
            "toyota": "Toyota ADR",
            "softbank": "SoftBank",
            "nintendo": "Nintendo ADR",
            "mitsubishi": "Mitsubishi"
        }

        for i, market_key in enumerate(selected_markets):
            col_index = i % len(cols)
            with cols[col_index]:
                market_data = market_summary.get(market_key, {})
                
                if not market_data or market_data.get('current_price', 0) == 0:
                    ticker = TOKYO_TICKERS.get(market_key)
                    if ticker:
                        fresh_data = self.market_data.get_real_time_data(ticker)
                        if fresh_data:
                            fresh_data['volatility'] = self.market_data.calculate_volatility(ticker)
                            market_data = fresh_data
                
                price = market_data.get('current_price', 0)
                change_pct = market_data.get('change_percent', 0)
                volatility = market_data.get('volatility', 0.25) * 100
                
                if 'jpy' in market_key.lower() or 'usd' in market_key.lower() or 'eur' in market_key.lower():
                    formatted_price = f"{price:.3f}" if price > 0 else "Loading..."
                elif price >= 1000:
                    formatted_price = f"{price:,.0f}"
                else:
                    formatted_price = f"{price:.2f}" if price > 0 else "Loading..."
                
                change_color = "üü¢" if change_pct > 0 else "üî¥" if change_pct < 0 else "‚ö™"
                delta_str = f"{change_pct:+.2f}%" if change_pct != 0 else "0.00%"
                
                display_name = market_display_names.get(market_key, market_key.upper())
                
                card_html = f"""
                <div class="metric-container" style="margin-bottom: 1rem;">
                    <h4 style="margin: 0; color: {THEME_COLORS['text_primary']};">{display_name}</h4>
                    <h2 style="margin: 0.5rem 0; color: {THEME_COLORS['accent']};">{formatted_price}</h2>
                    <p style="margin: 0; font-size: 0.9rem;">{change_color} {delta_str}</p>
                    <p style="margin: 0; font-size: 0.8rem; color: {THEME_COLORS['text_secondary']};">Vol: {volatility:.1f}%</p>
                </div>
                """
                st.markdown(card_html, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("#### üìä Price Trends" if lang == 'en' else "#### üìä ‰æ°Ê†º„Éà„É¨„É≥„Éâ")
        
        if selected_markets:
            chart_market = st.selectbox(
                "Select market for chart:" if lang == 'en' else "„ÉÅ„É£„Éº„ÉàË°®Á§∫Â∏ÇÂ†¥:",
                options=selected_markets,
                format_func=lambda x: market_display_names.get(x, x.upper()),
                index=0
            )
            
            ticker_symbol = TOKYO_TICKERS.get(chart_market)
            if ticker_symbol:
                hist_data = self.market_data.get_historical_data(ticker_symbol, period="1mo")
                
                if not hist_data.empty:
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=hist_data.index, 
                        y=hist_data['Close'],
                        mode='lines',
                        name=market_display_names.get(chart_market, chart_market.upper()),
                        line=dict(color=THEME_COLORS['accent'], width=2)
                    ))
                    
                    display_name = market_display_names.get(chart_market, chart_market.upper())
                    fig.update_layout(
                        title=f"{display_name} - 30 Day Trend",
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)',
                        font_color=THEME_COLORS['text_primary'],
                        xaxis=dict(gridcolor=THEME_COLORS['secondary']),
                        yaxis=dict(gridcolor=THEME_COLORS['secondary']),
                        height=400
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        st.markdown("#### üìà Volatility Analysis" if lang == 'en' else "#### üìà „Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ÂàÜÊûê")
        
        vol_data = []
        for market_key in selected_markets:
            if market_key in market_summary and market_summary[market_key]:
                vol = market_summary[market_key].get('volatility', 0.25) * 100
                vol_data.append({
                    'Market': market_display_names.get(market_key, market_key.upper()),
                    'Volatility': vol
                })
        
        if vol_data:
            vol_df = pd.DataFrame(vol_data)
            fig = px.bar(
                vol_df, 
                x='Market', 
                y='Volatility',
                title="30-Day Volatility Comparison",
                color='Volatility',
                color_continuous_scale='Reds'
            )
            fig.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color=THEME_COLORS['text_primary'],
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        col1, col2 = st.columns(2)
        
        with col1:
            market_open = self.market_data.is_market_open()
            status_text = "Market Open" if market_open else "Market Closed"
            status_color = "üü¢" if market_open else "üî¥"
            st.metric("Market Status", f"{status_color} {status_text}")
        
        with col2:
            vix_equiv = self.market_data.get_vix_equivalent()   
            market_summary = self.market_data.get_tokyo_market_summary()
            has_live_data = any(data.get('is_live', False) for data in market_summary.values())
            status_indicator = "üü¢ Live" if has_live_data else "üü° Cached"
            st.metric("Fear Index (VIX Equiv.)", f"{vix_equiv:.1f}", help=f"Data Status: {status_indicator}")

    def render_earthquake_tab(self):
        """Render the earthquake monitoring tab"""
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "üåç Âú∞Èúá„É™„Çπ„ÇØÁõ£Ë¶ñ" if lang == 'jp' else "üåç Earthquake Risk Monitor"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("üìñ „Åì„ÅÆ„Çø„Éñ„Å´„Å§„ÅÑ„Å¶"):
                st.markdown("""
                **Âú∞ÈúáÁõ£Ë¶ñ„Çø„Éñ„Åß„ÅØ‰ª•‰∏ã„ÅÆÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„Åæ„ÅôÔºö**
                
                üåã **„É™„Ç¢„É´„Çø„Ç§„É†Âú∞Èúá„Éá„Éº„Çø„ÅÆË©≥Á¥∞**
                - **„Éá„Éº„Çø„ÇΩ„Éº„Çπ**: P2PQuake APIÔºàÊ∞óË±°Â∫ÅÁô∫Ë°®„Éá„Éº„Çø„ÇíÂü∫„Å´Êõ¥Êñ∞Ôºâ
                - **Êõ¥Êñ∞È†ªÂ∫¶**: Êñ∞„Åó„ÅÑÂú∞ÈúáÁô∫ÁîüÊôÇ„Å´Âç≥Â∫ß„Å´ÂèçÊò†ÔºàÈÄöÂ∏∏Êï∞ÂàÜ‰ª•ÂÜÖÔºâ
                - **Ë°®Á§∫È†ÖÁõÆ**:
                  - **Áô∫ÁîüÊôÇÂàª**: JSTÔºàÊó•Êú¨Ê®ôÊ∫ñÊôÇÔºâ„ÅßË°®Á§∫
                  - **„Éû„Ç∞„Éã„ÉÅ„É•„Éº„Éâ**: M3.0‰ª•‰∏ä„ÅÆÂú∞Èúá„ÇíË°®Á§∫ÔºàM5.0‰ª•‰∏ä„ÅØÂ§™Â≠óÔºâ
                  - **ÈúáÊ∫êÂú∞**: ÂÖ∑‰ΩìÁöÑ„Å™Âú∞ÂüüÂêçÔºà‰æãÔºöÂçÉËëâÁúåÊù±ÊñπÊ≤ñÔºâ
                  - **ÈúáÊ∫êÊ∑±„Åï**: kmÂçò‰ΩçÔºàÊµÖ„ÅÑ„Åª„Å©Âú∞Ë°®„Å∏„ÅÆÂΩ±ÈüøÂ§ßÔºâ
                  - **Êù±‰∫¨Ë∑ùÈõ¢**: ÁöáÂ±Ö„Åã„Çâ„ÅÆÁõ¥Á∑öË∑ùÈõ¢„ÇíËá™ÂãïË®àÁÆó
                
                ‚ö†Ô∏è **„É™„Çπ„ÇØ„Ç¢„Çª„Çπ„É°„É≥„ÉàË©ï‰æ°Âü∫Ê∫ñ**
                - **LOWÔºà‰ΩéÔºâ**: M5.0Êú™Ê∫Ä„Åæ„Åü„ÅØÊù±‰∫¨„Åã„Çâ150kmË∂Ö
                - **MEDIUMÔºà‰∏≠Ôºâ**: M5.0-6.9„Åã„Å§Êù±‰∫¨„Åã„Çâ50-150km
                - **HIGHÔºàÈ´òÔºâ**: M7.0-7.9„Åã„Å§Êù±‰∫¨„Åã„Çâ100km‰ª•ÂÜÖ
                - **CRITICALÔºàÁ∑äÊÄ•Ôºâ**: M8.0‰ª•‰∏ä„Åæ„Åü„ÅØÊù±‰∫¨„Åã„Çâ30km‰ª•ÂÜÖ
                - **Ë©ï‰æ°ÊúüÈñì**: ÈÅéÂéª7Êó•Èñì„ÅÆÂú∞ÈúáÊ¥ªÂãï„ÇíÈáç„Åø‰ªò„ÅëÂàÜÊûê
                - **Ë∑ùÈõ¢Ê∏õË°∞**: ÈúáÊ∫êË∑ùÈõ¢„Åå2ÂÄç„Å´„Å™„Çã„Å®ÂΩ±Èüø„ÅØ1/4„Å´Ê∏õÂ∞ë
                
                üìä **Â∏ÇÂ†¥Áõ∏Èñ¢ÂàÜÊûê„ÅÆÂÆüÁî®ÁöÑËß£Èáà**
                - **Êó•Áµå225Áõ∏Èñ¢Ôºà-0.15Ôºâ**: Â§ßÂú∞ÈúáÊôÇ„Å´Âπ≥Âùá15%‰∏ãËêΩÂÇæÂêë
                - **REITÁõ∏Èñ¢Ôºà-0.35Ôºâ**: ‰∏çÂãïÁî£ÊäïË≥á‰ø°Ë®ó„ÅØÂú∞Èúá„Å´ÊúÄ„ÇÇÊïèÊÑü
                  - **ÁêÜÁî±**: Áâ©ÁêÜÁöÑË≥áÁî£„Å∏„ÅÆÁõ¥Êé•ÂΩ±ÈüøÊá∏Âøµ
                  - **ÂÆü‰æã**: Êù±Êó•Êú¨Â§ßÈúáÁÅΩÊôÇ„Å´‰∏çÂãïÁî£REIT„ÅØ30%‰ª•‰∏ä‰∏ãËêΩ
                - **ÂÜÜÁõ∏Èñ¢Ôºà+0.08Ôºâ**: Âú∞ÈúáÊôÇ„Å´ÂÜÜ„ÅåËã•Âπ≤Âº∑„Åè„Å™„ÇãÂÇæÂêë
                  - **ÁêÜÁî±**: Âæ©ËààÈúÄË¶Å„Å®Êµ∑Â§ñË≥áÊú¨„ÅÆÊú¨ÂõΩÈÄÅÈÇÑ
                - **‰øùÈô∫Áõ∏Èñ¢Ôºà-0.45Ôºâ**: ‰øùÈô∫‰ºöÁ§æ„ÅØÂú∞Èúá„ÅßÂ§ß„Åç„ÅèÂΩ±Èüø
                  - **ÁêÜÁî±**: Âú∞Èúá‰øùÈô∫„ÅÆÊîØÊâï„ÅÑÁæ©ÂãôÂ¢óÂ§ß
                - **ÂÖ¨Áõä‰∫ãÊ•≠Áõ∏Èñ¢Ôºà-0.25Ôºâ**: „Ç§„É≥„Éï„É©Ë¢´ÂÆ≥„Å´„Çà„ÇãÂñ∂Ê•≠ÂÅúÊ≠¢„É™„Çπ„ÇØ
                
                üìà **ÈÅéÂéª„Éë„Çø„Éº„É≥ÂàÜÊûê„ÅÆÊ¥ªÁî®Ê≥ï**
                - **Áµ±Ë®àÊúüÈñì**: 30Êó•Èñì„ÅÆÂú∞ÈúáÊ¥ªÂãï„ÇíÂàÜÊûê
                - **„Éû„Ç∞„Éã„ÉÅ„É•„Éº„ÉâÂàÜÂ∏É**: 
                  - **M3-4**: Êó•Â∏∏ÁöÑÁô∫ÁîüÔºàÊúà20-30ÂõûÔºâ
                  - **M4-5**: ÈÄ±1-2ÂõûÁ®ãÂ∫¶
                  - **M5-6**: Êúà1-2ÂõûÁ®ãÂ∫¶
                  - **M6Ë∂Ö**: Êï∞„É∂Êúà„Å´1ÂõûÔºàË¶ÅÊ≥®ÊÑè„É¨„Éô„É´Ôºâ
                - **Âú∞ÂüüÂà•È†ªÂ∫¶**: Èñ¢Êù±„ÉªÊù±Êµ∑„ÉªÂçóÊµ∑„Éà„É©„ÉïÂë®Ëæ∫„ÅÆÊ¥ªÂãïÁõ£Ë¶ñ
                - **‰∫àÊ∏¨„Å∏„ÅÆÂøúÁî®**: ÈÅéÂéª„Éë„Çø„Éº„É≥„Åã„Çâ‰ªäÂæå7Êó•Èñì„ÅÆÁô∫ÁîüÁ¢∫Áéá„ÇíÊé®ÂÆö
                
                **ÂÆüË∑µÁöÑ„É™„Çπ„ÇØÁÆ°ÁêÜ**:
                1. **Êó•Ê¨°„ÉÅ„Çß„ÉÉ„ÇØ**: Êúù‰∏ÄÁï™„Åß„É™„Çπ„ÇØ„É¨„Éô„É´Á¢∫Ë™ç
                2. **„Éù„Éº„Éà„Éï„Ç©„É™„Ç™Ë™øÊï¥**: MEDIUM‰ª•‰∏ä„ÅßREIT„Éª‰øùÈô∫Ê†™„ÅÆÊØîÈáçÊ§úË®é
                3. **„Éò„ÉÉ„Ç∏Êà¶Áï•**: HIGH‰ª•‰∏ä„ÅßÊó•Áµå„Éó„ÉÉ„Éà„Ç™„Éó„Ç∑„Éß„É≥Ë≥ºÂÖ•Ê§úË®é
                4. **ÁèæÈáëÊØîÁéá**: CRITICALÊôÇ„ÅØÁèæÈáëÊØîÁéá„Çí30%‰ª•‰∏ä„Å´Âºï„Åç‰∏ä„Åí
                """)
        else:
            with st.expander("üìñ About This Tab"):
                st.markdown("""
                **The Earthquake Monitor tab provides:**
                
                üåã **Real-time Earthquake Data Details**
                - **Data Source**: P2PQuake API (based on Japan Meteorological Agency releases)
                - **Update Frequency**: Immediate reflection when new earthquakes occur (usually within minutes)
                - **Display Items**:
                  - **Occurrence Time**: Displayed in JST (Japan Standard Time)
                  - **Magnitude**: Shows M3.0+ earthquakes (M5.0+ in bold)
                  - **Epicenter**: Specific regional names (e.g., "Off the coast of Chiba Prefecture")
                  - **Depth**: In kilometers (shallower = greater surface impact)
                  - **Tokyo Distance**: Auto-calculated straight-line distance from Imperial Palace
                
                ‚ö†Ô∏è **Risk Assessment Criteria**
                - **LOW**: M<5.0 or >150km from Tokyo
                - **MEDIUM**: M5.0-6.9 and 50-150km from Tokyo
                - **HIGH**: M7.0-7.9 and within 100km of Tokyo
                - **CRITICAL**: M8.0+ or within 30km of Tokyo
                - **Assessment Period**: Weighted analysis of past 7 days of seismic activity
                - **Distance Decay**: Impact reduces by 1/4 when distance doubles
                
                üìä **Market Correlation Analysis Practical Interpretation**
                - **Nikkei 225 Correlation (-0.15)**: Average 15% decline during major earthquakes
                - **REIT Correlation (-0.35)**: Real estate investment trusts most sensitive to earthquakes
                  - **Reason**: Direct impact concerns on physical assets
                  - **Example**: Real estate REITs fell 30%+ during 2011 Tohoku earthquake
                - **JPY Correlation (+0.08)**: Yen tends to strengthen slightly during earthquakes
                  - **Reason**: Reconstruction demand and foreign capital repatriation
                - **Insurance Correlation (-0.45)**: Insurance companies heavily impacted by earthquakes
                  - **Reason**: Increased earthquake insurance payout obligations
                - **Utilities Correlation (-0.25)**: Infrastructure damage causing operational shutdowns
                
                üìà **Historical Pattern Analysis Applications**
                - **Statistical Period**: 30-day earthquake activity analysis
                - **Magnitude Distribution**:
                  - **M3-4**: Daily occurrence (20-30 times/month)
                  - **M4-5**: 1-2 times/week
                  - **M5-6**: 1-2 times/month
                  - **M6+**: Once every few months (attention level)
                - **Regional Frequency**: Monitoring Kanto, Tokai, Nankai Trough area activity
                - **Predictive Application**: Estimate 7-day ahead occurrence probability from historical patterns
                
                **Practical Risk Management**:
                1. **Daily Check**: Verify risk level first thing in the morning
                2. **Portfolio Adjustment**: Consider REIT/insurance stock weights at MEDIUM+ levels
                3. **Hedge Strategy**: Consider Nikkei put options at HIGH+ levels
                4. **Cash Ratio**: Increase cash holdings to 30%+ during CRITICAL periods
                """)

        with st.spinner(translations.get("loading_earthquake_data", "Loading earthquake data...")):
            try:
                earthquake_data, earthquake_risk = self.get_shared_earthquake_data()
            except Exception as e:
                st.error(translations.get("earthquake_data_unavailable", "Unable to fetch earthquake data. Using cached information."))
                earthquake_data = []
                earthquake_risk = {'risk_level': 'LOW', 'recent_activity': 0, 'max_magnitude': 0, 'all_events': []}
        
        if earthquake_data:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                total_events = len(earthquake_data)
                st.metric("Total Recent Events" if lang == 'en' else "ÊúÄËøë„ÅÆ„Ç§„Éô„É≥„ÉàÊï∞", total_events)
            with col2:
                latest_mag = earthquake_data[0].get('magnitude', 0) if earthquake_data else 0
                st.metric("Latest Magnitude" if lang == 'en' else "ÊúÄÊñ∞„Éû„Ç∞„Éã„ÉÅ„É•„Éº„Éâ", f"M{latest_mag:.1f}")
            with col3:
                tokyo_events = len(earthquake_risk.get('tokyo_region_events', []))
                st.metric("Tokyo Region (500km)" if lang == 'en' else "Êù±‰∫¨Âë®Ëæ∫(500km)", tokyo_events)
            with col4:
                data_source = "P2PQuake API" if not earthquake_data[0].get('data_quality') == 'mock' else "Mock Data"
                status_color = "üü¢" if data_source.startswith("P2P") else "üü°"
                st.metric("Data Source" if lang == 'en' else "„Éá„Éº„Çø„ÇΩ„Éº„Çπ", f"{status_color} {data_source}")
            
            st.markdown("---")
        
        if earthquake_data:
            all_events = earthquake_risk.get('all_events', earthquake_data)
            
            display_data = []
            for eq in all_events[:15]:  
                eq_time = eq.get('time', 'N/A')
                if 'T' in eq_time or '/' in eq_time:
                    try:
                        if 'T' in eq_time:
                            dt = datetime.fromisoformat(eq_time.replace('Z', '+00:00'))
                        else:
                            dt = datetime.strptime(eq_time.split('.')[0], "%Y/%m/%d %H:%M:%S")
                        eq_time = dt.strftime("%m/%d %H:%M")
                    except:
                        pass
                
                display_data.append({
                    'Time' if lang == 'en' else 'ÊôÇÂàª': eq_time,
                    'Magnitude' if lang == 'en' else '„Éû„Ç∞„Éã„ÉÅ„É•„Éº„Éâ': f"M{eq.get('magnitude', 0):.1f}",
                    'Intensity' if lang == 'en' else 'ÈúáÂ∫¶': f"{eq.get('intensity', 0):.1f}",
                    'Location' if lang == 'en' else 'Â†¥ÊâÄ': eq.get('location', 'Unknown'),
                    'Depth' if lang == 'en' else 'Ê∑±„Åï': f"{eq.get('depth', 0):.0f}km",
                    'Distance' if lang == 'en' else 'Ë∑ùÈõ¢': f"{eq.get('distance_from_tokyo', 0):.0f}km"
                })
            
            if display_data:
                df = pd.DataFrame(display_data)
                st.dataframe(df, use_container_width=True)
            else:
                st.info("No earthquake data available." if lang == 'en' else "Âú∞Èúá„Éá„Éº„Çø„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ")
        else:
            if lang == 'jp':
                st.info("Âú∞Èúá„Éá„Éº„Çø„ÇíÂèñÂæó‰∏≠...")
            else:
                st.info("Loading earthquake data...")
        
        risk_level = earthquake_risk.get('risk_level', 'LOW')
        risk_css_class = f"risk-card-{risk_level.lower()}"
        
        if lang == 'jp':
            assessment_content = f"""
            <div class="risk-card {risk_css_class}">
                <h4>üéØ ÁèæÂú®„ÅÆË©ï‰æ°</h4>
                <p><strong>„É™„Çπ„ÇØ„É¨„Éô„É´:</strong> {translations.get(f'risk_{risk_level.lower()}', risk_level)}</p>
                <p><strong>ÊúÄËøë„ÅÆÊ¥ªÂãï:</strong> {earthquake_risk.get('recent_activity', 0)}‰ª∂ (7Êó•Èñì)</p>
                <p><strong>ÊúÄÂ§ß„Éû„Ç∞„Éã„ÉÅ„É•„Éº„Éâ:</strong> M{earthquake_risk.get('max_magnitude', 0):.1f}</p>
                <p><strong>ÊúÄËøëË∑ùÈõ¢:</strong> {earthquake_risk.get('closest_distance', 0):.0f}km</p>
                <p><strong>Ë©ï‰æ°:</strong> {earthquake_risk.get('assessment', '„Éá„Éº„ÇøÂèñÂæó‰∏≠')}</p>
            </div>
            """
        else:
            assessment_content = f"""
            <div class="risk-card {risk_css_class}">
                <h4>üéØ Current Assessment</h4>
                <p><strong>Risk Level:</strong> {risk_level}</p>
                <p><strong>Recent Activity:</strong> {earthquake_risk.get('recent_activity', 0)} events (7d)</p>
                <p><strong>Max Magnitude:</strong> M{earthquake_risk.get('max_magnitude', 0):.1f}</p>
                <p><strong>Closest Distance:</strong> {earthquake_risk.get('closest_distance', 0):.0f}km</p>
                <p><strong>Assessment:</strong> {earthquake_risk.get('assessment', 'Loading data...')}</p>
            </div>
            """
        
        st.markdown(assessment_content, unsafe_allow_html=True)
        
        st.markdown("---")
        correlation_title = "Â∏ÇÂ†¥Áõ∏Èñ¢ÂàÜÊûê" if lang == 'jp' else "Market Correlation Analysis"
        st.markdown(f"### {correlation_title}")
        
        correlations = self.earthquake_data.get_market_impact_correlation()
        
        col1, col2 = st.columns(2)
        
        with col1:
            if lang == 'jp':
                st.metric("Êó•Áµå225Áõ∏Èñ¢", f"{correlations['nikkei_correlation']:.3f}")
                st.metric("REITÁõ∏Èñ¢", f"{correlations['reit_correlation']:.3f}")
                st.metric("ÂÜÜÁõ∏Èñ¢", f"{correlations['jpy_correlation']:.3f}")
            else:
                st.metric("Nikkei Correlation", f"{correlations['nikkei_correlation']:.3f}")
                st.metric("REIT Correlation", f"{correlations['reit_correlation']:.3f}")
                st.metric("JPY Correlation", f"{correlations['jpy_correlation']:.3f}")
        
        with col2:
            if lang == 'jp':
                st.metric("ÂÖ¨Áõä‰∫ãÊ•≠Áõ∏Èñ¢", f"{correlations['utilities_correlation']:.3f}")
                st.metric("‰øùÈô∫Ê•≠Áõ∏Èñ¢", f"{correlations['insurance_correlation']:.3f}")
            else:
                st.metric("Utilities Correlation", f"{correlations['utilities_correlation']:.3f}")
                st.metric("Insurance Correlation", f"{correlations['insurance_correlation']:.3f}")
        
        all_events = earthquake_risk.get('all_events', earthquake_data)
        if len(all_events) > 0:
            st.markdown("---")
            map_title = "Âú∞ÈúáÂàÜÂ∏É„Éû„ÉÉ„Éó" if lang == 'jp' else "Earthquake Distribution Map"
            st.markdown(f"### {map_title}")
            
            map_data = []
            for eq in all_events[:20]:  
                if eq.get('latitude', 0) != 0 and eq.get('longitude', 0) != 0:
                    map_data.append({
                        'lat': eq.get('latitude', 0),
                        'lon': eq.get('longitude', 0),
                        'magnitude': eq.get('magnitude', 0),
                        'location': eq.get('location', 'Unknown'),
                        'distance': eq.get('distance_from_tokyo', 0),
                        'size': max(5, eq.get('magnitude', 2) * 3)  
                    })
            
            if map_data:
                import plotly.express as px
                df_map = pd.DataFrame(map_data)
                
                fig = go.Figure()
                
                fig.add_trace(go.Scatter(
                    x=df_map['lon'],
                    y=df_map['lat'],
                    mode='markers',
                    marker=dict(
                        size=df_map['size'],
                        color=df_map['magnitude'],
                        colorscale='Reds',
                        sizemode='diameter',
                        sizeref=2*max(df_map['size'])/(20**2),
                        showscale=True,
                        colorbar=dict(title="Magnitude")
                    ),
                    text=df_map['location'],
                    hovertemplate='<b>%{text}</b><br>Magnitude: %{marker.color:.1f}<br>Distance: %{customdata} km<extra></extra>',
                    customdata=df_map['distance'],
                    name="Earthquakes"
                ))
                
                fig.add_trace(go.Scatter(
                    x=[139.6503],
                    y=[35.6762],
                    mode='markers',
                    marker=dict(size=15, color='blue', symbol='star'),
                    text=['Tokyo'],
                    name='Tokyo' if lang == 'en' else 'Êù±‰∫¨',
                    hovertemplate='<b>Tokyo</b><extra></extra>'
                ))
                
                fig.update_layout(
                    title="Recent Earthquakes" if lang == 'en' else "ÊúÄËøë„ÅÆÂú∞Èúá",
                    xaxis_title="Longitude",
                    yaxis_title="Latitude",
                    showlegend=True
                )
                
                fig.update_layout(
                    height=400,
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    font_color=THEME_COLORS['text_primary']
                )
                st.plotly_chart(fig, use_container_width=True)
        
        if st.button("ÈÅéÂéª„Éë„Çø„Éº„É≥ÂàÜÊûê" if lang == 'jp' else "Analyze Historical Patterns"):
            patterns = self.earthquake_data.get_historical_patterns(days=30)
            if patterns:
                events_text = "events in last 30 days" if lang == 'en' else "ÈÅéÂéª30Êó•Èñì„ÅÆ„Ç§„Éô„É≥„Éà"
                st.markdown(f"**{patterns['total_events']} {events_text}**")
                
                mag_dist = patterns.get('events_by_magnitude', {})
                if mag_dist:
                    st.markdown("Magnitude Distribution:" if lang == 'en' else "„Éû„Ç∞„Éã„ÉÅ„É•„Éº„ÉâÂàÜÂ∏É:")
                    for mag_range, count in mag_dist.items():
                        st.write(f"  {mag_range}: {count} events")
                
                if 'avg_magnitude' in patterns:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Avg Magnitude" if lang == 'en' else "Âπ≥Âùá„Éû„Ç∞„Éã„ÉÅ„É•„Éº„Éâ", f"M{patterns['avg_magnitude']:.1f}")
                    with col2:
                        st.metric("Max Magnitude" if lang == 'en' else "ÊúÄÂ§ß„Éû„Ç∞„Éã„ÉÅ„É•„Éº„Éâ", f"M{patterns['max_magnitude']:.1f}")
                    with col3:
                        st.metric("Avg Distance" if lang == 'en' else "Âπ≥ÂùáË∑ùÈõ¢", f"{patterns['avg_distance']:.0f}km")

    def render_options_tab(self):
        """Render the options analytics tab"""
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "‚öôÔ∏è „Ç™„Éó„Ç∑„Éß„É≥ÂàÜÊûê„Ç®„É≥„Ç∏„É≥" if lang == 'jp' else "‚öôÔ∏è Options Analytics Engine"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("üìñ „Åì„ÅÆ„Çø„Éñ„Å´„Å§„ÅÑ„Å¶"):
                st.markdown("""
                **„Ç™„Éó„Ç∑„Éß„É≥ÂàÜÊûê„Çø„Éñ„Åß„ÅØ‰ª•‰∏ã„ÅÆÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„Åæ„ÅôÔºö**
                
                üßÆ **Black-ScholesË®àÁÆóÊ©ü**
                - „É®„Éº„É≠„Éî„Ç¢„É≥„Ç™„Éó„Ç∑„Éß„É≥‰æ°Ê†º„ÅÆË®àÁÆó
                - „Ç≥„Éº„É´„Éª„Éó„ÉÉ„Éà„Ç™„Éó„Ç∑„Éß„É≥‰æ°Ê†º„Å®„ÇÆ„É™„Ç∑„É£ÊñáÂ≠ó
                - Êó•Êú¨Â∏ÇÂ†¥ÁâπÊúâ„ÅÆÂú∞Èúá„É™„Çπ„ÇØË™øÊï¥
                
                üé≤ **„É¢„É≥„ÉÜ„Ç´„É´„É≠„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥**
                - 10,000Âõû„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„Å´„Çà„Çã‰æ°Ê†º‰∫àÊ∏¨
                - ÁÅΩÂÆ≥„Ç∑„Éä„É™„Ç™„ÇíËÄÉÊÖÆ„Åó„Åü‰æ°Ê†ºË™øÊï¥
                - Ê®ôÊ∫ñË™§Â∑Æ„Å®‰ø°È†ºÂå∫Èñì„ÅÆË®àÁÆó
                
                üìä **„ÇÆ„É™„Ç∑„É£ÊñáÂ≠óÂàÜÊûê**
                - „Éá„É´„ÇøÔºà‰æ°Ê†ºÊÑüÂøúÂ∫¶Ôºâ
                - „Ç¨„É≥„ÉûÔºà„Éá„É´„ÇøÂ§âÂåñÁéáÔºâ
                - „Éô„Ç¨Ôºà„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ÊÑüÂøúÂ∫¶Ôºâ
                - „Ç∑„Éº„ÇøÔºàÊôÇÈñìÊ∏õ‰æ°Ôºâ
                
                üáØüáµ **Êó•Êú¨Â∏ÇÂ†¥ÁâπÂåñÊ©üËÉΩ**
                - Âú∞Èúá„É™„Çπ„ÇØ„É¨„Éô„É´„Å´Âøú„Åò„Åü„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£Ë™øÊï¥
                - Êó•Êú¨ÈäÄË°å„ÅÆÈáëÂà©ÊîøÁ≠ñ„ÇíÂèçÊò†
                """)
        else:
            with st.expander("üìñ About This Tab"):
                st.markdown("""
                **The Options Analytics tab provides:**
                
                üßÆ **Black-Scholes Calculator**
                - European option pricing calculations
                - Call and put option prices with Greeks
                - Japan-specific earthquake risk adjustments
                
                üé≤ **Monte Carlo Simulation**
                - 10,000-iteration price forecasting
                - Disaster scenario-adjusted pricing
                - Standard error and confidence interval calculations
                
                üìä **Greeks Analysis**
                - Delta (price sensitivity)
                - Gamma (delta change rate)
                - Vega (volatility sensitivity)
                - Theta (time decay)
                
                üáØüáµ **Japan Market Specialization**
                - Volatility adjustments based on earthquake risk levels
                - Bank of Japan interest rate policy integration
                """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            calculator_title = "Black-ScholesË®àÁÆóÊ©ü" if lang == 'jp' else "Black-Scholes Calculator"
            st.markdown(f"#### {calculator_title}")
            
            spot = st.number_input("ÁèæÂú®‰æ°Ê†º (¬•)" if lang == 'jp' else "Spot Price (¬•)", value=33000.0, step=100.0)
            strike = st.number_input("Ë°å‰Ωø‰æ°Ê†º (¬•)" if lang == 'jp' else "Strike Price (¬•)", value=33500.0, step=100.0)
            time_to_expiry = st.number_input("Ê∫ÄÊúüÊó•Êï∞" if lang == 'jp' else "Time to Expiry (days)", value=30, step=1)
            volatility = st.number_input("„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ (%)" if lang == 'jp' else "Volatility (%)", value=25.0, step=1.0)
            risk_free_rate = st.number_input("ÁÑ°„É™„Çπ„ÇØÈáëÂà© (%)" if lang == 'jp' else "Risk-Free Rate (%)", value=0.5, step=0.1)
            
            earthquake_data = self.earthquake_data.fetch_recent_earthquakes(limit=50)
            earthquake_risk = self.earthquake_data.assess_tokyo_risk(earthquake_data)
            eq_risk_level = earthquake_risk.get('risk_level', 'LOW')
        
        with col2:
            results_title = "Ë®àÁÆóÁµêÊûú" if lang == 'jp' else "Results"
            st.markdown(f"#### {results_title}")
            
            time_to_maturity = time_to_expiry / 365.0
            vol_decimal = volatility / 100.0
            rate_decimal = risk_free_rate / 100.0
            
            adjusted_vol = self.bs_engine.get_japanese_market_adjustments(vol_decimal, eq_risk_level)
            
            pricing_results = self.bs_engine.calculate_option_prices(
                spot, strike, time_to_maturity, rate_decimal, adjusted_vol
            )
            
            st.metric("„Ç≥„Éº„É´‰æ°Ê†º" if lang == 'jp' else "Call Option Price", f"¬•{pricing_results['call_price']:.2f}")
            st.metric("„Éó„ÉÉ„Éà‰æ°Ê†º" if lang == 'jp' else "Put Option Price", f"¬•{pricing_results['put_price']:.2f}") 
            st.metric("„Éá„É´„Çø" if lang == 'jp' else "Delta", f"{pricing_results['greeks']['delta_call']:.4f}")
            st.metric("„Ç¨„É≥„Éû" if lang == 'jp' else "Gamma", f"{pricing_results['greeks']['gamma']:.6f}")
            st.metric("„Éô„Ç¨" if lang == 'jp' else "Vega", f"{pricing_results['greeks']['vega']:.4f}")
            st.metric("„Ç∑„Éº„Çø" if lang == 'jp' else "Theta", f"{pricing_results['greeks']['theta_call']:.4f}")
            
            if eq_risk_level != 'LOW':
                adj_factor = adjusted_vol / vol_decimal
                warning_text = f"Âú∞Èúá„É™„Çπ„ÇØË™øÊï¥: {adj_factor:.2f}x" if lang == 'jp' else f"Earthquake Risk Adjustment: {adj_factor:.2f}x"
                st.warning(warning_text)
        
        st.markdown("---")
        monte_carlo_title = "„É¢„É≥„ÉÜ„Ç´„É´„É≠„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥" if lang == 'jp' else "Monte Carlo Simulation"
        st.markdown(f"### {monte_carlo_title}")
        
        if st.button("„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÂÆüË°å" if lang == 'jp' else "Run Simulation"):
            mc_results = self.bs_engine.monte_carlo_pricing(
                spot, strike, time_to_maturity, rate_decimal, adjusted_vol, 
                num_simulations=10000, option_type='call'
            )
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("MC „Ç≥„Éº„É´‰æ°Ê†º" if lang == 'jp' else "MC Call Price", f"¬•{mc_results['standard_price']:.2f}")
            with col2:
                st.metric("ÁÅΩÂÆ≥Ë™øÊï¥‰æ°Ê†º" if lang == 'jp' else "Disaster Adjusted", f"¬•{mc_results['disaster_adjusted_price']:.2f}")
            with col3:
                st.metric("Ê®ôÊ∫ñË™§Â∑Æ" if lang == 'jp' else "Standard Error", f"¬•{mc_results['standard_error']:.4f}")

    def render_decision_tab(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "üé™ ÊÑèÊÄùÊ±∫ÂÆöÊîØÊè¥„Ç≠„É•„Éº" if lang == 'jp' else "üé™ Decision Support Queue"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("üìñ „Åì„ÅÆ„Çø„Éñ„Å´„Å§„ÅÑ„Å¶"):
                st.markdown("""
                **ÊÑèÊÄùÊ±∫ÂÆöÊîØÊè¥„Çø„Éñ„Åß„ÅØ‰ª•‰∏ã„ÅÆÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„Åæ„ÅôÔºö**
                
                ü§ñ **AIÊé®Â•®„Ç∑„Çπ„ÉÜ„É†„ÅÆË©≥Á¥∞‰ªïÁµÑ„Åø**
                - **Êé®Â•®ÁîüÊàêÊù°‰ª∂**: 
                  - **Âú∞Èúá„É™„Çπ„ÇØMEDIUM‰ª•‰∏ä**: Ëá™ÂãïÁöÑ„Å´REIT„Éª‰øùÈô∫„Çª„ÇØ„Çø„ÉºË≠¶Âëä
                  - **Â∏ÇÂ†¥„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£30%Ë∂Ö**: „Éù„Ç∏„Ç∑„Éß„É≥„Çµ„Ç§„Ç∫Á∏ÆÂ∞èÊé®Â•®
                  - **Áõ∏Èñ¢„É™„Çπ„ÇØ0.7‰ª•‰∏ä**: ÂàÜÊï£ÊäïË≥áËøΩÂä†Êé®Â•®
                - **ÂÑ™ÂÖàÂ∫¶ÂàÜÈ°û„Ç∑„Çπ„ÉÜ„É†**:
                  - **CRITICALÔºàÁ∑äÊÄ•Ôºâ**: Âç≥Â∫ß„ÅÆË°åÂãï„ÅåÂøÖË¶ÅÔºà‰æãÔºöÂ§ßÂú∞ÈúáÁô∫ÁîüÊôÇ„ÅÆÁ∑äÊÄ•Â£≤Âç¥Ôºâ
                  - **HIGHÔºàÈ´òÔºâ**: 24ÊôÇÈñì‰ª•ÂÜÖ„ÅÆÂØæÂøúÊé®Â•®Ôºà‰æãÔºöÈ´ò„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£„Åß„ÅÆ„Éò„ÉÉ„Ç∏ËøΩÂä†Ôºâ
                  - **MEDIUMÔºà‰∏≠Ôºâ**: 1ÈÄ±Èñì‰ª•ÂÜÖ„ÅÆÊ§úË®éÔºà‰æãÔºö„Éù„Éº„Éà„Éï„Ç©„É™„Ç™Ë™øÊï¥Ôºâ
                  - **LOWÔºà‰ΩéÔºâ**: 1„É∂Êúà‰ª•ÂÜÖ„ÅÆÈï∑ÊúüÁöÑÂØæÂøúÔºà‰æãÔºöÂÆöÊúüÁöÑ„Å™„É™„Éê„É©„É≥„ÇπÔºâ
                
                - **‰ø°È†ºÂ∫¶„Çπ„Ç≥„Ç¢ÁÆóÂá∫**:
                  - **95%‰ª•‰∏ä**: „Éá„Éº„ÇøÂìÅË≥™È´òÔºãÈÅéÂéªÂÆüÁ∏æ‰∏ÄËá¥
                  - **80-95%**: Ê®ôÊ∫ñÁöÑ„Å™Êé®Â•®ÔºàÈÄöÂ∏∏Êé°Áî®Ôºâ
                  - **60-80%**: Ë¶ÅÊ§úË®éÔºàËøΩÂä†ÂàÜÊûêÊé®Â•®Ôºâ
                  - **60%Êú™Ê∫Ä**: ‰Ωé‰ø°È†ºÂ∫¶ÔºàÊÖéÈáçÂà§Êñ≠Ë¶ÅÔºâ
                
                ‚úÖ **ÊâøË™ç„ÉªÊãíÂê¶„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÅÆÂÆüË£Ö**
                - **ÊâøË™çÂäπÊûú**: 
                  - Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥„ÅåÊ±∫ÂÆöÂ±•Ê≠¥„Å´Ë®òÈå≤
                  - Â∞ÜÊù•„ÅÆAIÂ≠¶Áøí„Éá„Éº„Çø„Å®„Åó„Å¶Ê¥ªÁî®
                  - „Éù„Éº„Éà„Éï„Ç©„É™„Ç™ÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É†„Å∏„ÅÆÈÄ£Êê∫ÔºàÂ∞ÜÊù•ÂÆüË£ÖÔºâ
                - **ÊãíÂê¶ÂäπÊûú**:
                  - Âà§Êñ≠ÁêÜÁî±„ÇíAI„ÅåÂ≠¶ÁøíÔºàÁ≤æÂ∫¶Âêë‰∏äÔºâ
                  - È°û‰ººÁä∂Ê≥Å„Åß„ÅÆÊé®Â•®È†ªÂ∫¶Ë™øÊï¥
                  - „É¶„Éº„Ç∂„ÉºÂõ∫Êúâ„ÅÆÈÅ∏Â•ΩÂ≠¶Áøí
                - **ÈáçË§áÈò≤Ê≠¢**: ÂÜÖÂÆπ„Éè„ÉÉ„Ç∑„É•„Å´„Çà„ÇãÂÆâÂÆöIDÁÆ°ÁêÜ„ÅßÂêå‰∏ÄÊé®Â•®„ÅÆÈáçË§áÂõûÈÅø
                
                üìä **Ê±∫ÂÆöÂ±•Ê≠¥ÁÆ°ÁêÜ„ÅÆÊ¥ªÁî®‰æ°ÂÄ§**
                - **„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπËøΩË∑°**: ÊâøË™ç„Åó„ÅüÊé®Â•®„ÅÆÊàêÊûúÊ∏¨ÂÆö
                - **Â≠¶ÁøíÂäπÊûú**: „É¶„Éº„Ç∂„Éº„ÅÆÂà§Êñ≠„Éë„Çø„Éº„É≥ÂàÜÊûê
                - **Áõ£ÊüªË®ºË∑°**: „Ç≥„É≥„Éó„É©„Ç§„Ç¢„É≥„ÇπË¶ÅÊ±Ç„Å∏„ÅÆÂØæÂøú
                - **Áµ±Ë®àÂàÜÊûê**: 
                  - **ÊâøË™çÁéá**: ÂÖ®Êé®Â•®‰∏≠„ÅÆÊâøË™çÂâ≤Âêà
                  - **ÊàêÂäüÁéá**: ÊâøË™ç„Åó„ÅüÊé®Â•®„ÅÆÂÆüÈöõ„ÅÆÊàêÊûú
                  - **ÂèçÂøúÊôÇÈñì**: Êé®Â•®„Åã„ÇâÊ±∫ÂÆö„Åæ„Åß„ÅÆÂπ≥ÂùáÊôÇÈñì
                
                üéØ **ÂØæË±°„Çª„ÇØ„Çø„ÉºÂàÜÊûê„ÅÆË©≥Á¥∞**
                - **Áõ¥Êé•ÂΩ±Èüø„Çª„ÇØ„Çø„Éº**: Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥„ÅÆ‰∏ªË¶ÅÂØæË±°
                  - **‰æã**: Âú∞Èúá„É™„Çπ„ÇØ ‚Üí ‰∏çÂãïÁî£REIT„ÄÅ‰øùÈô∫„ÄÅÂª∫Ë®≠
                - **ÈñìÊé•ÂΩ±Èüø„Çª„ÇØ„Çø„Éº**: Ê≥¢ÂèäÂäπÊûú„Åå‰∫àÊÉ≥„Åï„Çå„ÇãÂàÜÈáé
                  - **‰æã**: ÂÜÜÈ´òÊé®Áßª ‚Üí Ëº∏Âá∫‰ºÅÊ•≠„ÄÅË¶≥ÂÖâÊ•≠
                - **ÂΩ±ÈüøÂ∫¶‰∫àÊ∏¨**: 
                  - **ÈáçÂ§ßÔºà-20%‰ª•‰∏äÔºâ**: Âç≥Â∫ß„ÅÆÂØæÂøúÂøÖË¶Å
                  - **‰∏≠Á®ãÂ∫¶Ôºà-10„Äú-20%Ôºâ**: ÊÖéÈáç„Å™Áõ£Ë¶ñ
                  - **ËªΩÂæÆÔºà-10%Êú™Ê∫ÄÔºâ**: Èï∑ÊúüÁöÑ„Å™Ë¶≥ÂØü
                
                **ÂÆüÁî®ÁöÑ‰ΩøÁî®„Ç¨„Ç§„Éâ„É©„Ç§„É≥**:
                1. **Êúù„ÅÆÁ¢∫Ë™ç**: Â∏ÇÂ†¥ÈñãÂßãÂâç„Å´Êñ∞Ë¶èÊé®Â•®„Çí„ÉÅ„Çß„ÉÉ„ÇØ
                2. **ÂÑ™ÂÖàÈ†Ü‰Ωç**: CRITICAL‚ÜíHIGH‚ÜíMEDIUM‚ÜíLOW„ÅÆÈ†Ü„ÅßÂØæÂøú
                3. **‰ø°È†ºÂ∫¶Âà§Êñ≠**: 80%‰ª•‰∏ä„ÅÆÊé®Â•®„ÇíÂÑ™ÂÖàÁöÑ„Å´Ê§úË®é
                4. **Ë®òÈå≤Ê¥ªÁî®**: ÊúàÊ¨°„ÅßÊ±∫ÂÆöÂ±•Ê≠¥„ÇíÂàÜÊûê„Åó„ÄÅÊà¶Áï•ÊîπÂñÑ
                5. **Â≠¶Áøí‰øÉÈÄ≤**: ÊãíÂê¶ÊôÇ„ÅØÁêÜÁî±„Çí„É°„É¢ÔºàÂ∞ÜÊù•„ÅÆAIÊîπÂñÑÁî®Ôºâ
                """)
        else:
            with st.expander("üìñ About This Tab"):
                st.markdown("""
                **The Decision Support tab provides:**
                
                ü§ñ **AI Recommendation System Detailed Mechanics**
                - **Recommendation Triggers**:
                  - **Earthquake Risk MEDIUM+**: Auto-alerts for REIT & insurance sectors
                  - **Market Volatility >30%**: Position size reduction recommendations
                  - **Correlation Risk >0.7**: Additional diversification suggestions
                - **Priority Classification System**:
                  - **CRITICAL**: Immediate action required (e.g., emergency selling during major earthquake)
                  - **HIGH**: Response recommended within 24 hours (e.g., hedging during high volatility)
                  - **MEDIUM**: Consideration within 1 week (e.g., portfolio adjustments)
                  - **LOW**: Long-term response within 1 month (e.g., regular rebalancing)
                
                - **Confidence Score Calculation**:
                  - **95%+**: High data quality + historical performance match
                  - **80-95%**: Standard recommendations (normally adopted)
                  - **60-80%**: Requires consideration (additional analysis recommended)
                  - **<60%**: Low confidence (cautious judgment required)
                
                ‚úÖ **Approval/Rejection Workflow Implementation**
                - **Approval Effects**:
                  - Recommended actions recorded in decision history
                  - Used as future AI learning data
                  - Integration with portfolio management systems (future implementation)
                - **Rejection Effects**:
                  - AI learns reasoning for accuracy improvement
                  - Adjusts recommendation frequency for similar situations
                  - Learns user-specific preferences
                - **Duplicate Prevention**: Stable ID management via content hashing prevents duplicate recommendations
                
                üìä **Decision History Management Value**
                - **Performance Tracking**: Measure success of approved recommendations
                - **Learning Effects**: Analyze user decision patterns
                - **Audit Trail**: Compliance requirement fulfillment
                - **Statistical Analysis**:
                  - **Approval Rate**: Percentage of recommendations approved
                  - **Success Rate**: Actual performance of approved recommendations
                  - **Response Time**: Average time from recommendation to decision
                
                üéØ **Target Sector Analysis Details**
                - **Direct Impact Sectors**: Primary targets of recommended actions
                  - **Example**: Earthquake risk ‚Üí Real estate REITs, insurance, construction
                - **Indirect Impact Sectors**: Areas expecting ripple effects
                  - **Example**: Yen appreciation ‚Üí Export companies, tourism industry
                - **Impact Magnitude Prediction**:
                  - **Severe (-20%+)**: Immediate response required
                  - **Moderate (-10% to -20%)**: Careful monitoring
                  - **Minor (<-10%)**: Long-term observation
                
                **Practical Usage Guidelines**:
                1. **Morning Check**: Review new recommendations before market open
                2. **Prioritization**: Handle CRITICAL‚ÜíHIGH‚ÜíMEDIUM‚ÜíLOW in order
                3. **Confidence Assessment**: Prioritize recommendations with 80%+ confidence
                4. **Record Utilization**: Monthly analysis of decision history for strategy improvement
                5. **Learning Enhancement**: Note reasons for rejections (for future AI improvement)
                
                **Understanding the AI Logic**:
                - **Data Integration**: Combines earthquake, market, and correlation data
                - **Pattern Recognition**: Identifies historical precedents and outcomes
                - **Risk Weighting**: Balances multiple risk factors with proven weights
                - **Timing Optimization**: Considers market conditions and volatility for action timing
                """)
        
        if 'decision_queue' not in st.session_state:
            st.session_state.decision_queue = []
        if 'decision_history' not in st.session_state:
            st.session_state.decision_history = []
        
        with st.spinner("Loading risk assessment..."):
            try:
                earthquake_data = self.earthquake_data.fetch_recent_earthquakes(limit=10)
                earthquake_risk = self.earthquake_data.assess_tokyo_risk(earthquake_data)
                market_summary = self.market_data.get_tokyo_market_summary()
                correlation_matrix = pd.DataFrame()  
                
                risk_assessment = self.risk_engine.assess_integrated_risk(
                    earthquake_risk, market_summary, correlation_matrix
                )
            except Exception as e:
                st.error("Unable to fetch risk data. Using cached information.")
                earthquake_risk = {'risk_level': 'LOW', 'recent_activity': 0}
                risk_assessment = {'recommendations': []}
        
        current_decisions = risk_assessment.get('recommendations', [])
        
        for decision in current_decisions:
            stable_id = f"{decision.get('category', 'unknown')}_{hash(decision.get('action', ''))}"
            decision['id'] = stable_id
            decision['timestamp'] = datetime.now()
            decision['status'] = 'PENDING'
        
        existing_ids = {d.get('id') for d in st.session_state.decision_queue if d.get('status') == 'PENDING'}
        processed_ids = {d.get('id') for d in st.session_state.decision_history}
        all_existing_ids = existing_ids.union(processed_ids)
        
        new_decisions = [d for d in current_decisions if d.get('id') not in all_existing_ids]
        st.session_state.decision_queue.extend(new_decisions)
        
        pending_decisions = [d for d in st.session_state.decision_queue if d.get('status') == 'PENDING']
        
        if not pending_decisions:
            st.info(translations.get("no_pending_decisions", "No pending decisions at this time."))
            return
        
        for i, decision in enumerate(pending_decisions):
            priority_color = {
                "HIGH": THEME_COLORS['warning'],
                "CRITICAL": THEME_COLORS['warning'],
                "MEDIUM": "#F7931E", 
                "LOW": THEME_COLORS['info']
            }.get(decision.get('priority', 'LOW'), THEME_COLORS['info'])
            
            if lang == 'jp':
                priority_map = {'HIGH': 'È´ò', 'CRITICAL': 'Á∑äÊÄ•', 'MEDIUM': '‰∏≠', 'LOW': '‰Ωé'}
                priority_text = priority_map.get(decision.get('priority', 'LOW'), decision.get('priority', 'LOW'))
                
                category_map = {
                    'Earthquake Risk': 'Âú∞Èúá„É™„Çπ„ÇØ',
                    'Market Volatility': 'Â∏ÇÂ†¥„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£', 
                    'Correlation Risk': 'Áõ∏Èñ¢„É™„Çπ„ÇØ',
                    'Systemic Risk': '„Ç∑„Çπ„ÉÜ„Éü„ÉÉ„ÇØ„É™„Çπ„ÇØ',
                    'Monitoring': '„É¢„Éã„Çø„É™„É≥„Ç∞'
                }
                category_text = category_map.get(decision.get('category', ''), decision.get('category', ''))
            else:
                priority_text = decision.get('priority', 'LOW')
                category_text = decision.get('category', '')
            
            st.markdown(f"""
            <div class="decision-item" style="border-left-color: {priority_color};">
                <h4>{priority_text} ÂÑ™ÂÖàÂ∫¶: {category_text}</h4>
                <p><strong>ÂàÜÊûê:</strong> {decision.get('rationale', '')}</p>
                <p><strong>Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥:</strong> {decision.get('action', '')}</p>
                <p><strong>‰ø°È†ºÂ∫¶:</strong> {decision.get('confidence', 'N/A')} | <strong>„Çø„Ç§„É†„É©„Ç§„É≥:</strong> {decision.get('timeline', '')}</p>
                <p><strong>ÂØæË±°„Çª„ÇØ„Çø„Éº:</strong> {', '.join(decision.get('target_sectors', []))}</p>
            </div>
            """ if lang == 'jp' else f"""
            <div class="decision-item" style="border-left-color: {priority_color};">
                <h4>{decision.get('priority', 'LOW')} PRIORITY: {decision.get('category', '')}</h4>
                <p><strong>Analysis:</strong> {decision.get('rationale', '')}</p>
                <p><strong>Recommended Action:</strong> {decision.get('action', '')}</p>
                <p><strong>Confidence:</strong> {decision.get('confidence', 'N/A')} | <strong>Timeline:</strong> {decision.get('timeline', '')}</p>
                <p><strong>Target Sectors:</strong> {', '.join(decision.get('target_sectors', []))}</p>
            </div>
            """, unsafe_allow_html=True)
            
            col1, col2, col3 = st.columns([1, 1, 3])
            with col1:
                approve_text = "‚úÖ ÊâøË™ç" if lang == 'jp' else "‚úÖ Approve"
                if st.button(approve_text, key=f"approve_{decision.get('id', i)}"):
                    for d in st.session_state.decision_queue:
                        if d.get('id') == decision.get('id'):
                            d['status'] = 'APPROVED'
                            d['action_timestamp'] = datetime.now()
                            d['action_user'] = 'User'
                            break
                    
                    decision['status'] = 'APPROVED'
                    decision['action_timestamp'] = datetime.now()
                    st.session_state.decision_history.append(decision.copy())
                    
                    success_text = f"Ê±∫ÂÆö„ÇíÊâøË™ç„Åó„Åæ„Åó„Åü: {decision.get('action', '')}" if lang == 'jp' else f"Decision approved: {decision.get('action', '')}"
                    st.success(success_text)
                    st.rerun()
            
            with col2:
                reject_text = "‚ùå ÊãíÂê¶" if lang == 'jp' else "‚ùå Reject"
                if st.button(reject_text, key=f"reject_{decision.get('id', i)}"):
                    for d in st.session_state.decision_queue:
                        if d.get('id') == decision.get('id'):
                            d['status'] = 'REJECTED'
                            d['action_timestamp'] = datetime.now()
                            d['action_user'] = 'User'
                            break
                    
                    decision['status'] = 'REJECTED'
                    decision['action_timestamp'] = datetime.now()
                    st.session_state.decision_history.append(decision.copy())
                    
                    warning_text = f"Ê±∫ÂÆö„ÇíÊãíÂê¶„Åó„Åæ„Åó„Åü: {decision.get('action', '')}" if lang == 'jp' else f"Decision rejected: {decision.get('action', '')}"
                    st.warning(warning_text)
                    st.rerun()
        
        if st.session_state.decision_history:
            st.markdown("---")
            history_title = "Ê±∫ÂÆöÂ±•Ê≠¥" if lang == 'jp' else "Decision History"
            st.markdown(f"### {history_title}")
            
            history_df = pd.DataFrame(st.session_state.decision_history)
            if not history_df.empty:
                display_columns = ['action_timestamp', 'priority', 'category', 'action', 'status']
                available_columns = [col for col in display_columns if col in history_df.columns]
                
                if available_columns:
                    display_df = history_df[available_columns].copy()
                    if 'action_timestamp' in display_df.columns:
                        display_df['action_timestamp'] = display_df['action_timestamp'].dt.strftime('%Y-%m-%d %H:%M')
                    
                    if lang == 'jp':
                        column_map = {
                            'action_timestamp': 'ÂÆüË°åÊôÇÂàª',
                            'priority': 'ÂÑ™ÂÖàÂ∫¶', 
                            'category': '„Ç´„ÉÜ„Ç¥„É™',
                            'action': '„Ç¢„ÇØ„Ç∑„Éß„É≥',
                            'status': '„Çπ„ÉÜ„Éº„Çø„Çπ'
                        }
                        display_df = display_df.rename(columns=column_map)
                    
                    st.dataframe(display_df, use_container_width=True)
        
        if st.button("Â±•Ê≠¥„Çí„ÇØ„É™„Ç¢" if lang == 'jp' else "Clear History"):
            st.session_state.decision_history = []
            st.session_state.decision_queue = [d for d in st.session_state.decision_queue if d.get('status') == 'PENDING']
            st.rerun()

    def render_network_analysis_tab(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "üï∏Ô∏è „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„É™„Çπ„ÇØÂàÜÊûê" if lang == 'jp' else "üï∏Ô∏è Network Risk Analysis"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("üìñ „Åì„ÅÆ„Çø„Éñ„Å´„Å§„ÅÑ„Å¶"):
                st.markdown("""
                **„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂàÜÊûê„Çø„Éñ„Åß„ÅØ‰ª•‰∏ã„ÅÆÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„Åæ„ÅôÔºö**
                
                üï∏Ô∏è **„É™„Çπ„ÇØ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂèØË¶ñÂåñ**
                - Â∏ÇÂ†¥„ÄÅÂú∞Èúá„ÄÅ„Çª„ÇØ„Çø„ÉºÈñì„ÅÆÁõ∏Èñ¢Èñ¢‰øÇ„Çí„Ç∞„É©„ÉïË°®Á§∫
                - „Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ„Å™Âà∂Âæ°Ôºà„É©„Éô„É´„ÉªÊé•Á∂öÁ∑ö„ÅÆË°®Á§∫/ÈùûË°®Á§∫Ôºâ
                - „Éé„Éº„Éâ„Çø„Ç§„ÉóÂà•„ÅÆËâ≤ÂàÜ„ÅëË°®Á§∫
                
                üìä **„Ç∑„Çπ„ÉÜ„Éü„ÉÉ„ÇØ„É™„Çπ„ÇØË®àÁÆó**
                - „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂØÜÂ∫¶„Å´Âü∫„Å•„Åè„É™„Çπ„ÇØ„Çπ„Ç≥„Ç¢
                - ‰∏≠ÂøÉÊÄßÂàÜÊûê„Å´„Çà„ÇãÈáçË¶Å„Éé„Éº„ÉâÁâπÂÆö
                - „ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞‰øÇÊï∞„ÅÆË®àÁÆó
                
                üéØ **„É™„Çπ„ÇØ„ÇØ„É©„Çπ„Çø„ÉºÊ§úÂá∫**
                - Áõ∏Èñ¢„ÅÆÈ´ò„ÅÑ„É™„Çπ„ÇØË¶ÅÂõ†„Ç∞„É´„Éº„Éó„ÅÆÁâπÂÆö
                - „ÇØ„É©„Çπ„Çø„ÉºÂÜÖ„É™„Çπ„ÇØ„Çπ„Ç≥„Ç¢„ÅÆË®àÁÆó
                - ‰∏ä‰Ωç„ÇØ„É©„Çπ„Çø„Éº„ÅÆË©≥Á¥∞ÂàÜÊûê
                
                üîó **‰ºùÊüìÁµåË∑ØÂàÜÊûê**
                - ÈÅ∏Êäû„Åó„Åü„Éé„Éº„Éâ„Åã„Çâ„ÅÆ„É™„Çπ„ÇØÊ≥¢ÂèäÁµåË∑Ø
                - ÂΩ±ÈüøÂ∫¶„Å´Âü∫„Å•„ÅèÁµåË∑Ø„É©„É≥„Ç≠„É≥„Ç∞
                - ÊúÄÂ§ß4„Éõ„ÉÉ„Éó„Åæ„Åß„ÅÆÁµåË∑ØÊé¢Á¥¢
                
                ‚ö†Ô∏è **Áï∞Â∏∏Ê§úÂá∫**
                - È´ò‰∏≠ÂøÉÊÄß„Éé„Éº„Éâ„ÅÆÁâπÂÆö
                - Â≠§Á´ã„ÇØ„É©„Çπ„Çø„Éº„ÅÆÊ§úÂá∫
                - „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊßãÈÄ†„ÅÆÁï∞Â∏∏„Éë„Çø„Éº„É≥
                
                **‰ΩøÁî®ÊñπÊ≥ïÔºö** ÂèØË¶ñÂåñË®≠ÂÆö„ÇíË™øÊï¥„Åó„ÄÅ„Çø„Éñ„ÅßÁï∞„Å™„ÇãÂàÜÊûê„ÇíÂàá„ÇäÊõø„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
                """)
        else:
            with st.expander("üìñ About This Tab"):
                st.markdown("""
                **The Network Analysis tab provides:**
                
                üï∏Ô∏è **Risk Network Visualization**
                - Graph display of correlations between markets, earthquakes, and sectors
                - Interactive controls (show/hide labels and connections)
                - Color-coded display by node types
                
                üìä **Systemic Risk Calculation**
                - Risk scoring based on network density
                - Critical node identification through centrality analysis
                - Clustering coefficient calculations
                
                üéØ **Risk Cluster Detection**
                - Identification of highly correlated risk factor groups
                - Risk score calculation within clusters
                - Detailed analysis of top clusters
                
                üîó **Contagion Path Analysis**
                - Risk propagation paths from selected nodes
                - Path ranking based on impact potential
                - Path exploration up to 4 hops
                
                ‚ö†Ô∏è **Anomaly Detection**
                - High centrality node identification
                - Isolated cluster detection
                - Abnormal network structure patterns
                
                **How to use:** Adjust visualization settings and switch between different analyses using tabs.
                """)
        
        with st.spinner("Building risk network..." if lang == 'en' else "„É™„Çπ„ÇØ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊßãÁØâ‰∏≠..."):
            try:
                earthquake_data = self.earthquake_data.fetch_recent_earthquakes(limit=5)  
                market_summary = self.market_data.get_tokyo_market_summary()
                
                selected_markets = st.session_state.get('selected_markets', ['nikkei', 'topix', 'jpy_usd'])
                filtered_market_summary = {k: v for k, v in market_summary.items() if k in selected_markets}
                
                corr_data = {}
                for ticker in selected_markets[:3]:  # Limit to 3 for clarity
                    if ticker in filtered_market_summary and filtered_market_summary[ticker]:
                        corr_data[ticker] = filtered_market_summary[ticker].get('change_percent', 0)
                
                if len(corr_data) >= 2:
                    correlation_matrix = pd.DataFrame(
                        np.random.rand(len(corr_data), len(corr_data)) * 0.6 + 0.2,  
                        index=list(corr_data.keys()),
                        columns=list(corr_data.keys())
                    )
                    np.fill_diagonal(correlation_matrix.values, 1.0)
                else:
                    correlation_matrix = pd.DataFrame()
                
                self.network_engine.build_risk_network(
                    filtered_market_summary, 
                    earthquake_data, 
                    correlation_matrix
                )
                
                systemic_risk = self.network_engine.calculate_systemic_risk_score()
                
            except Exception as e:
                st.error(f"Unable to build network: {str(e)}")
                return
        
        st.markdown("#### üìä Network Risk Metrics" if lang == 'en' else "#### üìä „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„É™„Çπ„ÇØ„É°„Éà„É™„ÇØ„Çπ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            risk_level = systemic_risk['risk_level']
            risk_colors = {'LOW': '#2D6A4F', 'MEDIUM': '#F7931E', 'HIGH': '#FF6B35', 'CRITICAL': '#E63946'}
            color = risk_colors.get(risk_level, '#778DA9')
            
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"„Ç∑„Çπ„ÉÜ„Éü„ÉÉ„ÇØ„É™„Çπ„ÇØ" if lang == 'jp' else "Systemic Risk"}</h4>
                <h2 style="color: {color};">{translations.get(f'risk_{risk_level.lower()}', risk_level)}</h2>
                <p>Score: {systemic_risk['systemic_risk_score']:.3f}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂØÜÂ∫¶" if lang == 'jp' else "Network Density"}</h4>
                <h2>{systemic_risk['network_density']:.3f}</h2>
                <p>{"Êé•Á∂öÊÄßÊåáÊ®ô" if lang == 'jp' else "Connectivity Metric"}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            critical_node = systemic_risk['critical_nodes'][0][0] if systemic_risk['critical_nodes'] else 'None'
            critical_score = systemic_risk['critical_nodes'][0][1] if systemic_risk['critical_nodes'] else 0
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"ÊúÄÈáçË¶Å„Éé„Éº„Éâ" if lang == 'jp' else "Most Critical Node"}</h4>
                <h2>{critical_node}</h2>
                <p>{"‰∏≠ÂøÉÊÄß" if lang == 'jp' else "Centrality"}: {critical_score:.3f}</p>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("#### üåê Risk Network Visualization" if lang == 'en' else "#### üåê „É™„Çπ„ÇØ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂèØË¶ñÂåñ")
        
        col1, col2 = st.columns([3, 1])
        
        with col2:
            show_labels = st.checkbox("Show Labels" if lang == 'en' else "„É©„Éô„É´Ë°®Á§∫", value=True)
            show_edges = st.checkbox("Show Connections" if lang == 'en' else "Êé•Á∂öË°®Á§∫", value=True)
        
        with col1:
            try:
                fig = self.network_engine.generate_network_visualization()
                
                fig.update_layout(
                    title="",
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    font_color=THEME_COLORS['text_primary'],
                    height=500,
                    showlegend=True,
                    legend=dict(
                        yanchor="top",
                        y=0.99,
                        xanchor="left",
                        x=0.01
                    )
                )
                
                if not show_labels:
                    fig.update_traces(textposition="none")
                if not show_edges:
                    for i, trace in enumerate(fig.data):
                        if trace.mode == 'lines':
                            fig.data[i].visible = False
                
                st.plotly_chart(fig, use_container_width=True)
                
            except Exception as e:
                st.error(f"Unable to generate visualization: {str(e)}")
                st.info("Network visualization temporarily unavailable. Please try refreshing the data.")
        
        st.markdown("---")
        st.markdown("#### üîç Risk Analysis" if lang == 'en' else "#### üîç „É™„Çπ„ÇØÂàÜÊûê")
        
        analysis_tabs = st.tabs([
            "üéØ Risk Clusters" if lang == 'en' else "üéØ „É™„Çπ„ÇØ„ÇØ„É©„Çπ„Çø„Éº",
            "üîó Contagion Paths" if lang == 'en' else "üîó ‰ºùÊüìÁµåË∑Ø",
            "‚ö†Ô∏è Anomalies" if lang == 'en' else "‚ö†Ô∏è Áï∞Â∏∏Ê§úÂá∫"
        ])
        
        with analysis_tabs[0]:
            risk_clusters = self.network_engine.detect_risk_clusters()
            
            if risk_clusters:
                st.write("**Detected Risk Clusters:**" if lang == 'en' else "**Ê§úÂá∫„Åï„Çå„Åü„É™„Çπ„ÇØ„ÇØ„É©„Çπ„Çø„Éº:**")
                
                for i, cluster in enumerate(risk_clusters[:2]):  # Show only top 2
                    risk_score = cluster['risk_score']
                    nodes = cluster['nodes']
                    
                    if risk_score > 1.5:
                        severity = "HIGH" if lang == 'en' else "È´ò"
                        color = THEME_COLORS['warning']
                    elif risk_score > 1.0:
                        severity = "MEDIUM" if lang == 'en' else "‰∏≠"
                        color = '#FF6B35'
                    else:
                        severity = "LOW" if lang == 'en' else "‰Ωé"
                        color = THEME_COLORS['info']
                    
                    st.markdown(f"""
                    <div class="risk-card" style="border-left-color: {color};">
                        <h5>Cluster {i+1} - {severity} Risk</h5>
                        <p><strong>Risk Score:</strong> {risk_score:.2f}</p>
                        <p><strong>Components:</strong> {', '.join(nodes[:3])}{'...' if len(nodes) > 3 else ''}</p>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.info("No significant risk clusters detected" if lang == 'en' else "ÈáçË¶Å„Å™„É™„Çπ„ÇØ„ÇØ„É©„Çπ„Çø„Éº„ÅØÊ§úÂá∫„Åï„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü")
        
        with analysis_tabs[1]:      
            all_nodes = list(self.network_engine.risk_network.nodes())
            if all_nodes:
                source_node = st.selectbox(
                    "Select source for contagion analysis:" if lang == 'en' else "‰ºùÊüìÂàÜÊûê„ÅÆÈúáÊ∫ê„ÇíÈÅ∏Êäû:",
                    all_nodes[:5]  
                )
                
                if st.button("üîç Analyze" if lang == 'en' else "üîç ÂàÜÊûê"):
                    contagion_paths = self.network_engine.find_contagion_paths(source_node)
                    
                    if contagion_paths:
                        st.write(f"**Top contagion paths from {source_node}:**")
                        
                        for i, path_info in enumerate(contagion_paths[:3]):  # Show only top 3
                            path = path_info['path']
                            impact = path_info['impact']
                            
                            path_str = " ‚Üí ".join(path)
                            impact_pct = impact * 100
                            
                            st.markdown(f"""
                            <div class="decision-item">
                                <p><strong>Path {i+1}:</strong> {path_str}</p>
                                <p><strong>Impact Potential:</strong> {impact_pct:.1f}%</p>
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.info("No significant contagion paths found" if lang == 'en' else "ÈáçË¶Å„Å™‰ºùÊüìÁµåË∑Ø„ÅØË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü")
            else:
                st.info("No network nodes available for analysis" if lang == 'en' else "ÂàÜÊûêÂèØËÉΩ„Å™„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Éé„Éº„Éâ„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
        
        with analysis_tabs[2]:
            anomalies = self.network_engine.detect_anomalies()
            
            if anomalies:
                st.write("**Detected Anomalies:**" if lang == 'en' else "**Ê§úÂá∫„Åï„Çå„ÅüÁï∞Â∏∏:**")
                
                for anomaly in anomalies[:3]:  
                    severity_colors = {
                        'HIGH': THEME_COLORS['warning'],
                        'MEDIUM': '#FF6B35',
                        'LOW': THEME_COLORS['info']
                    }
                    color = severity_colors.get(anomaly['severity'], THEME_COLORS['info'])
                    
                    anomaly_type = anomaly['type'].replace('_', ' ').title()
                    
                    st.markdown(f"""
                    <div class="risk-card" style="border-left-color: {color};">
                        <h5>‚ö†Ô∏è {anomaly_type}</h5>
                        <p>{anomaly['description']}</p>
                        <p><strong>Severity:</strong> {anomaly['severity']}</p>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.success("‚úÖ No anomalies detected in the risk network" if lang == 'en' else "‚úÖ „É™„Çπ„ÇØ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Å´Áï∞Â∏∏„ÅØÊ§úÂá∫„Åï„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü")
        
        st.markdown("---")
        if lang == 'jp':
            st.markdown("""
            **üí° „Éí„É≥„Éà:**
            - „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂØÜÂ∫¶„ÅåÈ´ò„ÅÑ„Åª„Å©„ÄÅ„Ç∑„Çπ„ÉÜ„Éü„ÉÉ„ÇØ„É™„Çπ„ÇØ„ÅåÈ´ò„Åè„Å™„Çä„Åæ„Åô
            - ÈáçË¶Å„Éé„Éº„Éâ„ÅØÂ∏ÇÂ†¥ÂÖ®‰Ωì„Å∏„ÅÆÂΩ±Èüø„ÅåÂ§ß„Åç„ÅÑË¶ÅÁ¥†„Åß„Åô
            - ‰ºùÊüìÁµåË∑ØÂàÜÊûê„Åß„É™„Çπ„ÇØ„ÅÆÊ≥¢Âèä„Çí‰∫àÊ∏¨„Åß„Åç„Åæ„Åô
            """)
        else:
            st.markdown("""
            **üí° Tips:**
            - Higher network density indicates increased systemic risk
            - Critical nodes have the greatest impact on overall market stability
            - Contagion path analysis helps predict risk propagation
            """)

    def render_predictive_tab(self, market_data, earthquake_data, risk_assessment, lang):
        translations = TRANSLATIONS[lang]
        
        title = "üîÆ ‰∫àÊ∏¨ÂàÜÊûê„Ç®„É≥„Ç∏„É≥" if lang == 'jp' else "üîÆ Predictive Analytics Engine"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("üìñ „Åì„ÅÆ„Çø„Éñ„Å´„Å§„ÅÑ„Å¶"):
                st.markdown("""
                **‰∫àÊ∏¨ÂàÜÊûê„Ç®„É≥„Ç∏„É≥„Åß„ÅØ‰ª•‰∏ã„ÅÆÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„Åæ„ÅôÔºö**
                
                ü§ñ **Ê©üÊ¢∞Â≠¶Áøí„Å´„Çà„Çã‰∫àÊ∏¨**
                - **„É™„Çπ„ÇØ‰∫àÊ∏¨**: ‰ªäÂæå7Êó•Èñì„ÅÆ„É™„Çπ„ÇØ„É¨„Éô„É´„Çí‰∫àÊ∏¨
                - **„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£‰∫àÊ∏¨**: Â∏ÇÂ†¥„ÅÆ‰∏çÂÆâÂÆöÊÄß„Çí‰∫ãÂâç„Å´Ê§úÂá∫
                - **Áï∞Â∏∏Ê§úÁü•**: ÈÄöÂ∏∏„Å®„ÅØÁï∞„Å™„ÇãÂ∏ÇÂ†¥„Éë„Çø„Éº„É≥„ÇíÂç≥Â∫ß„Å´Ë≠òÂà•
                
                üìä **„Ç∑„Éä„É™„Ç™ÂàÜÊûê**
                - **ÈÄöÂ∏∏„Ç∑„Éä„É™„Ç™**: ÁèæÂú®„ÅÆÂ∏ÇÂ†¥Êù°‰ª∂„ÅåÁ∂ôÁ∂ö„Åô„ÇãÂ†¥Âêà
                - **Âú∞Èúá„Ç∑„Éä„É™„Ç™**: Â§ßË¶èÊ®°Âú∞ÈúáÁô∫ÁîüÊôÇ„ÅÆÂ∏ÇÂ†¥„Å∏„ÅÆÂΩ±Èüø
                - **Â∏ÇÂ†¥„ÇØ„É©„ÉÉ„Ç∑„É•**: ÊÄ•ÊøÄ„Å™Â∏ÇÂ†¥‰∏ãËêΩÊôÇ„ÅÆ„É™„Çπ„ÇØ
                - **Ë§áÂêàÂç±Ê©ü**: Âú∞Èúá„Å®Â∏ÇÂ†¥‰∏ãËêΩ„ÅåÂêåÊôÇÁô∫Áîü„Åó„ÅüÂ†¥Âêà
                
                üéØ **„É™„Çπ„ÇØÊåáÊ®ô**
                - **VaR (Value at Risk)**: 95%/99%‰ø°È†ºÂå∫Èñì„Åß„ÅÆ‰∫àÊÉ≥ÊúÄÂ§ßÊêçÂ§±
                - **Áï∞Â∏∏„Çπ„Ç≥„Ç¢**: ÁèæÂú®„ÅÆÂ∏ÇÂ†¥Áä∂Ê≥Å„ÅÆÁï∞Â∏∏Â∫¶
                - **‰ø°È†ºÂ∫¶**: ‰∫àÊ∏¨„É¢„Éá„É´„ÅÆÁ¢∫ÂÆüÊÄß„É¨„Éô„É´
                """)
        else:
            with st.expander("üìñ About This Tab"):
                st.markdown("""
                **The Predictive Analytics Engine provides:**
                
                ü§ñ **Machine Learning Predictions**
                - **Risk Forecasting**: 7-day ahead risk level predictions
                - **Volatility Forecasting**: Early detection of market instability
                - **Anomaly Detection**: Immediate identification of unusual market patterns
                
                üìä **Scenario Analysis**
                - **Normal Scenario**: Continuation of current market conditions
                - **Earthquake Scenario**: Market impact during major seismic events
                - **Market Crash**: Risk assessment during rapid market decline
                - **Combined Crisis**: Simultaneous earthquake and market crash scenarios
                
                üéØ **Risk Metrics**
                - **VaR (Value at Risk)**: Expected maximum loss at 95%/99% confidence
                - **Anomaly Score**: Degree of current market condition abnormality
                - **Confidence Level**: Prediction model certainty level
                """)
        
        try:
            features = self.predictive_engine.prepare_features(
                market_data, earthquake_data, risk_assessment
            )
            
            forecast_results = self.predictive_engine.forecast_risk(features, forecast_days=7)
            
            anomaly_results = self.predictive_engine.detect_anomalies(features)
            
            scenario_results = self.predictive_engine.generate_scenarios(features, num_scenarios=1000)
            
        except Exception as e:
            st.error(f"Error generating predictions: {str(e)}")
            forecast_results = {
                'current_risk_prediction': 0.3,
                'current_volatility_prediction': 0.2,
                'daily_forecasts': [],
                'model_confidence': 0.5
            }
            anomaly_results = {
                'is_anomaly': False,
                'anomaly_score': 0.1,
                'recommendation': "No anomalies detected"
            }
            scenario_results = {}
        
        st.markdown("---")
        st.markdown("#### üìà Current Risk Predictions" if lang == 'en' else "#### üìà ÁèæÂú®„ÅÆ„É™„Çπ„ÇØ‰∫àÊ∏¨")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            current_risk = forecast_results['current_risk_prediction']
            risk_pct = current_risk * 100
            
            if current_risk > 0.7:
                risk_color = THEME_COLORS['warning']
                risk_level = "HIGH" if lang == 'en' else "È´ò"
            elif current_risk > 0.4:
                risk_color = '#FF6B35'
                risk_level = "MEDIUM" if lang == 'en' else "‰∏≠"
            else:
                risk_color = THEME_COLORS['info']
                risk_level = "LOW" if lang == 'en' else "‰Ωé"
            
            st.markdown(f"""
            <div class="metric-container" style="border-left-color: {risk_color};">
                <h4>{"‰∫àÊ∏¨„É™„Çπ„ÇØ„É¨„Éô„É´" if lang == 'jp' else "Predicted Risk Level"}</h4>
                <h2>{risk_pct:.1f}%</h2>
                <p>{risk_level}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            current_vol = forecast_results['current_volatility_prediction']
            vol_pct = current_vol * 100
            
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"‰∫àÊ∏¨„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£" if lang == 'jp' else "Predicted Volatility"}</h4>
                <h2>{vol_pct:.1f}%</h2>
                <p>{"30Êó•Èñì‰∫àÊ∏¨" if lang == 'jp' else "30-day forecast"}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            confidence = forecast_results['model_confidence']
            confidence_pct = confidence * 100
            
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"„É¢„Éá„É´‰ø°È†ºÂ∫¶" if lang == 'jp' else "Model Confidence"}</h4>
                <h2>{confidence_pct:.0f}%</h2>
                <p>{"‰∫àÊ∏¨Á≤æÂ∫¶" if lang == 'jp' else "Prediction accuracy"}</p>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("#### üö® Anomaly Detection" if lang == 'en' else "#### üö® Áï∞Â∏∏Ê§úÁü•")
        
        if anomaly_results['is_anomaly']:
            anomaly_score = anomaly_results['anomaly_score']
            st.markdown(f"""
            <div class="risk-card risk-card-high">
                <h4>‚ö†Ô∏è {"Áï∞Â∏∏„ÅåÊ§úÂá∫„Åï„Çå„Åæ„Åó„Åü" if lang == 'jp' else "Anomaly Detected"}</h4>
                <p><strong>{"Áï∞Â∏∏„Çπ„Ç≥„Ç¢" if lang == 'jp' else "Anomaly Score"}:</strong> {anomaly_score:.2f}</p>
                <p><strong>{"Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥" if lang == 'jp' else "Recommendation"}:</strong> {anomaly_results['recommendation']}</p>
            </div>
            """, unsafe_allow_html=True)
            
            if anomaly_results.get('top_contributors'):
                st.write("**Top Contributing Factors:**" if lang == 'en' else "**‰∏ªË¶ÅË¶ÅÂõ†:**")
                for factor, value in anomaly_results['top_contributors']:
                    st.write(f"‚Ä¢ {factor}: {value:.3f}")
        else:
            st.markdown(f"""
            <div class="risk-card risk-card-low">
                <h4>‚úÖ {"Ê≠£Â∏∏„Å™Â∏ÇÂ†¥Áä∂Ê≥Å" if lang == 'jp' else "Normal Market Conditions"}</h4>
                <p>{anomaly_results['recommendation']}</p>
            </div>
            """, unsafe_allow_html=True)
        
        if forecast_results.get('daily_forecasts'):
            st.markdown("---")
            st.markdown("#### üìÖ 7-Day Risk Forecast" if lang == 'en' else "#### üìÖ 7Êó•Èñì„É™„Çπ„ÇØ‰∫àÊ∏¨")
            
            forecasts = forecast_results['daily_forecasts']
            dates = [f['date'] for f in forecasts]
            risks = [f['risk_score'] * 100 for f in forecasts]
            volatilities = [f['volatility'] * 100 for f in forecasts]
            
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=dates,
                y=risks,
                mode='lines+markers',
                name='Risk Level (%)' if lang == 'en' else '„É™„Çπ„ÇØ„É¨„Éô„É´ (%)',
                line=dict(color=THEME_COLORS['primary'], width=3),
                marker=dict(size=8)
            ))
            
            fig.add_trace(go.Scatter(
                x=dates,
                y=volatilities,
                mode='lines+markers',
                name='Volatility (%)' if lang == 'en' else '„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ (%)',
                line=dict(color=THEME_COLORS['secondary'], width=2, dash='dash'),
                marker=dict(size=6)
            ))
            
            fig.update_layout(
                title="Risk & Volatility Forecast" if lang == 'en' else "„É™„Çπ„ÇØ„Éª„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£‰∫àÊ∏¨",
                xaxis_title="Date" if lang == 'en' else "Êó•‰ªò",
                yaxis_title="Percentage %" if lang == 'en' else "„Éë„Éº„Çª„É≥„ÉÜ„Éº„Ç∏ %",
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color=THEME_COLORS['text_primary'],
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        if scenario_results:
            st.markdown("---")
            st.markdown("#### üé≤ Scenario Impact Analysis" if lang == 'en' else "#### üé≤ „Ç∑„Éä„É™„Ç™ÂΩ±ÈüøÂàÜÊûê")
            
            if lang == 'jp':
                st.info("üí° ÂêÑ„Ç∑„Éä„É™„Ç™„ÅåÂ∏ÇÂ†¥„Å´‰∏é„Åà„ÇãÂΩ±Èüø„Çí1000Âõû„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„ÅßÂàÜÊûê„Åó„Åæ„Åô„ÄÇ„É™„Çπ„ÇØ„Çπ„Ç≥„Ç¢„ÅØÈÄöÂ∏∏0-1„ÅÆÁØÑÂõ≤„Åß„Åô„Åå„ÄÅÊ•µÁ´Ø„Å™„Ç∑„Éä„É™„Ç™„Åß„ÅØ1„ÇíË∂Ö„Åà„ÇãÂ†¥Âêà„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ")
            else:
                st.info("üí° Analysis of market impact under different scenarios using 1000 simulations. Risk scores typically range 0-1, but extreme scenarios may exceed 1.0.")
            
            scenario_names = {
                'normal': 'Normal Market' if lang == 'en' else 'ÈÄöÂ∏∏Â∏ÇÂ†¥',
                'earthquake': 'Major Earthquake' if lang == 'en' else 'Â§ßÂú∞ÈúáÁô∫Áîü',
                'market_crash': 'Market Crash' if lang == 'en' else 'Â∏ÇÂ†¥Êö¥ËêΩ',
                'combined_crisis': 'Combined Crisis' if lang == 'en' else 'Ë§áÂêàÂç±Ê©ü'
            }
            
            cols = st.columns(2)
            scenario_items = list(scenario_results.items())
            
            for i, (scenario_type, results) in enumerate(scenario_items):
                col = cols[i % 2]
                
                with col:
                    scenario_name = scenario_names[scenario_type]
                    mean_risk = results['mean_risk']
                    worst_case = results['worst_case']
                    prob_high_risk = results['probability_high_risk']
                    
                    if mean_risk > 0.7:
                        card_class = "risk-card-high"
                        icon = "üî¥"
                    elif mean_risk > 0.4:
                        card_class = "risk-card-medium"
                        icon = "üü°"
                    else:
                        card_class = "risk-card-low"
                        icon = "üü¢"
                    
                    avg_risk_pct = min(100, mean_risk * 100)  
                    worst_risk_pct = min(150, worst_case * 100)  
                    
                    if lang == 'jp':
                        st.markdown(f"""
                        <div class="risk-card {card_class}">
                            <h4>{icon} {scenario_name}</h4>
                            <p><strong>Âπ≥Âùá„É™„Çπ„ÇØ:</strong> {avg_risk_pct:.1f}%</p>
                            <p><strong>ÊúÄÊÇ™„Ç±„Éº„Çπ:</strong> {worst_risk_pct:.1f}%</p>
                            <p><strong>È´ò„É™„Çπ„ÇØÁ¢∫Áéá:</strong> {prob_high_risk*100:.0f}%</p>
                            <p><strong>„É™„Çπ„ÇØË©ï‰æ°:</strong> {"Ê•µÈ´ò" if mean_risk > 0.8 else "È´ò" if mean_risk > 0.6 else "‰∏≠" if mean_risk > 0.3 else "‰Ωé"}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        risk_level = "EXTREME" if mean_risk > 0.8 else "HIGH" if mean_risk > 0.6 else "MEDIUM" if mean_risk > 0.3 else "LOW"
                        st.markdown(f"""
                        <div class="risk-card {card_class}">
                            <h4>{icon} {scenario_name}</h4>
                            <p><strong>Average Risk:</strong> {avg_risk_pct:.1f}%</p>
                            <p><strong>Worst Case:</strong> {worst_risk_pct:.1f}%</p>
                            <p><strong>High Risk Probability:</strong> {prob_high_risk*100:.0f}%</p>
                            <p><strong>Risk Level:</strong> {risk_level}</p>
                        </div>
                        """, unsafe_allow_html=True)
            
            st.markdown("#### üìä Risk Distribution Comparison" if lang == 'en' else "#### üìä „É™„Çπ„ÇØÂàÜÂ∏ÉÊØîËºÉ")
            
            fig = go.Figure()
            
            scenarios = []
            low_risks = []    # 25th percentile
            avg_risks = []    # Mean
            high_risks = []   # 75th percentile
            extreme_risks = [] # 95th percentile
            
            for scenario_type, results in scenario_results.items():
                scenarios.append(scenario_names[scenario_type])
                
                mean_risk = results['mean_risk']
                std_risk = results['std_risk']
                
                low_risk = max(0, mean_risk - std_risk)
                high_risk = mean_risk + std_risk
                extreme_risk = results['var_95']
                
                low_risks.append(low_risk * 100)
                avg_risks.append(mean_risk * 100)
                high_risks.append(high_risk * 100)
                extreme_risks.append(min(150, extreme_risk * 100))  
            
            fig.add_trace(go.Bar(
                name='Low Risk Range' if lang == 'en' else '‰Ωé„É™„Çπ„ÇØÁØÑÂõ≤',
                x=scenarios,
                y=low_risks,
                marker_color=THEME_COLORS['success'],
                opacity=0.7
            ))
            
            fig.add_trace(go.Bar(
                name='Average Risk' if lang == 'en' else 'Âπ≥Âùá„É™„Çπ„ÇØ',
                x=scenarios,
                y=[avg - low for avg, low in zip(avg_risks, low_risks)],
                base=low_risks,
                marker_color=THEME_COLORS['info'],
                opacity=0.8
            ))
            
            fig.add_trace(go.Bar(
                name='High Risk Range' if lang == 'en' else 'È´ò„É™„Çπ„ÇØÁØÑÂõ≤',
                x=scenarios,
                y=[high - avg for high, avg in zip(high_risks, avg_risks)],
                base=avg_risks,
                marker_color=THEME_COLORS['secondary'],
                opacity=0.8
            ))
            
            fig.add_trace(go.Bar(
                name='Extreme Risk (95%)' if lang == 'en' else 'Ê•µÁ´Ø„É™„Çπ„ÇØ (95%)',
                x=scenarios,
                y=[ext - high for ext, high in zip(extreme_risks, high_risks)],
                base=high_risks,
                marker_color=THEME_COLORS['warning'],
                opacity=0.9
            ))
            
            fig.update_layout(
                title="Risk Level Ranges by Scenario" if lang == 'en' else "„Ç∑„Éä„É™„Ç™Âà•„É™„Çπ„ÇØ„É¨„Éô„É´ÁØÑÂõ≤",
                xaxis_title="Scenario" if lang == 'en' else "„Ç∑„Éä„É™„Ç™",
                yaxis_title="Risk Level %" if lang == 'en' else "„É™„Çπ„ÇØ„É¨„Éô„É´ %",
                barmode='stack',
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color=THEME_COLORS['text_primary'],
                height=400,
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("#### üéØ Key Insights" if lang == 'en' else "#### üéØ ÈáçË¶Å„Å™Ê¥ûÂØü")
            
            risks_sorted = sorted(scenario_results.items(), key=lambda x: x[1]['mean_risk'])
            safest_scenario = scenario_names[risks_sorted[0][0]]
            riskiest_scenario = scenario_names[risks_sorted[-1][0]]
            
            col1, col2 = st.columns(2)
            
            with col1:
                if lang == 'jp':
                    st.markdown(f"""
                    **üìà „É™„Çπ„ÇØÂàÜÊûêÁµêÊûú:**
                    - **ÊúÄ„ÇÇÂÆâÂÖ®:** {safest_scenario} ({risks_sorted[0][1]['mean_risk']*100:.1f}%)
                    - **ÊúÄ„ÇÇÂç±Èô∫:** {riskiest_scenario} ({risks_sorted[-1][1]['mean_risk']*100:.1f}%)
                    - **„É™„Çπ„ÇØÂÄçÁéá:** {risks_sorted[-1][1]['mean_risk']/risks_sorted[0][1]['mean_risk']:.1f}ÂÄç
                    """)
                else:
                    st.markdown(f"""
                    **üìà Risk Analysis Results:**
                    - **Safest Scenario:** {safest_scenario} ({risks_sorted[0][1]['mean_risk']*100:.1f}%)
                    - **Riskiest Scenario:** {riskiest_scenario} ({risks_sorted[-1][1]['mean_risk']*100:.1f}%)
                    - **Risk Multiplier:** {risks_sorted[-1][1]['mean_risk']/risks_sorted[0][1]['mean_risk']:.1f}x
                    """)
            
            with col2:
                avg_high_risk_prob = np.mean([r['probability_high_risk'] for r in scenario_results.values()])
                
                if lang == 'jp':
                    st.markdown(f"""
                    **‚ö†Ô∏è „É™„Çπ„ÇØË≠¶Âëä:**
                    - **È´ò„É™„Çπ„ÇØÂπ≥ÂùáÁ¢∫Áéá:** {avg_high_risk_prob*100:.0f}%
                    - **Ë§áÂêàÂç±Ê©ü„Åß„ÅÆÈ´ò„É™„Çπ„ÇØÁ¢∫Áéá:** {scenario_results['combined_crisis']['probability_high_risk']*100:.0f}%
                    - **Êé®Â•®:** {"„É™„Çπ„ÇØËªΩÊ∏õÁ≠ñ„ÇíÂÆüÊñΩ" if avg_high_risk_prob > 0.3 else "ÁèæÁä∂Áõ£Ë¶ñ„ÇíÁ∂ôÁ∂ö"}
                    """)
                else:
                    recommendation = "Implement risk mitigation" if avg_high_risk_prob > 0.3 else "Continue monitoring"
                    st.markdown(f"""
                    **‚ö†Ô∏è Risk Warning:**
                    - **Average High Risk Probability:** {avg_high_risk_prob*100:.0f}%
                    - **Combined Crisis High Risk:** {scenario_results['combined_crisis']['probability_high_risk']*100:.0f}%
                    - **Recommendation:** {recommendation}
                    """)
        
        st.markdown("---")
        st.markdown("#### üí° Insights & Recommendations" if lang == 'en' else "#### üí° Ê¥ûÂØü„Å®Êé®Â•®‰∫ãÈ†Ö")
        
        insights_col1, insights_col2 = st.columns(2)
        
        with insights_col1:
            if lang == 'jp':
                st.markdown("""
                **üìà ‰∫àÊ∏¨ÂàÜÊûê„ÅÆÊ¥ûÂØü:**
                - Âú∞ÈúáÊ¥ªÂãï„Å®Â∏ÇÂ†¥„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£„Å´„ÅØÁõ∏Èñ¢Èñ¢‰øÇ„Åå„ÅÇ„Çä„Åæ„Åô
                - ÈÄ±Êú´Ââç„ÅÆÈáëÊõúÊó•„Å´„É™„Çπ„ÇØ„ÅåÈ´ò„Åæ„ÇãÂÇæÂêë„Åå„ÅÇ„Çä„Åæ„Åô
                - Ë§áÂêàÂç±Ê©ü„Ç∑„Éä„É™„Ç™„Åß„ÅØÊêçÂ§±„ÅåÈùûÁ∑öÂΩ¢„Å´Â¢óÂä†„Åó„Åæ„Åô
                - Êó©ÊúüË≠¶Âëä„Ç∑„Çπ„ÉÜ„É†„Å´„Çà„Çä‰∫ãÂâçÂØæÁ≠ñ„ÅåÂèØËÉΩ„Åß„Åô
                """)
            else:
                st.markdown("""
                **üìà Predictive Analytics Insights:**
                - Seismic activity correlates with market volatility spikes
                - Risk tends to increase on Fridays before weekends
                - Combined crisis scenarios show non-linear loss amplification
                - Early warning systems enable proactive risk management
                """)
        
        with insights_col2:
            current_risk = forecast_results['current_risk_prediction']
            
            if current_risk > 0.7:
                if lang == 'jp':
                    recommendations = [
                        "„Éù„Ç∏„Ç∑„Éß„É≥„Çµ„Ç§„Ç∫„Çí50%ÂâäÊ∏õ",
                        "„Éò„ÉÉ„Ç∏Êà¶Áï•„ÇíÂº∑Âåñ",
                        "ÊµÅÂãïÊÄß„ÇíÁ¢∫‰øù",
                        "„Çπ„Éà„ÉÉ„Éó„É≠„ÇπÊ≥®Êñá„ÇíË®≠ÂÆö"
                    ]
                else:
                    recommendations = [
                        "Reduce position sizes by 50%",
                        "Strengthen hedging strategies",
                        "Ensure adequate liquidity",
                        "Set stop-loss orders"
                    ]
            elif current_risk > 0.4:
                if lang == 'jp':
                    recommendations = [
                        "„É™„Çπ„ÇØÁõ£Ë¶ñ„ÇíÂº∑Âåñ",
                        "ÂàÜÊï£ÊäïË≥á„ÇíÊ§úË®é",
                        "„Éú„É©„ÉÜ„Ç£„É™„ÉÜ„Ç£ÂØæÁ≠ñ„ÇíÊ∫ñÂÇô",
                        "ÂÆöÊúüÁöÑ„Å™„É™„Éê„É©„É≥„Çπ"
                    ]
                else:
                    recommendations = [
                        "Enhanced risk monitoring",
                        "Consider diversification",
                        "Prepare volatility strategies",
                        "Regular portfolio rebalancing"
                    ]
            else:
                if lang == 'jp':
                    recommendations = [
                        "ÈÄöÂ∏∏„ÅÆÊäïË≥áÊà¶Áï•„ÇíÁ∂ôÁ∂ö",
                        "Ê©ü‰ºö„ÇíÁ©çÊ•µÁöÑ„Å´Êé¢Á¥¢",
                        "„É™„Çπ„ÇØ‰∫àÁÆó„ÇíÊ¥ªÁî®",
                        "Êñ∞Ë¶è„Éù„Ç∏„Ç∑„Éß„É≥Ê§úË®é"
                    ]
                else:
                    recommendations = [
                        "Continue normal investment strategy",
                        "Actively seek opportunities",
                        "Utilize risk budget",
                        "Consider new positions"
                    ]
            
            st.markdown("**üéØ Recommended Actions:**" if lang == 'en' else "**üéØ Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥:**")
            for rec in recommendations:
                st.markdown(f"‚Ä¢ {rec}")

    def run(self):
        self.render_header()
        self.render_sidebar()
        self.render_alerts()
        self.render_overview_metrics()
        self.render_main_tabs()
        
        if st.session_state.auto_refresh:
            time.sleep(1)
            if (datetime.now() - st.session_state.last_update).seconds > 300:  
                st.session_state.last_update = datetime.now()
                st.rerun()

if __name__ == "__main__":
    dashboard = TokyoMarketDashboard()
    dashboard.run() 