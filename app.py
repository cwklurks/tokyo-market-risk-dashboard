"""
Tokyo Market Risk Dashboard
A Palantir Foundry-inspired risk management dashboard
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import requests
import yfinance as yf
from typing import Dict, List, Tuple
import time


from config import *
from data.market_data import MarketDataProvider
from data.earthquake_data import EarthquakeDataProvider
from analytics.risk_engine import RiskEngine
from analytics.black_scholes import BlackScholesEngine
from analytics.network_analysis import NetworkAnalysisEngine
from analytics.predictive_engine import PredictiveEngine
from ui.components import UIComponents

st.set_page_config(
    page_title="Tokyo Market Risk Dashboard",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown(f"""
<style>
    .stApp {{
        background-color: {THEME_COLORS['background']};
        color: {THEME_COLORS['text_primary']};
    }}
    
    .main-header {{
        background: linear-gradient(90deg, {THEME_COLORS['primary']}, {THEME_COLORS['secondary']});
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }}
    
    .risk-card {{
        background-color: {THEME_COLORS['surface']};
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid {THEME_COLORS['accent']};
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }}
    
    .risk-card-critical {{
        border-left-color: {THEME_COLORS['warning']};
    }}
    
    .risk-card-high {{
        border-left-color: #FF6B35;
    }}
    
    .risk-card-medium {{
        border-left-color: #F7931E;
    }}
    
    .risk-card-low {{
        border-left-color: {THEME_COLORS['success']};
    }}
    
    .metric-container {{
        background-color: {THEME_COLORS['surface']};
        padding: 1rem;
        border-radius: 8px;
        text-align: center;
        margin: 0.5rem;
    }}
    
    .sidebar .sidebar-content {{
        background-color: {THEME_COLORS['surface']};
    }}
    
    .stSelectbox > div > div {{
        background-color: {THEME_COLORS['surface']};
    }}
    
    h1, h2, h3 {{
        color: {THEME_COLORS['text_primary']};
    }}
    
    .decision-item {{
        background-color: {THEME_COLORS['surface']};
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 8px;
        border-left: 3px solid {THEME_COLORS['info']};
    }}
    
    .alert-banner {{
        background-color: {THEME_COLORS['warning']};
        color: white;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
        text-align: center;
        font-weight: bold;
    }}
</style>
""", unsafe_allow_html=True)

class TokyoMarketDashboard:
    def __init__(self):
        self.market_data = MarketDataProvider()
        self.earthquake_data = EarthquakeDataProvider()
        self.risk_engine = RiskEngine()
        self.bs_engine = BlackScholesEngine()
        self.network_engine = NetworkAnalysisEngine()
        self.predictive_engine = PredictiveEngine()
        self.ui = UIComponents()
        
        if 'language' not in st.session_state:
            st.session_state.language = 'en'
        if 'auto_refresh' not in st.session_state:
            st.session_state.auto_refresh = True
        if 'last_update' not in st.session_state:
            st.session_state.last_update = datetime.now()
        
        if 'shared_earthquake_data' not in st.session_state:
            st.session_state.shared_earthquake_data = None
        if 'shared_earthquake_risk' not in st.session_state:
            st.session_state.shared_earthquake_risk = None
    
    def get_shared_earthquake_data(self):
        current_minute = datetime.now().strftime('%Y%m%d_%H%M')
        
        if ('earthquake_cache_minute' not in st.session_state or 
            st.session_state.earthquake_cache_minute != current_minute or
            st.session_state.shared_earthquake_data is None):
            
            try:
                earthquake_data = self.earthquake_data.fetch_recent_earthquakes(limit=20)
                earthquake_risk = self.earthquake_data.assess_tokyo_risk(earthquake_data)
                
                st.session_state.shared_earthquake_data = earthquake_data
                st.session_state.shared_earthquake_risk = earthquake_risk
                st.session_state.earthquake_cache_minute = current_minute
                
            except Exception as e:
                if st.session_state.shared_earthquake_data is None:
                    st.session_state.shared_earthquake_data = []
                    st.session_state.shared_earthquake_risk = {
                        'risk_level': 'LOW', 
                        'max_magnitude': 0, 
                        'closest_distance': float('inf'), 
                        'all_events': [],
                        'tokyo_region_events': []
                    }
        
        return st.session_state.shared_earthquake_data, st.session_state.shared_earthquake_risk

    def render_header(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        st.markdown(f"""
        <div class="main-header">
            <h1>ğŸ¯ {translations['title']}</h1>
            <p style="font-size: 1.2rem; margin: 0;">{translations['subtitle']}</p>
            <p style="font-size: 0.9rem; margin: 0.5rem 0 0 0;">
                Last Updated: {st.session_state.last_update.strftime('%Y-%m-%d %H:%M:%S JST')}
            </p>
        </div>
        """, unsafe_allow_html=True)

    def render_sidebar(self):   
        with st.sidebar:
            st.markdown("### ğŸ›ï¸ Control Panel")
            
            lang_options = {"English": "en", "æ—¥æœ¬èª": "jp"}
            selected_lang = st.selectbox(
                "Language / è¨€èª",
                options=list(lang_options.keys()),
                index=0 if st.session_state.language == 'en' else 1
            )
            st.session_state.language = lang_options[selected_lang]
            
            lang = st.session_state.language
            
            st.markdown("---")
            
            st.session_state.auto_refresh = st.checkbox(
                "Auto Refresh", 
                value=st.session_state.auto_refresh
            )
            
            if st.button("ğŸ”„ Refresh Data"):
                st.cache_data.clear()  
                st.session_state.shared_earthquake_data = None
                st.session_state.shared_earthquake_risk = None
                if 'earthquake_cache_minute' in st.session_state:
                    del st.session_state.earthquake_cache_minute
                st.session_state.last_update = datetime.now()
                st.rerun()
            
            st.markdown("---")
            
            st.markdown("### ğŸ“Š Market Focus")
            
            if 'selected_markets' not in st.session_state:
                st.session_state.selected_markets = ["nikkei", "topix", "jpy_usd", "mitsubishi"]
            selected_tickers = st.multiselect(
                "Select Markets (Max 4)",
                options=list(TOKYO_TICKERS.keys()),
                default=st.session_state.selected_markets,
                max_selections=4,
                help="Choose up to 4 markets to focus on in your analysis"
            )
            
            st.session_state.selected_markets = selected_tickers
            
            if not selected_tickers:
                st.warning("Please select at least one market to analyze." if lang == 'en' else "åˆ†æã™ã‚‹å¸‚å ´ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§é¸æŠã—ã¦ãã ã•ã„ã€‚")
            
            st.caption(f"Selected: {len(selected_tickers)}/4 markets")
            
            st.markdown("---")
            
            st.markdown("### âš ï¸ Risk Thresholds")
            earthquake_threshold = st.slider(
                "Earthquake Alert (Magnitude)",
                min_value=3.0,
                max_value=9.0,
                value=5.5,
                step=0.1
            )
            
            volatility_threshold = st.slider(
                "Volatility Alert (%)",
                min_value=10,
                max_value=100,
                value=25,
                step=5
            )

    def render_alerts(self):
        current_time = datetime.now()
        if current_time.minute % 10 < 2:  
            st.markdown("""
            <div class="alert-banner">
                ğŸš¨ RISK ALERT: Elevated seismic activity detected in Tokyo Bay region. 
                Monitoring market correlation patterns.
            </div>
            """, unsafe_allow_html=True)

    def render_overview_metrics(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        try:
            earthquake_data, earthquake_risk = self.get_shared_earthquake_data()
            
            market_summary = {}
            try:
                market_summary = self.market_data.get_tokyo_market_summary()
            except Exception as e:
                st.warning("Market data temporarily unavailable, using cached data.")
            
            correlation_matrix = pd.DataFrame()
            
            risk_assessment = self.risk_engine.assess_integrated_risk(
                earthquake_risk, market_summary, correlation_matrix
            )
        except Exception as e:
            earthquake_data = []
            earthquake_risk = {'risk_level': 'LOW', 'max_magnitude': 0, 'closest_distance': float('inf'), 'all_events': []}
            risk_assessment = {
                'market_risk': {'level': 'LOW'},
                'correlation_risk': {'level': 'LOW', 'raw_metrics': {'mean_abs_correlation': 0.3}},
                'recommendations': []
            }
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            risk_level = earthquake_risk.get('risk_level', 'LOW')
            risk_colors = {'LOW': '#2D6A4F', 'MEDIUM': '#F7931E', 'HIGH': '#FF6B35', 'CRITICAL': '#E63946'}
            
            all_events = earthquake_risk.get('all_events', [])
            if all_events:
                display_magnitude = max([eq.get('magnitude', 0) for eq in all_events])
            else:
                display_magnitude = 0
            
            tokyo_events = earthquake_risk.get('tokyo_region_events', [])
            if tokyo_events:
                display_distance = min([eq.get('distance_from_tokyo', float('inf')) for eq in tokyo_events])
            else:
                display_distance = float('inf')
            
            if display_distance == float('inf'):
                distance_text = ">1000km"
            else:
                distance_text = f"{display_distance:.0f}km"
            
            st.markdown(f"""
            <div class="metric-container">
                <h3>ğŸŒ {translations['earthquake_risk']}</h3>
                <h2 style="color: {risk_colors.get(risk_level, '#778DA9')};">{translations.get(f'risk_{risk_level.lower()}', risk_level)}</h2>
                <p>M{display_magnitude:.1f} - {distance_text}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            market_risk_level = risk_assessment['market_risk']['level']
            nikkei_vol = self.market_data.calculate_volatility(TOKYO_TICKERS['nikkei']) * 100
            st.markdown(f"""
            <div class="metric-container">
                <h3>ğŸ“ˆ {translations['market_volatility']}</h3>
                <h2 style="color: {risk_colors.get(market_risk_level, '#778DA9')};">{translations.get(f'risk_{market_risk_level.lower()}', market_risk_level)}</h2>
                <p>Nikkei: {nikkei_vol:.1f}% (30d)</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            corr_risk_level = risk_assessment['correlation_risk']['level']
            mean_corr = risk_assessment['correlation_risk'].get('raw_metrics', {}).get('mean_abs_correlation', 0.42)
            st.markdown(f"""
            <div class="metric-container">
                <h3>ğŸ”— {translations['correlation_analysis']}</h3>
                <h2 style="color: {risk_colors.get(corr_risk_level, '#778DA9')};">{translations.get(f'risk_{corr_risk_level.lower()}', corr_risk_level)}</h2>
                <p>Avg: {mean_corr:.2f}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            decision_count = len(risk_assessment.get('recommendations', []))
            high_priority = len([r for r in risk_assessment.get('recommendations', []) if r.get('priority') == 'HIGH'])
            st.markdown(f"""
            <div class="metric-container">
                <h3>âš¡ {translations['decision_queue']}</h3>
                <h2 style="color: #E63946;">{high_priority}</h2>
                <p>{decision_count} Total Items</p>
            </div>
            """, unsafe_allow_html=True)

    def render_main_tabs(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        if lang == 'jp':
            tab_labels = [
                "ğŸ¯ ãƒªã‚¹ã‚¯æ¦‚è¦", 
                "ğŸ“Š å¸‚å ´åˆ†æ", 
                "ğŸŒ åœ°éœ‡ç›£è¦–", 
                "âš™ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒ³åˆ†æ", 
                "ğŸª æ„æ€æ±ºå®šæ”¯æ´",
                "ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ",
                "ğŸ”® äºˆæ¸¬åˆ†æ"
            ]
        else:
            tab_labels = [
                "ğŸ¯ Risk Overview", 
                "ğŸ“Š Market Analysis", 
                "ğŸŒ Earthquake Monitor", 
                "âš™ï¸ Options Analytics", 
                "ğŸª Decision Support",
                "ğŸ•¸ï¸ Network Analysis",
                "ğŸ”® Predictive Analytics"
            ]
        
        tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(tab_labels)
        
        with tab1:
            self.render_risk_overview_tab()
        
        with tab2:
            self.render_market_analysis_tab()
        
        with tab3:
            self.render_earthquake_tab()
        
        with tab4:
            self.render_options_tab()
        
        with tab5:
            self.render_decision_tab()
            
        with tab6:
            self.render_network_analysis_tab()
        
        with tab7:
            earthquake_data, earthquake_risk = self.get_shared_earthquake_data()
            market_data = self.market_data.get_tokyo_market_summary()
            risk_assessment = self.risk_engine.assess_integrated_risk(
                earthquake_risk, market_data, pd.DataFrame()
            )
            lang = st.session_state.language
            self.render_predictive_tab(market_data, earthquake_data, risk_assessment, lang)

    def render_risk_overview_tab(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "ğŸ¯ çµ±åˆãƒªã‚¹ã‚¯è©•ä¾¡" if lang == 'jp' else "ğŸ¯ Integrated Risk Assessment"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("ğŸ“– ã“ã®ã‚¿ãƒ–ã«ã¤ã„ã¦"):
                st.markdown("""
                **çµ±åˆãƒªã‚¹ã‚¯è©•ä¾¡ã‚¿ãƒ–ã§ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š**
                
                ğŸ” **ç·åˆãƒªã‚¹ã‚¯åˆ†æ**
                - **åœ°éœ‡ãƒªã‚¹ã‚¯**: æœ€è¿‘7æ—¥é–“ã®åœ°éœ‡æ´»å‹•ï¼ˆãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰ã€è·é›¢ã€é »åº¦ï¼‰ã‚’åˆ†æ
                - **å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£**: å„å¸‚å ´ã®30æ—¥é–“ã®ä¾¡æ ¼å¤‰å‹•å¹…ã‚’è¨ˆç®—ï¼ˆé«˜ã„ã»ã©ãƒªã‚¹ã‚¯å¤§ï¼‰
                - **ç›¸é–¢ãƒªã‚¹ã‚¯**: å¸‚å ´é–“ã®é€£å‹•æ€§ã‚’æ¸¬å®šï¼ˆåŒæ™‚ã«å‹•ãå‚¾å‘ãŒé«˜ã„ã¨ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯å¢—å¤§ï¼‰
                - **æœ€çµ‚ã‚¹ã‚³ã‚¢**: 3ã¤ã®ãƒªã‚¹ã‚¯ã‚’é‡ã¿ä»˜ã‘ã—ã¦çµ±åˆï¼ˆåœ°éœ‡40%ã€å¸‚å ´35%ã€ç›¸é–¢25%ï¼‰
                
                ğŸ“Š **å¸‚å ´ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ - èª­ã¿æ–¹**
                - **æ•°å€¤ã®æ„å‘³**: -1.0ï½+1.0ã®ç¯„å›²ã§å¸‚å ´é–“ã®é€£å‹•æ€§ã‚’è¡¨ç¤º
                  - **+1.0**: å®Œå…¨ã«åŒã˜æ–¹å‘ã«å‹•ãï¼ˆä¸€æ–¹ãŒä¸ŠãŒã‚‹ã¨ä»–æ–¹ã‚‚å¿…ãšä¸ŠãŒã‚‹ï¼‰
                  - **0.0**: å…¨ãé–¢ä¿‚ãªãå‹•ãï¼ˆç‹¬ç«‹ï¼‰
                  - **-1.0**: å®Œå…¨ã«é€†æ–¹å‘ã«å‹•ãï¼ˆä¸€æ–¹ãŒä¸ŠãŒã‚‹ã¨ä»–æ–¹ã¯å¿…ãšä¸‹ãŒã‚‹ï¼‰
                - **è‰²ã®æ„å‘³**: 
                  - **èµ¤è‰²**: å¼·ã„æ­£ã®ç›¸é–¢ï¼ˆ0.7ä»¥ä¸Šï¼‰- åŒæ™‚ã«æš´è½ã™ã‚‹ãƒªã‚¹ã‚¯
                  - **é’è‰²**: å¼·ã„è² ã®ç›¸é–¢ï¼ˆ-0.7ä»¥ä¸‹ï¼‰- åˆ†æ•£åŠ¹æœã‚ã‚Š
                  - **ç™½è‰²**: ä½ç›¸é–¢ï¼ˆ-0.3ï½+0.3ï¼‰- ç‹¬ç«‹æ€§ãŒé«˜ã„
                - **å®Ÿä¾‹**: æ—¥çµŒã¨TOPIXãŒ0.9ã®å ´åˆã€æ—¥çµŒãŒ1%ä¸‹è½ã™ã‚‹ã¨ TOPIXã‚‚ç´„0.9%ä¸‹è½ã™ã‚‹å‚¾å‘
                
                ğŸ“ˆ **ãƒªã‚¹ã‚¯ã‚«ãƒ¼ãƒ‰è©³ç´°**
                - **åœ°éœ‡ãƒªã‚¹ã‚¯**: æ±äº¬ã‹ã‚‰100kmä»¥å†…ã®M5.0ä»¥ä¸Šã§ã€Œä¸­ã€ã€M7.0ä»¥ä¸Šã§ã€Œé«˜ã€
                - **å¸‚å ´ãƒªã‚¹ã‚¯**: 30æ—¥ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ25%è¶…ã§ã€Œä¸­ã€ã€40%è¶…ã§ã€Œé«˜ã€
                - **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: å…·ä½“çš„ãªæŠ•è³‡æˆ¦ç•¥ï¼ˆãƒã‚¸ã‚·ãƒ§ãƒ³ç¸®å°ã€ãƒ˜ãƒƒã‚¸è¿½åŠ ç­‰ï¼‰
                
                ğŸ“‹ **è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹**
                - **VaRè¨ˆç®—**: 95%ä¿¡é ¼åŒºé–“ã§ã®æœ€å¤§äºˆæƒ³æå¤±é¡
                - **ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ**: åœ°éœ‡ç™ºç”Ÿæ™‚ã®å¸‚å ´å½±éŸ¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                - **æ™‚ç³»åˆ—äºˆæ¸¬**: ä»Šå¾Œ7æ—¥é–“ã®ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«äºˆæ¸¬
                """)
        else:
            with st.expander("ğŸ“– About This Tab"):
                st.markdown("""
                **The Integrated Risk Assessment tab provides:**
                
                ğŸ” **Comprehensive Risk Analysis Explained**
                - **Earthquake Risk**: Analyzes last 7 days of seismic activity (magnitude, distance, frequency)
                - **Market Volatility**: Calculates 30-day price fluctuation range for each market (higher = more risk)
                - **Correlation Risk**: Measures how markets move together (high correlation = systemic risk)
                - **Final Score**: Weighted combination of 3 risks (earthquake 40%, market 35%, correlation 25%)
                
                ğŸ“Š **Market Correlation Matrix - How to Read**
                - **Number Meaning**: Scale from -1.0 to +1.0 showing how markets move together
                  - **+1.0**: Perfect positive correlation (when one goes up 1%, other goes up 1%)
                  - **0.0**: No relationship (markets move independently)
                  - **-1.0**: Perfect negative correlation (when one goes up 1%, other goes down 1%)
                - **Color Coding**:
                  - **Red**: Strong positive correlation (0.7+) - crash together risk
                  - **Blue**: Strong negative correlation (-0.7+) - diversification benefit
                  - **White**: Low correlation (-0.3 to +0.3) - good independence
                - **Real Example**: If Nikkei-TOPIX shows 0.9, when Nikkei drops 1%, TOPIX typically drops ~0.9%
                
                ğŸ“ˆ **Risk Cards Detailed**
                - **Earthquake Risk**: "Medium" for M5.0+ within 100km of Tokyo, "High" for M7.0+
                - **Market Risk**: "Medium" for 30-day volatility >25%, "High" for >40%
                - **Recommendations**: Specific investment actions (reduce positions, add hedges, etc.)
                
                ğŸ“‹ **Detailed Report Contents**
                - **VaR Calculations**: Maximum expected loss at 95% confidence level
                - **Stress Testing**: Market impact simulations during earthquake scenarios
                - **Time Series Forecasting**: 7-day ahead risk level predictions
                """)
        
        try:
            earthquake_data, earthquake_risk = self.get_shared_earthquake_data()
            market_summary = self.market_data.get_tokyo_market_summary()
            
            correlation_matrix = pd.DataFrame(np.random.rand(3, 3), 
                                            columns=['Nikkei', 'TOPIX', 'JPY'],
                                            index=['Nikkei', 'TOPIX', 'JPY'])
            
            risk_assessment = self.risk_engine.assess_integrated_risk(
                earthquake_risk, market_summary, correlation_matrix
            )
        except Exception as e:
            earthquake_risk = {'risk_level': 'LOW', 'max_magnitude': 0, 'recent_activity': 0}
            risk_assessment = {
                'market_risk': {'level': 'LOW'},
                'correlation_risk': {'level': 'LOW'},
                'recommendations': []
            }
        
        if not correlation_matrix.empty:
            fig = px.imshow(
                correlation_matrix,
                labels=dict(x="Markets" if lang == 'en' else "å¸‚å ´", 
                           y="Markets" if lang == 'en' else "å¸‚å ´", 
                           color="Correlation" if lang == 'en' else "ç›¸é–¢"),
                color_continuous_scale="RdYlBu_r"
            )
            title_text = "Market Correlation Matrix" if lang == 'en' else "å¸‚å ´ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹"
        else:
            mock_data = np.random.rand(5, 5)
            risk_factors = ["Earthquake", "Typhoon", "Transit", "Political", "Global"] if lang == 'en' else ["åœ°éœ‡", "å°é¢¨", "äº¤é€š", "æ”¿æ²»", "ã‚°ãƒ­ãƒ¼ãƒãƒ«"]
            market_segments = ["Nikkei", "TOPIX", "JPY", "Bonds", "Real Estate"] if lang == 'en' else ["æ—¥çµŒ", "TOPIX", "å††", "å‚µåˆ¸", "ä¸å‹•ç”£"]
            
            fig = px.imshow(
                mock_data,
                labels=dict(x="Risk Factors" if lang == 'en' else "ãƒªã‚¹ã‚¯è¦å› ", 
                           y="Market Segments" if lang == 'en' else "å¸‚å ´ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ", 
                           color="Correlation" if lang == 'en' else "ç›¸é–¢"),
                x=risk_factors,
                y=market_segments,
                color_continuous_scale="RdYlBu_r"
            )
            title_text = "Risk Factor Correlation Matrix" if lang == 'en' else "ãƒªã‚¹ã‚¯è¦å› ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹"
        
        fig.update_layout(
            title=title_text,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color=THEME_COLORS['text_primary']
        )
        st.plotly_chart(fig, use_container_width=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            eq_risk_level = earthquake_risk.get('risk_level', 'LOW')
            eq_css_class = f"risk-card-{eq_risk_level.lower()}"
            if lang == 'jp':
                eq_content = f"""
                <div class="risk-card {eq_css_class}">
                    <h4>ğŸŒ åœ°éœ‡ãƒªã‚¹ã‚¯</h4>
                    <p><strong>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:</strong> {translations.get(f'risk_{eq_risk_level.lower()}', eq_risk_level)}</p>
                    <p><strong>æœ€è¿‘ã®æ´»å‹•:</strong> {earthquake_risk.get('recent_activity', 0)}ä»¶ (7æ—¥é–“)</p>
                    <p><strong>æœ€å¤§ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰:</strong> M{earthquake_risk.get('max_magnitude', 0):.1f}</p>
                    <p><strong>æ¨å¥¨:</strong> REITã‚»ã‚¯ã‚¿ãƒ¼ã®ç›£è¦–ã‚’å¼·åŒ–</p>
                </div>
                """
            else:
                eq_content = f"""
                <div class="risk-card {eq_css_class}">
                    <h4>ğŸŒ Earthquake Risk</h4>
                    <p><strong>Status:</strong> {eq_risk_level}</p>
                    <p><strong>Recent Activity:</strong> {earthquake_risk.get('recent_activity', 0)} events (7d)</p>
                    <p><strong>Max Magnitude:</strong> M{earthquake_risk.get('max_magnitude', 0):.1f}</p>
                    <p><strong>Recommendation:</strong> Enhanced REIT sector monitoring</p>
                </div>
                """
            st.markdown(eq_content, unsafe_allow_html=True)
        
        with col2:
            market_risk_level = risk_assessment['market_risk']['level']
            market_css_class = f"risk-card-{market_risk_level.lower()}"
            if lang == 'jp':
                market_content = f"""
                <div class="risk-card {market_css_class}">
                    <h4>ğŸ“Š å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£</h4>
                    <p><strong>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:</strong> {translations.get(f'risk_{market_risk_level.lower()}', market_risk_level)}</p>
                    <p><strong>åˆ†æå¸‚å ´æ•°:</strong> {risk_assessment['market_risk'].get('processed_markets', 0)}</p>
                    <p><strong>ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¦å› :</strong> {risk_assessment['market_risk']['factors']['volatility']:.3f}</p>
                    <p><strong>æ¨å¥¨:</strong> ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºã®èª¿æ•´</p>
                </div>
                """
            else:
                market_content = f"""
                <div class="risk-card {market_css_class}">
                    <h4>ğŸ“Š Market Volatility</h4>
                    <p><strong>Status:</strong> {market_risk_level}</p>
                    <p><strong>Markets Analyzed:</strong> {risk_assessment['market_risk'].get('processed_markets', 0)}</p>
                    <p><strong>Volatility Factor:</strong> {risk_assessment['market_risk']['factors']['volatility']:.3f}</p>
                    <p><strong>Recommendation:</strong> Adjust position sizing</p>
                </div>
                """
            st.markdown(market_content, unsafe_allow_html=True)
        
        st.markdown("---")
        summary_title = "ç·åˆãƒªã‚¹ã‚¯ã‚µãƒãƒªãƒ¼" if lang == 'jp' else "Overall Risk Summary"
        st.markdown(f"### {summary_title}")
        
        combined_risk = risk_assessment['combined_risk']
        risk_report = self.risk_engine.generate_risk_report(risk_assessment)
        
        if lang == 'jp':
            with st.expander("è©³ç´°ãƒªã‚¹ã‚¯ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"):
                st.text(risk_report)
        else:
            with st.expander("View Detailed Risk Report"):
                st.text(risk_report)

    def render_market_analysis_tab(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "ğŸ“Š æ±äº¬å¸‚å ´åˆ†æ" if lang == 'jp' else "ğŸ“Š Tokyo Market Analysis"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("ğŸ“– ã“ã®ã‚¿ãƒ–ã«ã¤ã„ã¦"):
                st.markdown("""
                **å¸‚å ´åˆ†æã‚¿ãƒ–ã§ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š**
                
                ğŸ’¹ **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°**
                - **ç¾åœ¨ä¾¡æ ¼**: æœ€æ–°ã®å–å¼•ä¾¡æ ¼ï¼ˆé…å»¶ç´„15åˆ†ï¼‰
                - **å¤‰å‹•ç‡**: å‰æ—¥çµ‚å€¤ã‹ã‚‰ã®å¤‰åŒ–ç‡ï¼ˆä¾‹ï¼š+2.5%ã¯å‰æ—¥æ¯”2.5%ä¸Šæ˜‡ï¼‰
                - **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£**: 30æ—¥é–“ã®æ—¥æ¬¡å¤‰å‹•ç‡ã®æ¨™æº–åå·®Ã—âˆš252ã§å¹´ç‡æ›ç®—
                  - **15%æœªæº€**: ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å®šï¼‰
                  - **15-25%**: é€šå¸¸ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                  - **25%è¶…**: é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆãƒªã‚¹ã‚¯å¤§ï¼‰
                - **ãƒ‡ãƒ¼ã‚¿æ›´æ–°**: 5åˆ†é–“éš”ã§è‡ªå‹•æ›´æ–°ã€APIéšœå®³æ™‚ã¯æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                
                ğŸ“ˆ **ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰ãƒãƒ£ãƒ¼ãƒˆ**
                - 30æ—¥é–“ã®ä¾¡æ ¼æ¨ç§»ã‚’è¦–è¦šåŒ–
                - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒ£ãƒ¼ãƒˆé¸æŠæ©Ÿèƒ½
                
                ğŸ“Š **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ**
                - å„å¸‚å ´ã®30æ—¥ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¯”è¼ƒ
                - ãƒªã‚¹ã‚¯è©•ä¾¡ã®ãŸã‚ã®çµ±è¨ˆåˆ†æ
                
                ğŸ”„ **å¸‚å ´ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**
                - æ±äº¬è¨¼åˆ¸å–å¼•æ‰€ã®é–‹å ´çŠ¶æ³
                - VIXç›¸å½“æŒ‡æ•°ã¨ãƒ•ã‚£ã‚¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                
                **ä½¿ç”¨æ–¹æ³•ï¼š** ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æœ€å¤§4ã¤ã®å¸‚å ´ã‚’é¸æŠã—ã¦åˆ†æã§ãã¾ã™ã€‚
                """)
        else:
            with st.expander("ğŸ“– About This Tab"):
                st.markdown("""
                **The Market Analysis tab provides:**
                
                ğŸ’¹ **Real-time Market Data**
                - Current prices, changes, and volatility for selected markets
                - Auto-refresh and error handling capabilities
                
                ğŸ“ˆ **Price Trend Charts**
                - 30-day price movement visualization
                - Interactive chart selection functionality
                
                ğŸ“Š **Volatility Analysis**
                - 30-day volatility comparison across markets
                - Statistical analysis for risk assessment
                
                ğŸ”„ **Market Status**
                - Tokyo Stock Exchange trading hours status
                - VIX equivalent and fear index metrics
                
                **How to use:** Select up to 4 markets in the sidebar for analysis.
                """)
        
        selected_markets = st.session_state.get('selected_markets', ['nikkei', 'topix', 'jpy_usd', 'mitsubishi'])
        
        if not selected_markets:
            st.warning("Please select markets in the sidebar to analyze." if lang == 'en' else "åˆ†æã™ã‚‹å¸‚å ´ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§é¸æŠã—ã¦ãã ã•ã„ã€‚")
            return
        
        with st.spinner("Loading market data..." if lang == 'en' else "å¸‚å ´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
            try:
                market_summary = self.market_data.get_tokyo_market_summary()
                
                for market_key in selected_markets:
                    if market_key not in market_summary or not market_summary[market_key]:
                        ticker = TOKYO_TICKERS.get(market_key)
                        if ticker:
                            individual_data = self.market_data.get_real_time_data(ticker)
                            if individual_data:
                                individual_data['volatility'] = self.market_data.calculate_volatility(ticker)
                                market_summary[market_key] = individual_data
                
            except Exception as e:
                st.error(f"Unable to load market data: {str(e)}")
                return
        
        st.markdown("#### ğŸ“ˆ Market Overview" if lang == 'en' else "#### ğŸ“ˆ å¸‚å ´æ¦‚è¦")
        
        num_markets = len(selected_markets)
        if num_markets <= 2:
            cols = st.columns(num_markets)
        elif num_markets <= 4:
            cols = st.columns(2)
        else:
            cols = st.columns(3)
        
        market_display_names = {
            "nikkei": "Nikkei 225",
            "topix": "TOPIX",
            "jpy_usd": "JPY/USD",
            "jpy_eur": "EUR/JPY",
            "sony": "Sony ADR",
            "toyota": "Toyota ADR",
            "softbank": "SoftBank",
            "nintendo": "Nintendo ADR",
            "mitsubishi": "Mitsubishi"
        }

        for i, market_key in enumerate(selected_markets):
            col_index = i % len(cols)
            with cols[col_index]:
                market_data = market_summary.get(market_key, {})
                
                if not market_data or market_data.get('current_price', 0) == 0:
                    ticker = TOKYO_TICKERS.get(market_key)
                    if ticker:
                        fresh_data = self.market_data.get_real_time_data(ticker)
                        if fresh_data:
                            fresh_data['volatility'] = self.market_data.calculate_volatility(ticker)
                            market_data = fresh_data
                
                price = market_data.get('current_price', 0)
                change_pct = market_data.get('change_percent', 0)
                volatility = market_data.get('volatility', 0.25) * 100
                
                if 'jpy' in market_key.lower() or 'usd' in market_key.lower() or 'eur' in market_key.lower():
                    formatted_price = f"{price:.3f}" if price > 0 else "Loading..."
                elif price >= 1000:
                    formatted_price = f"{price:,.0f}"
                else:
                    formatted_price = f"{price:.2f}" if price > 0 else "Loading..."
                
                change_color = "ğŸŸ¢" if change_pct > 0 else "ğŸ”´" if change_pct < 0 else "âšª"
                delta_str = f"{change_pct:+.2f}%" if change_pct != 0 else "0.00%"
                
                display_name = market_display_names.get(market_key, market_key.upper())
                
                card_html = f"""
                <div class="metric-container" style="margin-bottom: 1rem;">
                    <h4 style="margin: 0; color: {THEME_COLORS['text_primary']};">{display_name}</h4>
                    <h2 style="margin: 0.5rem 0; color: {THEME_COLORS['accent']};">{formatted_price}</h2>
                    <p style="margin: 0; font-size: 0.9rem;">{change_color} {delta_str}</p>
                    <p style="margin: 0; font-size: 0.8rem; color: {THEME_COLORS['text_secondary']};">Vol: {volatility:.1f}%</p>
                </div>
                """
                st.markdown(card_html, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("#### ğŸ“Š Price Trends" if lang == 'en' else "#### ğŸ“Š ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰")
        
        if selected_markets:
            chart_market = st.selectbox(
                "Select market for chart:" if lang == 'en' else "ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºå¸‚å ´:",
                options=selected_markets,
                format_func=lambda x: market_display_names.get(x, x.upper()),
                index=0
            )
            
            ticker_symbol = TOKYO_TICKERS.get(chart_market)
            if ticker_symbol:
                hist_data = self.market_data.get_historical_data(ticker_symbol, period="1mo")
                
                if not hist_data.empty:
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=hist_data.index, 
                        y=hist_data['Close'],
                        mode='lines',
                        name=market_display_names.get(chart_market, chart_market.upper()),
                        line=dict(color=THEME_COLORS['accent'], width=2)
                    ))
                    
                    display_name = market_display_names.get(chart_market, chart_market.upper())
                    fig.update_layout(
                        title=f"{display_name} - 30 Day Trend",
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)',
                        font_color=THEME_COLORS['text_primary'],
                        xaxis=dict(gridcolor=THEME_COLORS['secondary']),
                        yaxis=dict(gridcolor=THEME_COLORS['secondary']),
                        height=400
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        st.markdown("#### ğŸ“ˆ Volatility Analysis" if lang == 'en' else "#### ğŸ“ˆ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ")
        
        vol_data = []
        for market_key in selected_markets:
            if market_key in market_summary and market_summary[market_key]:
                vol = market_summary[market_key].get('volatility', 0.25) * 100
                vol_data.append({
                    'Market': market_display_names.get(market_key, market_key.upper()),
                    'Volatility': vol
                })
        
        if vol_data:
            vol_df = pd.DataFrame(vol_data)
            fig = px.bar(
                vol_df, 
                x='Market', 
                y='Volatility',
                title="30-Day Volatility Comparison",
                color='Volatility',
                color_continuous_scale='Reds'
            )
            fig.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color=THEME_COLORS['text_primary'],
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        col1, col2 = st.columns(2)
        
        with col1:
            market_open = self.market_data.is_market_open()
            status_text = "Market Open" if market_open else "Market Closed"
            status_color = "ğŸŸ¢" if market_open else "ğŸ”´"
            st.metric("Market Status", f"{status_color} {status_text}")
        
        with col2:
            vix_equiv = self.market_data.get_vix_equivalent()   
            market_summary = self.market_data.get_tokyo_market_summary()
            has_live_data = any(data.get('is_live', False) for data in market_summary.values())
            status_indicator = "ğŸŸ¢ Live" if has_live_data else "ğŸŸ¡ Cached"
            st.metric("Fear Index (VIX Equiv.)", f"{vix_equiv:.1f}", help=f"Data Status: {status_indicator}")

    def render_earthquake_tab(self):
        """Render the earthquake monitoring tab"""
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "ğŸŒ åœ°éœ‡ãƒªã‚¹ã‚¯ç›£è¦–" if lang == 'jp' else "ğŸŒ Earthquake Risk Monitor"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("ğŸ“– ã“ã®ã‚¿ãƒ–ã«ã¤ã„ã¦"):
                st.markdown("""
                **åœ°éœ‡ç›£è¦–ã‚¿ãƒ–ã§ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š**
                
                ğŸŒ‹ **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åœ°éœ‡ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°**
                - **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: P2PQuake APIï¼ˆæ°—è±¡åºç™ºè¡¨ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«æ›´æ–°ï¼‰
                - **æ›´æ–°é »åº¦**: æ–°ã—ã„åœ°éœ‡ç™ºç”Ÿæ™‚ã«å³åº§ã«åæ˜ ï¼ˆé€šå¸¸æ•°åˆ†ä»¥å†…ï¼‰
                - **è¡¨ç¤ºé …ç›®**:
                  - **ç™ºç”Ÿæ™‚åˆ»**: JSTï¼ˆæ—¥æœ¬æ¨™æº–æ™‚ï¼‰ã§è¡¨ç¤º
                  - **ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰**: M3.0ä»¥ä¸Šã®åœ°éœ‡ã‚’è¡¨ç¤ºï¼ˆM5.0ä»¥ä¸Šã¯å¤ªå­—ï¼‰
                  - **éœ‡æºåœ°**: å…·ä½“çš„ãªåœ°åŸŸåï¼ˆä¾‹ï¼šåƒè‘‰çœŒæ±æ–¹æ²–ï¼‰
                  - **éœ‡æºæ·±ã•**: kmå˜ä½ï¼ˆæµ…ã„ã»ã©åœ°è¡¨ã¸ã®å½±éŸ¿å¤§ï¼‰
                  - **æ±äº¬è·é›¢**: çš‡å±…ã‹ã‚‰ã®ç›´ç·šè·é›¢ã‚’è‡ªå‹•è¨ˆç®—
                
                âš ï¸ **ãƒªã‚¹ã‚¯ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆè©•ä¾¡åŸºæº–**
                - **LOWï¼ˆä½ï¼‰**: M5.0æœªæº€ã¾ãŸã¯æ±äº¬ã‹ã‚‰150kmè¶…
                - **MEDIUMï¼ˆä¸­ï¼‰**: M5.0-6.9ã‹ã¤æ±äº¬ã‹ã‚‰50-150km
                - **HIGHï¼ˆé«˜ï¼‰**: M7.0-7.9ã‹ã¤æ±äº¬ã‹ã‚‰100kmä»¥å†…
                - **CRITICALï¼ˆç·Šæ€¥ï¼‰**: M8.0ä»¥ä¸Šã¾ãŸã¯æ±äº¬ã‹ã‚‰30kmä»¥å†…
                - **è©•ä¾¡æœŸé–“**: éå»7æ—¥é–“ã®åœ°éœ‡æ´»å‹•ã‚’é‡ã¿ä»˜ã‘åˆ†æ
                - **è·é›¢æ¸›è¡°**: éœ‡æºè·é›¢ãŒ2å€ã«ãªã‚‹ã¨å½±éŸ¿ã¯1/4ã«æ¸›å°‘
                
                ğŸ“Š **å¸‚å ´ç›¸é–¢åˆ†æã®å®Ÿç”¨çš„è§£é‡ˆ**
                - **æ—¥çµŒ225ç›¸é–¢ï¼ˆ-0.15ï¼‰**: å¤§åœ°éœ‡æ™‚ã«å¹³å‡15%ä¸‹è½å‚¾å‘
                - **REITç›¸é–¢ï¼ˆ-0.35ï¼‰**: ä¸å‹•ç”£æŠ•è³‡ä¿¡è¨—ã¯åœ°éœ‡ã«æœ€ã‚‚æ•æ„Ÿ
                  - **ç†ç”±**: ç‰©ç†çš„è³‡ç”£ã¸ã®ç›´æ¥å½±éŸ¿æ‡¸å¿µ
                  - **å®Ÿä¾‹**: æ±æ—¥æœ¬å¤§éœ‡ç½æ™‚ã«ä¸å‹•ç”£REITã¯30%ä»¥ä¸Šä¸‹è½
                - **å††ç›¸é–¢ï¼ˆ+0.08ï¼‰**: åœ°éœ‡æ™‚ã«å††ãŒè‹¥å¹²å¼·ããªã‚‹å‚¾å‘
                  - **ç†ç”±**: å¾©èˆˆéœ€è¦ã¨æµ·å¤–è³‡æœ¬ã®æœ¬å›½é€é‚„
                - **ä¿é™ºç›¸é–¢ï¼ˆ-0.45ï¼‰**: ä¿é™ºä¼šç¤¾ã¯åœ°éœ‡ã§å¤§ããå½±éŸ¿
                  - **ç†ç”±**: åœ°éœ‡ä¿é™ºã®æ”¯æ‰•ã„ç¾©å‹™å¢—å¤§
                - **å…¬ç›Šäº‹æ¥­ç›¸é–¢ï¼ˆ-0.25ï¼‰**: ã‚¤ãƒ³ãƒ•ãƒ©è¢«å®³ã«ã‚ˆã‚‹å–¶æ¥­åœæ­¢ãƒªã‚¹ã‚¯
                
                ğŸ“ˆ **éå»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã®æ´»ç”¨æ³•**
                - **çµ±è¨ˆæœŸé–“**: 30æ—¥é–“ã®åœ°éœ‡æ´»å‹•ã‚’åˆ†æ
                - **ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰åˆ†å¸ƒ**: 
                  - **M3-4**: æ—¥å¸¸çš„ç™ºç”Ÿï¼ˆæœˆ20-30å›ï¼‰
                  - **M4-5**: é€±1-2å›ç¨‹åº¦
                  - **M5-6**: æœˆ1-2å›ç¨‹åº¦
                  - **M6è¶…**: æ•°ãƒ¶æœˆã«1å›ï¼ˆè¦æ³¨æ„ãƒ¬ãƒ™ãƒ«ï¼‰
                - **åœ°åŸŸåˆ¥é »åº¦**: é–¢æ±ãƒ»æ±æµ·ãƒ»å—æµ·ãƒˆãƒ©ãƒ•å‘¨è¾ºã®æ´»å‹•ç›£è¦–
                - **äºˆæ¸¬ã¸ã®å¿œç”¨**: éå»ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ä»Šå¾Œ7æ—¥é–“ã®ç™ºç”Ÿç¢ºç‡ã‚’æ¨å®š
                
                **å®Ÿè·µçš„ãƒªã‚¹ã‚¯ç®¡ç†**:
                1. **æ—¥æ¬¡ãƒã‚§ãƒƒã‚¯**: æœä¸€ç•ªã§ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ç¢ºèª
                2. **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªèª¿æ•´**: MEDIUMä»¥ä¸Šã§REITãƒ»ä¿é™ºæ ªã®æ¯”é‡æ¤œè¨
                3. **ãƒ˜ãƒƒã‚¸æˆ¦ç•¥**: HIGHä»¥ä¸Šã§æ—¥çµŒãƒ—ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³è³¼å…¥æ¤œè¨
                4. **ç¾é‡‘æ¯”ç‡**: CRITICALæ™‚ã¯ç¾é‡‘æ¯”ç‡ã‚’30%ä»¥ä¸Šã«å¼•ãä¸Šã’
                """)
        else:
            with st.expander("ğŸ“– About This Tab"):
                st.markdown("""
                **The Earthquake Monitor tab provides:**
                
                ğŸŒ‹ **Real-time Earthquake Data Details**
                - **Data Source**: P2PQuake API (based on Japan Meteorological Agency releases)
                - **Update Frequency**: Immediate reflection when new earthquakes occur (usually within minutes)
                - **Display Items**:
                  - **Occurrence Time**: Displayed in JST (Japan Standard Time)
                  - **Magnitude**: Shows M3.0+ earthquakes (M5.0+ in bold)
                  - **Epicenter**: Specific regional names (e.g., "Off the coast of Chiba Prefecture")
                  - **Depth**: In kilometers (shallower = greater surface impact)
                  - **Tokyo Distance**: Auto-calculated straight-line distance from Imperial Palace
                
                âš ï¸ **Risk Assessment Criteria**
                - **LOW**: M<5.0 or >150km from Tokyo
                - **MEDIUM**: M5.0-6.9 and 50-150km from Tokyo
                - **HIGH**: M7.0-7.9 and within 100km of Tokyo
                - **CRITICAL**: M8.0+ or within 30km of Tokyo
                - **Assessment Period**: Weighted analysis of past 7 days of seismic activity
                - **Distance Decay**: Impact reduces by 1/4 when distance doubles
                
                ğŸ“Š **Market Correlation Analysis Practical Interpretation**
                - **Nikkei 225 Correlation (-0.15)**: Average 15% decline during major earthquakes
                - **REIT Correlation (-0.35)**: Real estate investment trusts most sensitive to earthquakes
                  - **Reason**: Direct impact concerns on physical assets
                  - **Example**: Real estate REITs fell 30%+ during 2011 Tohoku earthquake
                - **JPY Correlation (+0.08)**: Yen tends to strengthen slightly during earthquakes
                  - **Reason**: Reconstruction demand and foreign capital repatriation
                - **Insurance Correlation (-0.45)**: Insurance companies heavily impacted by earthquakes
                  - **Reason**: Increased earthquake insurance payout obligations
                - **Utilities Correlation (-0.25)**: Infrastructure damage causing operational shutdowns
                
                ğŸ“ˆ **Historical Pattern Analysis Applications**
                - **Statistical Period**: 30-day earthquake activity analysis
                - **Magnitude Distribution**:
                  - **M3-4**: Daily occurrence (20-30 times/month)
                  - **M4-5**: 1-2 times/week
                  - **M5-6**: 1-2 times/month
                  - **M6+**: Once every few months (attention level)
                - **Regional Frequency**: Monitoring Kanto, Tokai, Nankai Trough area activity
                - **Predictive Application**: Estimate 7-day ahead occurrence probability from historical patterns
                
                **Practical Risk Management**:
                1. **Daily Check**: Verify risk level first thing in the morning
                2. **Portfolio Adjustment**: Consider REIT/insurance stock weights at MEDIUM+ levels
                3. **Hedge Strategy**: Consider Nikkei put options at HIGH+ levels
                4. **Cash Ratio**: Increase cash holdings to 30%+ during CRITICAL periods
                """)

        with st.spinner(translations.get("loading_earthquake_data", "Loading earthquake data...")):
            try:
                earthquake_data, earthquake_risk = self.get_shared_earthquake_data()
            except Exception as e:
                st.error(translations.get("earthquake_data_unavailable", "Unable to fetch earthquake data. Using cached information."))
                earthquake_data = []
                earthquake_risk = {'risk_level': 'LOW', 'recent_activity': 0, 'max_magnitude': 0, 'all_events': []}
        
        if earthquake_data:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                total_events = len(earthquake_data)
                st.metric("Total Recent Events" if lang == 'en' else "æœ€è¿‘ã®ã‚¤ãƒ™ãƒ³ãƒˆæ•°", total_events)
            with col2:
                latest_mag = earthquake_data[0].get('magnitude', 0) if earthquake_data else 0
                st.metric("Latest Magnitude" if lang == 'en' else "æœ€æ–°ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰", f"M{latest_mag:.1f}")
            with col3:
                tokyo_events = len(earthquake_risk.get('tokyo_region_events', []))
                st.metric("Tokyo Region (500km)" if lang == 'en' else "æ±äº¬å‘¨è¾º(500km)", tokyo_events)
            with col4:
                data_source = "P2PQuake API" if not earthquake_data[0].get('data_quality') == 'mock' else "Mock Data"
                status_color = "ğŸŸ¢" if data_source.startswith("P2P") else "ğŸŸ¡"
                st.metric("Data Source" if lang == 'en' else "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", f"{status_color} {data_source}")
            
            st.markdown("---")
        
        if earthquake_data:
            all_events = earthquake_risk.get('all_events', earthquake_data)
            
            display_data = []
            for eq in all_events[:15]:  
                eq_time = eq.get('time', 'N/A')
                if 'T' in eq_time or '/' in eq_time:
                    try:
                        if 'T' in eq_time:
                            dt = datetime.fromisoformat(eq_time.replace('Z', '+00:00'))
                        else:
                            dt = datetime.strptime(eq_time.split('.')[0], "%Y/%m/%d %H:%M:%S")
                        eq_time = dt.strftime("%m/%d %H:%M")
                    except:
                        pass
                
                display_data.append({
                    'Time' if lang == 'en' else 'æ™‚åˆ»': eq_time,
                    'Magnitude' if lang == 'en' else 'ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰': f"M{eq.get('magnitude', 0):.1f}",
                    'Intensity' if lang == 'en' else 'éœ‡åº¦': f"{eq.get('intensity', 0):.1f}",
                    'Location' if lang == 'en' else 'å ´æ‰€': eq.get('location', 'Unknown'),
                    'Depth' if lang == 'en' else 'æ·±ã•': f"{eq.get('depth', 0):.0f}km",
                    'Distance' if lang == 'en' else 'è·é›¢': f"{eq.get('distance_from_tokyo', 0):.0f}km"
                })
            
            if display_data:
                df = pd.DataFrame(display_data)
                st.dataframe(df, use_container_width=True)
            else:
                st.info("No earthquake data available." if lang == 'en' else "åœ°éœ‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            if lang == 'jp':
                st.info("åœ°éœ‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            else:
                st.info("Loading earthquake data...")
        
        risk_level = earthquake_risk.get('risk_level', 'LOW')
        risk_css_class = f"risk-card-{risk_level.lower()}"
        
        if lang == 'jp':
            assessment_content = f"""
            <div class="risk-card {risk_css_class}">
                <h4>ğŸ¯ ç¾åœ¨ã®è©•ä¾¡</h4>
                <p><strong>ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«:</strong> {translations.get(f'risk_{risk_level.lower()}', risk_level)}</p>
                <p><strong>æœ€è¿‘ã®æ´»å‹•:</strong> {earthquake_risk.get('recent_activity', 0)}ä»¶ (7æ—¥é–“)</p>
                <p><strong>æœ€å¤§ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰:</strong> M{earthquake_risk.get('max_magnitude', 0):.1f}</p>
                <p><strong>æœ€è¿‘è·é›¢:</strong> {earthquake_risk.get('closest_distance', 0):.0f}km</p>
                <p><strong>è©•ä¾¡:</strong> {earthquake_risk.get('assessment', 'ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­')}</p>
            </div>
            """
        else:
            assessment_content = f"""
            <div class="risk-card {risk_css_class}">
                <h4>ğŸ¯ Current Assessment</h4>
                <p><strong>Risk Level:</strong> {risk_level}</p>
                <p><strong>Recent Activity:</strong> {earthquake_risk.get('recent_activity', 0)} events (7d)</p>
                <p><strong>Max Magnitude:</strong> M{earthquake_risk.get('max_magnitude', 0):.1f}</p>
                <p><strong>Closest Distance:</strong> {earthquake_risk.get('closest_distance', 0):.0f}km</p>
                <p><strong>Assessment:</strong> {earthquake_risk.get('assessment', 'Loading data...')}</p>
            </div>
            """
        
        st.markdown(assessment_content, unsafe_allow_html=True)
        
        st.markdown("---")
        correlation_title = "å¸‚å ´ç›¸é–¢åˆ†æ" if lang == 'jp' else "Market Correlation Analysis"
        st.markdown(f"### {correlation_title}")
        
        correlations = self.earthquake_data.get_market_impact_correlation()
        
        col1, col2 = st.columns(2)
        
        with col1:
            if lang == 'jp':
                st.metric("æ—¥çµŒ225ç›¸é–¢", f"{correlations['nikkei_correlation']:.3f}")
                st.metric("REITç›¸é–¢", f"{correlations['reit_correlation']:.3f}")
                st.metric("å††ç›¸é–¢", f"{correlations['jpy_correlation']:.3f}")
            else:
                st.metric("Nikkei Correlation", f"{correlations['nikkei_correlation']:.3f}")
                st.metric("REIT Correlation", f"{correlations['reit_correlation']:.3f}")
                st.metric("JPY Correlation", f"{correlations['jpy_correlation']:.3f}")
        
        with col2:
            if lang == 'jp':
                st.metric("å…¬ç›Šäº‹æ¥­ç›¸é–¢", f"{correlations['utilities_correlation']:.3f}")
                st.metric("ä¿é™ºæ¥­ç›¸é–¢", f"{correlations['insurance_correlation']:.3f}")
            else:
                st.metric("Utilities Correlation", f"{correlations['utilities_correlation']:.3f}")
                st.metric("Insurance Correlation", f"{correlations['insurance_correlation']:.3f}")
        
        all_events = earthquake_risk.get('all_events', earthquake_data)
        if len(all_events) > 0:
            st.markdown("---")
            map_title = "åœ°éœ‡åˆ†å¸ƒãƒãƒƒãƒ—" if lang == 'jp' else "Earthquake Distribution Map"
            st.markdown(f"### {map_title}")
            
            map_data = []
            for eq in all_events[:20]:  
                if eq.get('latitude', 0) != 0 and eq.get('longitude', 0) != 0:
                    map_data.append({
                        'lat': eq.get('latitude', 0),
                        'lon': eq.get('longitude', 0),
                        'magnitude': eq.get('magnitude', 0),
                        'location': eq.get('location', 'Unknown'),
                        'distance': eq.get('distance_from_tokyo', 0),
                        'size': max(5, eq.get('magnitude', 2) * 3)  
                    })
            
            if map_data:
                import plotly.express as px
                df_map = pd.DataFrame(map_data)
                
                fig = go.Figure()
                
                fig.add_trace(go.Scatter(
                    x=df_map['lon'],
                    y=df_map['lat'],
                    mode='markers',
                    marker=dict(
                        size=df_map['size'],
                        color=df_map['magnitude'],
                        colorscale='Reds',
                        sizemode='diameter',
                        sizeref=2*max(df_map['size'])/(20**2),
                        showscale=True,
                        colorbar=dict(title="Magnitude")
                    ),
                    text=df_map['location'],
                    hovertemplate='<b>%{text}</b><br>Magnitude: %{marker.color:.1f}<br>Distance: %{customdata} km<extra></extra>',
                    customdata=df_map['distance'],
                    name="Earthquakes"
                ))
                
                fig.add_trace(go.Scatter(
                    x=[139.6503],
                    y=[35.6762],
                    mode='markers',
                    marker=dict(size=15, color='blue', symbol='star'),
                    text=['Tokyo'],
                    name='Tokyo' if lang == 'en' else 'æ±äº¬',
                    hovertemplate='<b>Tokyo</b><extra></extra>'
                ))
                
                fig.update_layout(
                    title="Recent Earthquakes" if lang == 'en' else "æœ€è¿‘ã®åœ°éœ‡",
                    xaxis_title="Longitude",
                    yaxis_title="Latitude",
                    showlegend=True
                )
                
                fig.update_layout(
                    height=400,
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    font_color=THEME_COLORS['text_primary']
                )
                st.plotly_chart(fig, use_container_width=True)
        
        if st.button("éå»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ" if lang == 'jp' else "Analyze Historical Patterns"):
            patterns = self.earthquake_data.get_historical_patterns(days=30)
            if patterns:
                events_text = "events in last 30 days" if lang == 'en' else "éå»30æ—¥é–“ã®ã‚¤ãƒ™ãƒ³ãƒˆ"
                st.markdown(f"**{patterns['total_events']} {events_text}**")
                
                mag_dist = patterns.get('events_by_magnitude', {})
                if mag_dist:
                    st.markdown("Magnitude Distribution:" if lang == 'en' else "ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰åˆ†å¸ƒ:")
                    for mag_range, count in mag_dist.items():
                        st.write(f"  {mag_range}: {count} events")
                
                if 'avg_magnitude' in patterns:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Avg Magnitude" if lang == 'en' else "å¹³å‡ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰", f"M{patterns['avg_magnitude']:.1f}")
                    with col2:
                        st.metric("Max Magnitude" if lang == 'en' else "æœ€å¤§ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰", f"M{patterns['max_magnitude']:.1f}")
                    with col3:
                        st.metric("Avg Distance" if lang == 'en' else "å¹³å‡è·é›¢", f"{patterns['avg_distance']:.0f}km")

    def render_options_tab(self):
        """Render the options analytics tab"""
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "âš™ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒ³åˆ†æã‚¨ãƒ³ã‚¸ãƒ³" if lang == 'jp' else "âš™ï¸ Options Analytics Engine"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("ğŸ“– ã“ã®ã‚¿ãƒ–ã«ã¤ã„ã¦"):
                st.markdown("""
                **ã‚ªãƒ—ã‚·ãƒ§ãƒ³åˆ†æã‚¿ãƒ–ã§ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š**
                
                ğŸ§® **Black-Scholesè¨ˆç®—æ©Ÿ**
                - ãƒ¨ãƒ¼ãƒ­ãƒ”ã‚¢ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾¡æ ¼ã®è¨ˆç®—
                - ã‚³ãƒ¼ãƒ«ãƒ»ãƒ—ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾¡æ ¼ã¨ã‚®ãƒªã‚·ãƒ£æ–‡å­—
                - æ—¥æœ¬å¸‚å ´ç‰¹æœ‰ã®åœ°éœ‡ãƒªã‚¹ã‚¯èª¿æ•´
                
                ğŸ² **ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**
                - 10,000å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ä¾¡æ ¼äºˆæ¸¬
                - ç½å®³ã‚·ãƒŠãƒªã‚ªã‚’è€ƒæ…®ã—ãŸä¾¡æ ¼èª¿æ•´
                - æ¨™æº–èª¤å·®ã¨ä¿¡é ¼åŒºé–“ã®è¨ˆç®—
                
                ğŸ“Š **ã‚®ãƒªã‚·ãƒ£æ–‡å­—åˆ†æ**
                - ãƒ‡ãƒ«ã‚¿ï¼ˆä¾¡æ ¼æ„Ÿå¿œåº¦ï¼‰
                - ã‚¬ãƒ³ãƒï¼ˆãƒ‡ãƒ«ã‚¿å¤‰åŒ–ç‡ï¼‰
                - ãƒ™ã‚¬ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ„Ÿå¿œåº¦ï¼‰
                - ã‚·ãƒ¼ã‚¿ï¼ˆæ™‚é–“æ¸›ä¾¡ï¼‰
                
                ğŸ‡¯ğŸ‡µ **æ—¥æœ¬å¸‚å ´ç‰¹åŒ–æ©Ÿèƒ½**
                - åœ°éœ‡ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´
                - æ—¥æœ¬éŠ€è¡Œã®é‡‘åˆ©æ”¿ç­–ã‚’åæ˜ 
                """)
        else:
            with st.expander("ğŸ“– About This Tab"):
                st.markdown("""
                **The Options Analytics tab provides:**
                
                ğŸ§® **Black-Scholes Calculator**
                - European option pricing calculations
                - Call and put option prices with Greeks
                - Japan-specific earthquake risk adjustments
                
                ğŸ² **Monte Carlo Simulation**
                - 10,000-iteration price forecasting
                - Disaster scenario-adjusted pricing
                - Standard error and confidence interval calculations
                
                ğŸ“Š **Greeks Analysis**
                - Delta (price sensitivity)
                - Gamma (delta change rate)
                - Vega (volatility sensitivity)
                - Theta (time decay)
                
                ğŸ‡¯ğŸ‡µ **Japan Market Specialization**
                - Volatility adjustments based on earthquake risk levels
                - Bank of Japan interest rate policy integration
                """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            calculator_title = "Black-Scholesè¨ˆç®—æ©Ÿ" if lang == 'jp' else "Black-Scholes Calculator"
            st.markdown(f"#### {calculator_title}")
            
            spot = st.number_input("ç¾åœ¨ä¾¡æ ¼ (Â¥)" if lang == 'jp' else "Spot Price (Â¥)", value=33000.0, step=100.0)
            strike = st.number_input("è¡Œä½¿ä¾¡æ ¼ (Â¥)" if lang == 'jp' else "Strike Price (Â¥)", value=33500.0, step=100.0)
            time_to_expiry = st.number_input("æº€æœŸæ—¥æ•°" if lang == 'jp' else "Time to Expiry (days)", value=30, step=1)
            volatility = st.number_input("ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (%)" if lang == 'jp' else "Volatility (%)", value=25.0, step=1.0)
            risk_free_rate = st.number_input("ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ© (%)" if lang == 'jp' else "Risk-Free Rate (%)", value=0.5, step=0.1)
            
            earthquake_data = self.earthquake_data.fetch_recent_earthquakes(limit=50)
            earthquake_risk = self.earthquake_data.assess_tokyo_risk(earthquake_data)
            eq_risk_level = earthquake_risk.get('risk_level', 'LOW')
        
        with col2:
            results_title = "è¨ˆç®—çµæœ" if lang == 'jp' else "Results"
            st.markdown(f"#### {results_title}")
            
            time_to_maturity = time_to_expiry / 365.0
            vol_decimal = volatility / 100.0
            rate_decimal = risk_free_rate / 100.0
            
            adjusted_vol = self.bs_engine.get_japanese_market_adjustments(vol_decimal, eq_risk_level)
            
            pricing_results = self.bs_engine.calculate_option_prices(
                spot, strike, time_to_maturity, rate_decimal, adjusted_vol
            )
            
            st.metric("ã‚³ãƒ¼ãƒ«ä¾¡æ ¼" if lang == 'jp' else "Call Option Price", f"Â¥{pricing_results['call_price']:.2f}")
            st.metric("ãƒ—ãƒƒãƒˆä¾¡æ ¼" if lang == 'jp' else "Put Option Price", f"Â¥{pricing_results['put_price']:.2f}") 
            st.metric("ãƒ‡ãƒ«ã‚¿" if lang == 'jp' else "Delta", f"{pricing_results['greeks']['delta_call']:.4f}")
            st.metric("ã‚¬ãƒ³ãƒ" if lang == 'jp' else "Gamma", f"{pricing_results['greeks']['gamma']:.6f}")
            st.metric("ãƒ™ã‚¬" if lang == 'jp' else "Vega", f"{pricing_results['greeks']['vega']:.4f}")
            st.metric("ã‚·ãƒ¼ã‚¿" if lang == 'jp' else "Theta", f"{pricing_results['greeks']['theta_call']:.4f}")
            
            if eq_risk_level != 'LOW':
                adj_factor = adjusted_vol / vol_decimal
                warning_text = f"åœ°éœ‡ãƒªã‚¹ã‚¯èª¿æ•´: {adj_factor:.2f}x" if lang == 'jp' else f"Earthquake Risk Adjustment: {adj_factor:.2f}x"
                st.warning(warning_text)
        
        st.markdown("---")
        monte_carlo_title = "ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³" if lang == 'jp' else "Monte Carlo Simulation"
        st.markdown(f"### {monte_carlo_title}")
        
        if st.button("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ" if lang == 'jp' else "Run Simulation"):
            mc_results = self.bs_engine.monte_carlo_pricing(
                spot, strike, time_to_maturity, rate_decimal, adjusted_vol, 
                num_simulations=10000, option_type='call'
            )
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("MC ã‚³ãƒ¼ãƒ«ä¾¡æ ¼" if lang == 'jp' else "MC Call Price", f"Â¥{mc_results['standard_price']:.2f}")
            with col2:
                st.metric("ç½å®³èª¿æ•´ä¾¡æ ¼" if lang == 'jp' else "Disaster Adjusted", f"Â¥{mc_results['disaster_adjusted_price']:.2f}")
            with col3:
                st.metric("æ¨™æº–èª¤å·®" if lang == 'jp' else "Standard Error", f"Â¥{mc_results['standard_error']:.4f}")

    def render_decision_tab(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "ğŸª æ„æ€æ±ºå®šæ”¯æ´ã‚­ãƒ¥ãƒ¼" if lang == 'jp' else "ğŸª Decision Support Queue"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("ğŸ“– ã“ã®ã‚¿ãƒ–ã«ã¤ã„ã¦"):
                st.markdown("""
                **æ„æ€æ±ºå®šæ”¯æ´ã‚¿ãƒ–ã§ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š**
                
                ğŸ¤– **AIæ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°ä»•çµ„ã¿**
                - **æ¨å¥¨ç”Ÿæˆæ¡ä»¶**: 
                  - **åœ°éœ‡ãƒªã‚¹ã‚¯MEDIUMä»¥ä¸Š**: è‡ªå‹•çš„ã«REITãƒ»ä¿é™ºã‚»ã‚¯ã‚¿ãƒ¼è­¦å‘Š
                  - **å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£30%è¶…**: ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºç¸®å°æ¨å¥¨
                  - **ç›¸é–¢ãƒªã‚¹ã‚¯0.7ä»¥ä¸Š**: åˆ†æ•£æŠ•è³‡è¿½åŠ æ¨å¥¨
                - **å„ªå…ˆåº¦åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ **:
                  - **CRITICALï¼ˆç·Šæ€¥ï¼‰**: å³åº§ã®è¡Œå‹•ãŒå¿…è¦ï¼ˆä¾‹ï¼šå¤§åœ°éœ‡ç™ºç”Ÿæ™‚ã®ç·Šæ€¥å£²å´ï¼‰
                  - **HIGHï¼ˆé«˜ï¼‰**: 24æ™‚é–“ä»¥å†…ã®å¯¾å¿œæ¨å¥¨ï¼ˆä¾‹ï¼šé«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ã®ãƒ˜ãƒƒã‚¸è¿½åŠ ï¼‰
                  - **MEDIUMï¼ˆä¸­ï¼‰**: 1é€±é–“ä»¥å†…ã®æ¤œè¨ï¼ˆä¾‹ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªèª¿æ•´ï¼‰
                  - **LOWï¼ˆä½ï¼‰**: 1ãƒ¶æœˆä»¥å†…ã®é•·æœŸçš„å¯¾å¿œï¼ˆä¾‹ï¼šå®šæœŸçš„ãªãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰
                
                - **ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ç®—å‡º**:
                  - **95%ä»¥ä¸Š**: ãƒ‡ãƒ¼ã‚¿å“è³ªé«˜ï¼‹éå»å®Ÿç¸¾ä¸€è‡´
                  - **80-95%**: æ¨™æº–çš„ãªæ¨å¥¨ï¼ˆé€šå¸¸æ¡ç”¨ï¼‰
                  - **60-80%**: è¦æ¤œè¨ï¼ˆè¿½åŠ åˆ†ææ¨å¥¨ï¼‰
                  - **60%æœªæº€**: ä½ä¿¡é ¼åº¦ï¼ˆæ…é‡åˆ¤æ–­è¦ï¼‰
                
                âœ… **æ‰¿èªãƒ»æ‹’å¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè£…**
                - **æ‰¿èªåŠ¹æœ**: 
                  - æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒæ±ºå®šå±¥æ­´ã«è¨˜éŒ²
                  - å°†æ¥ã®AIå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨
                  - ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã¸ã®é€£æºï¼ˆå°†æ¥å®Ÿè£…ï¼‰
                - **æ‹’å¦åŠ¹æœ**:
                  - åˆ¤æ–­ç†ç”±ã‚’AIãŒå­¦ç¿’ï¼ˆç²¾åº¦å‘ä¸Šï¼‰
                  - é¡ä¼¼çŠ¶æ³ã§ã®æ¨å¥¨é »åº¦èª¿æ•´
                  - ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®é¸å¥½å­¦ç¿’
                - **é‡è¤‡é˜²æ­¢**: å†…å®¹ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹å®‰å®šIDç®¡ç†ã§åŒä¸€æ¨å¥¨ã®é‡è¤‡å›é¿
                
                ğŸ“Š **æ±ºå®šå±¥æ­´ç®¡ç†ã®æ´»ç”¨ä¾¡å€¤**
                - **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡**: æ‰¿èªã—ãŸæ¨å¥¨ã®æˆæœæ¸¬å®š
                - **å­¦ç¿’åŠ¹æœ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆ¤æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                - **ç›£æŸ»è¨¼è·¡**: ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦æ±‚ã¸ã®å¯¾å¿œ
                - **çµ±è¨ˆåˆ†æ**: 
                  - **æ‰¿èªç‡**: å…¨æ¨å¥¨ä¸­ã®æ‰¿èªå‰²åˆ
                  - **æˆåŠŸç‡**: æ‰¿èªã—ãŸæ¨å¥¨ã®å®Ÿéš›ã®æˆæœ
                  - **åå¿œæ™‚é–“**: æ¨å¥¨ã‹ã‚‰æ±ºå®šã¾ã§ã®å¹³å‡æ™‚é–“
                
                ğŸ¯ **å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æã®è©³ç´°**
                - **ç›´æ¥å½±éŸ¿ã‚»ã‚¯ã‚¿ãƒ¼**: æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ä¸»è¦å¯¾è±¡
                  - **ä¾‹**: åœ°éœ‡ãƒªã‚¹ã‚¯ â†’ ä¸å‹•ç”£REITã€ä¿é™ºã€å»ºè¨­
                - **é–“æ¥å½±éŸ¿ã‚»ã‚¯ã‚¿ãƒ¼**: æ³¢åŠåŠ¹æœãŒäºˆæƒ³ã•ã‚Œã‚‹åˆ†é‡
                  - **ä¾‹**: å††é«˜æ¨ç§» â†’ è¼¸å‡ºä¼æ¥­ã€è¦³å…‰æ¥­
                - **å½±éŸ¿åº¦äºˆæ¸¬**: 
                  - **é‡å¤§ï¼ˆ-20%ä»¥ä¸Šï¼‰**: å³åº§ã®å¯¾å¿œå¿…è¦
                  - **ä¸­ç¨‹åº¦ï¼ˆ-10ã€œ-20%ï¼‰**: æ…é‡ãªç›£è¦–
                  - **è»½å¾®ï¼ˆ-10%æœªæº€ï¼‰**: é•·æœŸçš„ãªè¦³å¯Ÿ
                
                **å®Ÿç”¨çš„ä½¿ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³**:
                1. **æœã®ç¢ºèª**: å¸‚å ´é–‹å§‹å‰ã«æ–°è¦æ¨å¥¨ã‚’ãƒã‚§ãƒƒã‚¯
                2. **å„ªå…ˆé †ä½**: CRITICALâ†’HIGHâ†’MEDIUMâ†’LOWã®é †ã§å¯¾å¿œ
                3. **ä¿¡é ¼åº¦åˆ¤æ–­**: 80%ä»¥ä¸Šã®æ¨å¥¨ã‚’å„ªå…ˆçš„ã«æ¤œè¨
                4. **è¨˜éŒ²æ´»ç”¨**: æœˆæ¬¡ã§æ±ºå®šå±¥æ­´ã‚’åˆ†æã—ã€æˆ¦ç•¥æ”¹å–„
                5. **å­¦ç¿’ä¿ƒé€²**: æ‹’å¦æ™‚ã¯ç†ç”±ã‚’ãƒ¡ãƒ¢ï¼ˆå°†æ¥ã®AIæ”¹å–„ç”¨ï¼‰
                """)
        else:
            with st.expander("ğŸ“– About This Tab"):
                st.markdown("""
                **The Decision Support tab provides:**
                
                ğŸ¤– **AI Recommendation System Detailed Mechanics**
                - **Recommendation Triggers**:
                  - **Earthquake Risk MEDIUM+**: Auto-alerts for REIT & insurance sectors
                  - **Market Volatility >30%**: Position size reduction recommendations
                  - **Correlation Risk >0.7**: Additional diversification suggestions
                - **Priority Classification System**:
                  - **CRITICAL**: Immediate action required (e.g., emergency selling during major earthquake)
                  - **HIGH**: Response recommended within 24 hours (e.g., hedging during high volatility)
                  - **MEDIUM**: Consideration within 1 week (e.g., portfolio adjustments)
                  - **LOW**: Long-term response within 1 month (e.g., regular rebalancing)
                
                - **Confidence Score Calculation**:
                  - **95%+**: High data quality + historical performance match
                  - **80-95%**: Standard recommendations (normally adopted)
                  - **60-80%**: Requires consideration (additional analysis recommended)
                  - **<60%**: Low confidence (cautious judgment required)
                
                âœ… **Approval/Rejection Workflow Implementation**
                - **Approval Effects**:
                  - Recommended actions recorded in decision history
                  - Used as future AI learning data
                  - Integration with portfolio management systems (future implementation)
                - **Rejection Effects**:
                  - AI learns reasoning for accuracy improvement
                  - Adjusts recommendation frequency for similar situations
                  - Learns user-specific preferences
                - **Duplicate Prevention**: Stable ID management via content hashing prevents duplicate recommendations
                
                ğŸ“Š **Decision History Management Value**
                - **Performance Tracking**: Measure success of approved recommendations
                - **Learning Effects**: Analyze user decision patterns
                - **Audit Trail**: Compliance requirement fulfillment
                - **Statistical Analysis**:
                  - **Approval Rate**: Percentage of recommendations approved
                  - **Success Rate**: Actual performance of approved recommendations
                  - **Response Time**: Average time from recommendation to decision
                
                ğŸ¯ **Target Sector Analysis Details**
                - **Direct Impact Sectors**: Primary targets of recommended actions
                  - **Example**: Earthquake risk â†’ Real estate REITs, insurance, construction
                - **Indirect Impact Sectors**: Areas expecting ripple effects
                  - **Example**: Yen appreciation â†’ Export companies, tourism industry
                - **Impact Magnitude Prediction**:
                  - **Severe (-20%+)**: Immediate response required
                  - **Moderate (-10% to -20%)**: Careful monitoring
                  - **Minor (<-10%)**: Long-term observation
                
                **Practical Usage Guidelines**:
                1. **Morning Check**: Review new recommendations before market open
                2. **Prioritization**: Handle CRITICALâ†’HIGHâ†’MEDIUMâ†’LOW in order
                3. **Confidence Assessment**: Prioritize recommendations with 80%+ confidence
                4. **Record Utilization**: Monthly analysis of decision history for strategy improvement
                5. **Learning Enhancement**: Note reasons for rejections (for future AI improvement)
                
                **Understanding the AI Logic**:
                - **Data Integration**: Combines earthquake, market, and correlation data
                - **Pattern Recognition**: Identifies historical precedents and outcomes
                - **Risk Weighting**: Balances multiple risk factors with proven weights
                - **Timing Optimization**: Considers market conditions and volatility for action timing
                """)
        
        if 'decision_queue' not in st.session_state:
            st.session_state.decision_queue = []
        if 'decision_history' not in st.session_state:
            st.session_state.decision_history = []
        
        with st.spinner("Loading risk assessment..."):
            try:
                earthquake_data = self.earthquake_data.fetch_recent_earthquakes(limit=10)
                earthquake_risk = self.earthquake_data.assess_tokyo_risk(earthquake_data)
                market_summary = self.market_data.get_tokyo_market_summary()
                correlation_matrix = pd.DataFrame()  
                
                risk_assessment = self.risk_engine.assess_integrated_risk(
                    earthquake_risk, market_summary, correlation_matrix
                )
            except Exception as e:
                st.error("Unable to fetch risk data. Using cached information.")
                earthquake_risk = {'risk_level': 'LOW', 'recent_activity': 0}
                risk_assessment = {'recommendations': []}
        
        current_decisions = risk_assessment.get('recommendations', [])
        
        for decision in current_decisions:
            stable_id = f"{decision.get('category', 'unknown')}_{hash(decision.get('action', ''))}"
            decision['id'] = stable_id
            decision['timestamp'] = datetime.now()
            decision['status'] = 'PENDING'
        
        existing_ids = {d.get('id') for d in st.session_state.decision_queue if d.get('status') == 'PENDING'}
        processed_ids = {d.get('id') for d in st.session_state.decision_history}
        all_existing_ids = existing_ids.union(processed_ids)
        
        new_decisions = [d for d in current_decisions if d.get('id') not in all_existing_ids]
        st.session_state.decision_queue.extend(new_decisions)
        
        pending_decisions = [d for d in st.session_state.decision_queue if d.get('status') == 'PENDING']
        
        if not pending_decisions:
            st.info(translations.get("no_pending_decisions", "No pending decisions at this time."))
            return
        
        for i, decision in enumerate(pending_decisions):
            priority_color = {
                "HIGH": THEME_COLORS['warning'],
                "CRITICAL": THEME_COLORS['warning'],
                "MEDIUM": "#F7931E", 
                "LOW": THEME_COLORS['info']
            }.get(decision.get('priority', 'LOW'), THEME_COLORS['info'])
            
            if lang == 'jp':
                priority_map = {'HIGH': 'é«˜', 'CRITICAL': 'ç·Šæ€¥', 'MEDIUM': 'ä¸­', 'LOW': 'ä½'}
                priority_text = priority_map.get(decision.get('priority', 'LOW'), decision.get('priority', 'LOW'))
                
                category_map = {
                    'Earthquake Risk': 'åœ°éœ‡ãƒªã‚¹ã‚¯',
                    'Market Volatility': 'å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£', 
                    'Correlation Risk': 'ç›¸é–¢ãƒªã‚¹ã‚¯',
                    'Systemic Risk': 'ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯',
                    'Monitoring': 'ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°'
                }
                category_text = category_map.get(decision.get('category', ''), decision.get('category', ''))
            else:
                priority_text = decision.get('priority', 'LOW')
                category_text = decision.get('category', '')
            
            st.markdown(f"""
            <div class="decision-item" style="border-left-color: {priority_color};">
                <h4>{priority_text} å„ªå…ˆåº¦: {category_text}</h4>
                <p><strong>åˆ†æ:</strong> {decision.get('rationale', '')}</p>
                <p><strong>æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:</strong> {decision.get('action', '')}</p>
                <p><strong>ä¿¡é ¼åº¦:</strong> {decision.get('confidence', 'N/A')} | <strong>ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³:</strong> {decision.get('timeline', '')}</p>
                <p><strong>å¯¾è±¡ã‚»ã‚¯ã‚¿ãƒ¼:</strong> {', '.join(decision.get('target_sectors', []))}</p>
            </div>
            """ if lang == 'jp' else f"""
            <div class="decision-item" style="border-left-color: {priority_color};">
                <h4>{decision.get('priority', 'LOW')} PRIORITY: {decision.get('category', '')}</h4>
                <p><strong>Analysis:</strong> {decision.get('rationale', '')}</p>
                <p><strong>Recommended Action:</strong> {decision.get('action', '')}</p>
                <p><strong>Confidence:</strong> {decision.get('confidence', 'N/A')} | <strong>Timeline:</strong> {decision.get('timeline', '')}</p>
                <p><strong>Target Sectors:</strong> {', '.join(decision.get('target_sectors', []))}</p>
            </div>
            """, unsafe_allow_html=True)
            
            col1, col2, col3 = st.columns([1, 1, 3])
            with col1:
                approve_text = "âœ… æ‰¿èª" if lang == 'jp' else "âœ… Approve"
                if st.button(approve_text, key=f"approve_{decision.get('id', i)}"):
                    for d in st.session_state.decision_queue:
                        if d.get('id') == decision.get('id'):
                            d['status'] = 'APPROVED'
                            d['action_timestamp'] = datetime.now()
                            d['action_user'] = 'User'
                            break
                    
                    decision['status'] = 'APPROVED'
                    decision['action_timestamp'] = datetime.now()
                    st.session_state.decision_history.append(decision.copy())
                    
                    success_text = f"æ±ºå®šã‚’æ‰¿èªã—ã¾ã—ãŸ: {decision.get('action', '')}" if lang == 'jp' else f"Decision approved: {decision.get('action', '')}"
                    st.success(success_text)
                    st.rerun()
            
            with col2:
                reject_text = "âŒ æ‹’å¦" if lang == 'jp' else "âŒ Reject"
                if st.button(reject_text, key=f"reject_{decision.get('id', i)}"):
                    for d in st.session_state.decision_queue:
                        if d.get('id') == decision.get('id'):
                            d['status'] = 'REJECTED'
                            d['action_timestamp'] = datetime.now()
                            d['action_user'] = 'User'
                            break
                    
                    decision['status'] = 'REJECTED'
                    decision['action_timestamp'] = datetime.now()
                    st.session_state.decision_history.append(decision.copy())
                    
                    warning_text = f"æ±ºå®šã‚’æ‹’å¦ã—ã¾ã—ãŸ: {decision.get('action', '')}" if lang == 'jp' else f"Decision rejected: {decision.get('action', '')}"
                    st.warning(warning_text)
                    st.rerun()
        
        if st.session_state.decision_history:
            st.markdown("---")
            history_title = "æ±ºå®šå±¥æ­´" if lang == 'jp' else "Decision History"
            st.markdown(f"### {history_title}")
            
            history_df = pd.DataFrame(st.session_state.decision_history)
            if not history_df.empty:
                display_columns = ['action_timestamp', 'priority', 'category', 'action', 'status']
                available_columns = [col for col in display_columns if col in history_df.columns]
                
                if available_columns:
                    display_df = history_df[available_columns].copy()
                    if 'action_timestamp' in display_df.columns:
                        display_df['action_timestamp'] = display_df['action_timestamp'].dt.strftime('%Y-%m-%d %H:%M')
                    
                    if lang == 'jp':
                        column_map = {
                            'action_timestamp': 'å®Ÿè¡Œæ™‚åˆ»',
                            'priority': 'å„ªå…ˆåº¦', 
                            'category': 'ã‚«ãƒ†ã‚´ãƒª',
                            'action': 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³',
                            'status': 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'
                        }
                        display_df = display_df.rename(columns=column_map)
                    
                    st.dataframe(display_df, use_container_width=True)
        
        if st.button("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢" if lang == 'jp' else "Clear History"):
            st.session_state.decision_history = []
            st.session_state.decision_queue = [d for d in st.session_state.decision_queue if d.get('status') == 'PENDING']
            st.rerun()

    def render_network_analysis_tab(self):
        lang = st.session_state.language
        translations = TRANSLATIONS[lang]
        
        title = "ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒªã‚¹ã‚¯åˆ†æ" if lang == 'jp' else "ğŸ•¸ï¸ Network Risk Analysis"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("ğŸ“– ã“ã®ã‚¿ãƒ–ã«ã¤ã„ã¦"):
                st.markdown("""
                **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã‚¿ãƒ–ã§ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š**
                
                ğŸ•¸ï¸ **ãƒªã‚¹ã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–**
                - å¸‚å ´ã€åœ°éœ‡ã€ã‚»ã‚¯ã‚¿ãƒ¼é–“ã®ç›¸é–¢é–¢ä¿‚ã‚’ã‚°ãƒ©ãƒ•è¡¨ç¤º
                - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªåˆ¶å¾¡ï¼ˆãƒ©ãƒ™ãƒ«ãƒ»æ¥ç¶šç·šã®è¡¨ç¤º/éè¡¨ç¤ºï¼‰
                - ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—åˆ¥ã®è‰²åˆ†ã‘è¡¨ç¤º
                
                ğŸ“Š **ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯è¨ˆç®—**
                - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯†åº¦ã«åŸºã¥ããƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢
                - ä¸­å¿ƒæ€§åˆ†æã«ã‚ˆã‚‹é‡è¦ãƒãƒ¼ãƒ‰ç‰¹å®š
                - ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°ã®è¨ˆç®—
                
                ğŸ¯ **ãƒªã‚¹ã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ¤œå‡º**
                - ç›¸é–¢ã®é«˜ã„ãƒªã‚¹ã‚¯è¦å› ã‚°ãƒ«ãƒ¼ãƒ—ã®ç‰¹å®š
                - ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
                - ä¸Šä½ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®è©³ç´°åˆ†æ
                
                ğŸ”— **ä¼æŸ“çµŒè·¯åˆ†æ**
                - é¸æŠã—ãŸãƒãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒªã‚¹ã‚¯æ³¢åŠçµŒè·¯
                - å½±éŸ¿åº¦ã«åŸºã¥ãçµŒè·¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°
                - æœ€å¤§4ãƒ›ãƒƒãƒ—ã¾ã§ã®çµŒè·¯æ¢ç´¢
                
                âš ï¸ **ç•°å¸¸æ¤œå‡º**
                - é«˜ä¸­å¿ƒæ€§ãƒãƒ¼ãƒ‰ã®ç‰¹å®š
                - å­¤ç«‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®æ¤œå‡º
                - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³
                
                **ä½¿ç”¨æ–¹æ³•ï¼š** å¯è¦–åŒ–è¨­å®šã‚’èª¿æ•´ã—ã€ã‚¿ãƒ–ã§ç•°ãªã‚‹åˆ†æã‚’åˆ‡ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚
                """)
        else:
            with st.expander("ğŸ“– About This Tab"):
                st.markdown("""
                **The Network Analysis tab provides:**
                
                ğŸ•¸ï¸ **Risk Network Visualization**
                - Graph display of correlations between markets, earthquakes, and sectors
                - Interactive controls (show/hide labels and connections)
                - Color-coded display by node types
                
                ğŸ“Š **Systemic Risk Calculation**
                - Risk scoring based on network density
                - Critical node identification through centrality analysis
                - Clustering coefficient calculations
                
                ğŸ¯ **Risk Cluster Detection**
                - Identification of highly correlated risk factor groups
                - Risk score calculation within clusters
                - Detailed analysis of top clusters
                
                ğŸ”— **Contagion Path Analysis**
                - Risk propagation paths from selected nodes
                - Path ranking based on impact potential
                - Path exploration up to 4 hops
                
                âš ï¸ **Anomaly Detection**
                - High centrality node identification
                - Isolated cluster detection
                - Abnormal network structure patterns
                
                **How to use:** Adjust visualization settings and switch between different analyses using tabs.
                """)
        
        with st.spinner("Building risk network..." if lang == 'en' else "ãƒªã‚¹ã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ä¸­..."):
            try:
                earthquake_data = self.earthquake_data.fetch_recent_earthquakes(limit=5)  
                market_summary = self.market_data.get_tokyo_market_summary()
                
                selected_markets = st.session_state.get('selected_markets', ['nikkei', 'topix', 'jpy_usd'])
                filtered_market_summary = {k: v for k, v in market_summary.items() if k in selected_markets}
                
                corr_data = {}
                for ticker in selected_markets[:3]:  # Limit to 3 for clarity
                    if ticker in filtered_market_summary and filtered_market_summary[ticker]:
                        corr_data[ticker] = filtered_market_summary[ticker].get('change_percent', 0)
                
                if len(corr_data) >= 2:
                    correlation_matrix = pd.DataFrame(
                        np.random.rand(len(corr_data), len(corr_data)) * 0.6 + 0.2,  
                        index=list(corr_data.keys()),
                        columns=list(corr_data.keys())
                    )
                    np.fill_diagonal(correlation_matrix.values, 1.0)
                else:
                    correlation_matrix = pd.DataFrame()
                
                self.network_engine.build_risk_network(
                    filtered_market_summary, 
                    earthquake_data, 
                    correlation_matrix
                )
                
                systemic_risk = self.network_engine.calculate_systemic_risk_score()
                
            except Exception as e:
                st.error(f"Unable to build network: {str(e)}")
                return
        
        st.markdown("#### ğŸ“Š Network Risk Metrics" if lang == 'en' else "#### ğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒªã‚¹ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            risk_level = systemic_risk['risk_level']
            risk_colors = {'LOW': '#2D6A4F', 'MEDIUM': '#F7931E', 'HIGH': '#FF6B35', 'CRITICAL': '#E63946'}
            color = risk_colors.get(risk_level, '#778DA9')
            
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯" if lang == 'jp' else "Systemic Risk"}</h4>
                <h2 style="color: {color};">{translations.get(f'risk_{risk_level.lower()}', risk_level)}</h2>
                <p>Score: {systemic_risk['systemic_risk_score']:.3f}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯†åº¦" if lang == 'jp' else "Network Density"}</h4>
                <h2>{systemic_risk['network_density']:.3f}</h2>
                <p>{"æ¥ç¶šæ€§æŒ‡æ¨™" if lang == 'jp' else "Connectivity Metric"}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            critical_node = systemic_risk['critical_nodes'][0][0] if systemic_risk['critical_nodes'] else 'None'
            critical_score = systemic_risk['critical_nodes'][0][1] if systemic_risk['critical_nodes'] else 0
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"æœ€é‡è¦ãƒãƒ¼ãƒ‰" if lang == 'jp' else "Most Critical Node"}</h4>
                <h2>{critical_node}</h2>
                <p>{"ä¸­å¿ƒæ€§" if lang == 'jp' else "Centrality"}: {critical_score:.3f}</p>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("#### ğŸŒ Risk Network Visualization" if lang == 'en' else "#### ğŸŒ ãƒªã‚¹ã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–")
        
        col1, col2 = st.columns([3, 1])
        
        with col2:
            show_labels = st.checkbox("Show Labels" if lang == 'en' else "ãƒ©ãƒ™ãƒ«è¡¨ç¤º", value=True)
            show_edges = st.checkbox("Show Connections" if lang == 'en' else "æ¥ç¶šè¡¨ç¤º", value=True)
        
        with col1:
            try:
                fig = self.network_engine.generate_network_visualization()
                
                fig.update_layout(
                    title="",
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    font_color=THEME_COLORS['text_primary'],
                    height=500,
                    showlegend=True,
                    legend=dict(
                        yanchor="top",
                        y=0.99,
                        xanchor="left",
                        x=0.01
                    )
                )
                
                if not show_labels:
                    fig.update_traces(textposition="none")
                if not show_edges:
                    for i, trace in enumerate(fig.data):
                        if trace.mode == 'lines':
                            fig.data[i].visible = False
                
                st.plotly_chart(fig, use_container_width=True)
                
            except Exception as e:
                st.error(f"Unable to generate visualization: {str(e)}")
                st.info("Network visualization temporarily unavailable. Please try refreshing the data.")
        
        st.markdown("---")
        st.markdown("#### ğŸ” Risk Analysis" if lang == 'en' else "#### ğŸ” ãƒªã‚¹ã‚¯åˆ†æ")
        
        analysis_tabs = st.tabs([
            "ğŸ¯ Risk Clusters" if lang == 'en' else "ğŸ¯ ãƒªã‚¹ã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼",
            "ğŸ”— Contagion Paths" if lang == 'en' else "ğŸ”— ä¼æŸ“çµŒè·¯",
            "âš ï¸ Anomalies" if lang == 'en' else "âš ï¸ ç•°å¸¸æ¤œå‡º"
        ])
        
        with analysis_tabs[0]:
            risk_clusters = self.network_engine.detect_risk_clusters()
            
            if risk_clusters:
                st.write("**Detected Risk Clusters:**" if lang == 'en' else "**æ¤œå‡ºã•ã‚ŒãŸãƒªã‚¹ã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼:**")
                
                for i, cluster in enumerate(risk_clusters[:2]):  # Show only top 2
                    risk_score = cluster['risk_score']
                    nodes = cluster['nodes']
                    
                    if risk_score > 1.5:
                        severity = "HIGH" if lang == 'en' else "é«˜"
                        color = THEME_COLORS['warning']
                    elif risk_score > 1.0:
                        severity = "MEDIUM" if lang == 'en' else "ä¸­"
                        color = '#FF6B35'
                    else:
                        severity = "LOW" if lang == 'en' else "ä½"
                        color = THEME_COLORS['info']
                    
                    st.markdown(f"""
                    <div class="risk-card" style="border-left-color: {color};">
                        <h5>Cluster {i+1} - {severity} Risk</h5>
                        <p><strong>Risk Score:</strong> {risk_score:.2f}</p>
                        <p><strong>Components:</strong> {', '.join(nodes[:3])}{'...' if len(nodes) > 3 else ''}</p>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.info("No significant risk clusters detected" if lang == 'en' else "é‡è¦ãªãƒªã‚¹ã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        with analysis_tabs[1]:      
            all_nodes = list(self.network_engine.risk_network.nodes())
            if all_nodes:
                source_node = st.selectbox(
                    "Select source for contagion analysis:" if lang == 'en' else "ä¼æŸ“åˆ†æã®éœ‡æºã‚’é¸æŠ:",
                    all_nodes[:5]  
                )
                
                if st.button("ğŸ” Analyze" if lang == 'en' else "ğŸ” åˆ†æ"):
                    contagion_paths = self.network_engine.find_contagion_paths(source_node)
                    
                    if contagion_paths:
                        st.write(f"**Top contagion paths from {source_node}:**")
                        
                        for i, path_info in enumerate(contagion_paths[:3]):  # Show only top 3
                            path = path_info['path']
                            impact = path_info['impact']
                            
                            path_str = " â†’ ".join(path)
                            impact_pct = impact * 100
                            
                            st.markdown(f"""
                            <div class="decision-item">
                                <p><strong>Path {i+1}:</strong> {path_str}</p>
                                <p><strong>Impact Potential:</strong> {impact_pct:.1f}%</p>
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.info("No significant contagion paths found" if lang == 'en' else "é‡è¦ãªä¼æŸ“çµŒè·¯ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            else:
                st.info("No network nodes available for analysis" if lang == 'en' else "åˆ†æå¯èƒ½ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
        
        with analysis_tabs[2]:
            anomalies = self.network_engine.detect_anomalies()
            
            if anomalies:
                st.write("**Detected Anomalies:**" if lang == 'en' else "**æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸:**")
                
                for anomaly in anomalies[:3]:  
                    severity_colors = {
                        'HIGH': THEME_COLORS['warning'],
                        'MEDIUM': '#FF6B35',
                        'LOW': THEME_COLORS['info']
                    }
                    color = severity_colors.get(anomaly['severity'], THEME_COLORS['info'])
                    
                    anomaly_type = anomaly['type'].replace('_', ' ').title()
                    
                    st.markdown(f"""
                    <div class="risk-card" style="border-left-color: {color};">
                        <h5>âš ï¸ {anomaly_type}</h5>
                        <p>{anomaly['description']}</p>
                        <p><strong>Severity:</strong> {anomaly['severity']}</p>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.success("âœ… No anomalies detected in the risk network" if lang == 'en' else "âœ… ãƒªã‚¹ã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ç•°å¸¸ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        st.markdown("---")
        if lang == 'jp':
            st.markdown("""
            **ğŸ’¡ ãƒ’ãƒ³ãƒˆ:**
            - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯†åº¦ãŒé«˜ã„ã»ã©ã€ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯ãŒé«˜ããªã‚Šã¾ã™
            - é‡è¦ãƒãƒ¼ãƒ‰ã¯å¸‚å ´å…¨ä½“ã¸ã®å½±éŸ¿ãŒå¤§ãã„è¦ç´ ã§ã™
            - ä¼æŸ“çµŒè·¯åˆ†æã§ãƒªã‚¹ã‚¯ã®æ³¢åŠã‚’äºˆæ¸¬ã§ãã¾ã™
            """)
        else:
            st.markdown("""
            **ğŸ’¡ Tips:**
            - Higher network density indicates increased systemic risk
            - Critical nodes have the greatest impact on overall market stability
            - Contagion path analysis helps predict risk propagation
            """)

    def render_predictive_tab(self, market_data, earthquake_data, risk_assessment, lang):
        translations = TRANSLATIONS[lang]
        
        title = "ğŸ”® äºˆæ¸¬åˆ†æã‚¨ãƒ³ã‚¸ãƒ³" if lang == 'jp' else "ğŸ”® Predictive Analytics Engine"
        st.markdown(f"### {title}")
        
        if lang == 'jp':
            with st.expander("ğŸ“– ã“ã®ã‚¿ãƒ–ã«ã¤ã„ã¦"):
                st.markdown("""
                **äºˆæ¸¬åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã§ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š**
                
                ğŸ¤– **æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹äºˆæ¸¬**
                - **ãƒªã‚¹ã‚¯äºˆæ¸¬**: ä»Šå¾Œ7æ—¥é–“ã®ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’äºˆæ¸¬
                - **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬**: å¸‚å ´ã®ä¸å®‰å®šæ€§ã‚’äº‹å‰ã«æ¤œå‡º
                - **ç•°å¸¸æ¤œçŸ¥**: é€šå¸¸ã¨ã¯ç•°ãªã‚‹å¸‚å ´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å³åº§ã«è­˜åˆ¥
                
                ğŸ“Š **ã‚·ãƒŠãƒªã‚ªåˆ†æ**
                - **é€šå¸¸ã‚·ãƒŠãƒªã‚ª**: ç¾åœ¨ã®å¸‚å ´æ¡ä»¶ãŒç¶™ç¶šã™ã‚‹å ´åˆ
                - **åœ°éœ‡ã‚·ãƒŠãƒªã‚ª**: å¤§è¦æ¨¡åœ°éœ‡ç™ºç”Ÿæ™‚ã®å¸‚å ´ã¸ã®å½±éŸ¿
                - **å¸‚å ´ã‚¯ãƒ©ãƒƒã‚·ãƒ¥**: æ€¥æ¿€ãªå¸‚å ´ä¸‹è½æ™‚ã®ãƒªã‚¹ã‚¯
                - **è¤‡åˆå±æ©Ÿ**: åœ°éœ‡ã¨å¸‚å ´ä¸‹è½ãŒåŒæ™‚ç™ºç”Ÿã—ãŸå ´åˆ
                
                ğŸ¯ **ãƒªã‚¹ã‚¯æŒ‡æ¨™**
                - **VaR (Value at Risk)**: 95%/99%ä¿¡é ¼åŒºé–“ã§ã®äºˆæƒ³æœ€å¤§æå¤±
                - **ç•°å¸¸ã‚¹ã‚³ã‚¢**: ç¾åœ¨ã®å¸‚å ´çŠ¶æ³ã®ç•°å¸¸åº¦
                - **ä¿¡é ¼åº¦**: äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ç¢ºå®Ÿæ€§ãƒ¬ãƒ™ãƒ«
                """)
        else:
            with st.expander("ğŸ“– About This Tab"):
                st.markdown("""
                **The Predictive Analytics Engine provides:**
                
                ğŸ¤– **Machine Learning Predictions**
                - **Risk Forecasting**: 7-day ahead risk level predictions
                - **Volatility Forecasting**: Early detection of market instability
                - **Anomaly Detection**: Immediate identification of unusual market patterns
                
                ğŸ“Š **Scenario Analysis**
                - **Normal Scenario**: Continuation of current market conditions
                - **Earthquake Scenario**: Market impact during major seismic events
                - **Market Crash**: Risk assessment during rapid market decline
                - **Combined Crisis**: Simultaneous earthquake and market crash scenarios
                
                ğŸ¯ **Risk Metrics**
                - **VaR (Value at Risk)**: Expected maximum loss at 95%/99% confidence
                - **Anomaly Score**: Degree of current market condition abnormality
                - **Confidence Level**: Prediction model certainty level
                """)
        
        try:
            features = self.predictive_engine.prepare_features(
                market_data, earthquake_data, risk_assessment
            )
            
            forecast_results = self.predictive_engine.forecast_risk(features, forecast_days=7)
            
            anomaly_results = self.predictive_engine.detect_anomalies(features)
            
            scenario_results = self.predictive_engine.generate_scenarios(features, num_scenarios=1000)
            
        except Exception as e:
            st.error(f"Error generating predictions: {str(e)}")
            forecast_results = {
                'current_risk_prediction': 0.3,
                'current_volatility_prediction': 0.2,
                'daily_forecasts': [],
                'model_confidence': 0.5
            }
            anomaly_results = {
                'is_anomaly': False,
                'anomaly_score': 0.1,
                'recommendation': "No anomalies detected"
            }
            scenario_results = {}
        
        st.markdown("---")
        st.markdown("#### ğŸ“ˆ Current Risk Predictions" if lang == 'en' else "#### ğŸ“ˆ ç¾åœ¨ã®ãƒªã‚¹ã‚¯äºˆæ¸¬")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            current_risk = forecast_results['current_risk_prediction']
            risk_pct = current_risk * 100
            
            if current_risk > 0.7:
                risk_color = THEME_COLORS['warning']
                risk_level = "HIGH" if lang == 'en' else "é«˜"
            elif current_risk > 0.4:
                risk_color = '#FF6B35'
                risk_level = "MEDIUM" if lang == 'en' else "ä¸­"
            else:
                risk_color = THEME_COLORS['info']
                risk_level = "LOW" if lang == 'en' else "ä½"
            
            st.markdown(f"""
            <div class="metric-container" style="border-left-color: {risk_color};">
                <h4>{"äºˆæ¸¬ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«" if lang == 'jp' else "Predicted Risk Level"}</h4>
                <h2>{risk_pct:.1f}%</h2>
                <p>{risk_level}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            current_vol = forecast_results['current_volatility_prediction']
            vol_pct = current_vol * 100
            
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"äºˆæ¸¬ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£" if lang == 'jp' else "Predicted Volatility"}</h4>
                <h2>{vol_pct:.1f}%</h2>
                <p>{"30æ—¥é–“äºˆæ¸¬" if lang == 'jp' else "30-day forecast"}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            confidence = forecast_results['model_confidence']
            confidence_pct = confidence * 100
            
            st.markdown(f"""
            <div class="metric-container">
                <h4>{"ãƒ¢ãƒ‡ãƒ«ä¿¡é ¼åº¦" if lang == 'jp' else "Model Confidence"}</h4>
                <h2>{confidence_pct:.0f}%</h2>
                <p>{"äºˆæ¸¬ç²¾åº¦" if lang == 'jp' else "Prediction accuracy"}</p>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("#### ğŸš¨ Anomaly Detection" if lang == 'en' else "#### ğŸš¨ ç•°å¸¸æ¤œçŸ¥")
        
        if anomaly_results['is_anomaly']:
            anomaly_score = anomaly_results['anomaly_score']
            st.markdown(f"""
            <div class="risk-card risk-card-high">
                <h4>âš ï¸ {"ç•°å¸¸ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ" if lang == 'jp' else "Anomaly Detected"}</h4>
                <p><strong>{"ç•°å¸¸ã‚¹ã‚³ã‚¢" if lang == 'jp' else "Anomaly Score"}:</strong> {anomaly_score:.2f}</p>
                <p><strong>{"æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³" if lang == 'jp' else "Recommendation"}:</strong> {anomaly_results['recommendation']}</p>
            </div>
            """, unsafe_allow_html=True)
            
            if anomaly_results.get('top_contributors'):
                st.write("**Top Contributing Factors:**" if lang == 'en' else "**ä¸»è¦è¦å› :**")
                for factor, value in anomaly_results['top_contributors']:
                    st.write(f"â€¢ {factor}: {value:.3f}")
        else:
            st.markdown(f"""
            <div class="risk-card risk-card-low">
                <h4>âœ… {"æ­£å¸¸ãªå¸‚å ´çŠ¶æ³" if lang == 'jp' else "Normal Market Conditions"}</h4>
                <p>{anomaly_results['recommendation']}</p>
            </div>
            """, unsafe_allow_html=True)
        
        if forecast_results.get('daily_forecasts'):
            st.markdown("---")
            st.markdown("#### ğŸ“… 7-Day Risk Forecast" if lang == 'en' else "#### ğŸ“… 7æ—¥é–“ãƒªã‚¹ã‚¯äºˆæ¸¬")
            
            forecasts = forecast_results['daily_forecasts']
            dates = [f['date'] for f in forecasts]
            risks = [f['risk_score'] * 100 for f in forecasts]
            volatilities = [f['volatility'] * 100 for f in forecasts]
            
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=dates,
                y=risks,
                mode='lines+markers',
                name='Risk Level (%)' if lang == 'en' else 'ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ« (%)',
                line=dict(color=THEME_COLORS['primary'], width=3),
                marker=dict(size=8)
            ))
            
            fig.add_trace(go.Scatter(
                x=dates,
                y=volatilities,
                mode='lines+markers',
                name='Volatility (%)' if lang == 'en' else 'ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (%)',
                line=dict(color=THEME_COLORS['secondary'], width=2, dash='dash'),
                marker=dict(size=6)
            ))
            
            fig.update_layout(
                title="Risk & Volatility Forecast" if lang == 'en' else "ãƒªã‚¹ã‚¯ãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£äºˆæ¸¬",
                xaxis_title="Date" if lang == 'en' else "æ—¥ä»˜",
                yaxis_title="Percentage %" if lang == 'en' else "ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ %",
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color=THEME_COLORS['text_primary'],
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        if scenario_results:
            st.markdown("---")
            st.markdown("#### ğŸ² Scenario Impact Analysis" if lang == 'en' else "#### ğŸ² ã‚·ãƒŠãƒªã‚ªå½±éŸ¿åˆ†æ")
            
            if lang == 'jp':
                st.info("ğŸ’¡ å„ã‚·ãƒŠãƒªã‚ªãŒå¸‚å ´ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’1000å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§åˆ†æã—ã¾ã™ã€‚ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã¯é€šå¸¸0-1ã®ç¯„å›²ã§ã™ãŒã€æ¥µç«¯ãªã‚·ãƒŠãƒªã‚ªã§ã¯1ã‚’è¶…ãˆã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
            else:
                st.info("ğŸ’¡ Analysis of market impact under different scenarios using 1000 simulations. Risk scores typically range 0-1, but extreme scenarios may exceed 1.0.")
            
            scenario_names = {
                'normal': 'Normal Market' if lang == 'en' else 'é€šå¸¸å¸‚å ´',
                'earthquake': 'Major Earthquake' if lang == 'en' else 'å¤§åœ°éœ‡ç™ºç”Ÿ',
                'market_crash': 'Market Crash' if lang == 'en' else 'å¸‚å ´æš´è½',
                'combined_crisis': 'Combined Crisis' if lang == 'en' else 'è¤‡åˆå±æ©Ÿ'
            }
            
            cols = st.columns(2)
            scenario_items = list(scenario_results.items())
            
            for i, (scenario_type, results) in enumerate(scenario_items):
                col = cols[i % 2]
                
                with col:
                    scenario_name = scenario_names[scenario_type]
                    mean_risk = results['mean_risk']
                    worst_case = results['worst_case']
                    prob_high_risk = results['probability_high_risk']
                    
                    if mean_risk > 0.7:
                        card_class = "risk-card-high"
                        icon = "ğŸ”´"
                    elif mean_risk > 0.4:
                        card_class = "risk-card-medium"
                        icon = "ğŸŸ¡"
                    else:
                        card_class = "risk-card-low"
                        icon = "ğŸŸ¢"
                    
                    avg_risk_pct = min(100, mean_risk * 100)  
                    worst_risk_pct = min(150, worst_case * 100)  
                    
                    if lang == 'jp':
                        st.markdown(f"""
                        <div class="risk-card {card_class}">
                            <h4>{icon} {scenario_name}</h4>
                            <p><strong>å¹³å‡ãƒªã‚¹ã‚¯:</strong> {avg_risk_pct:.1f}%</p>
                            <p><strong>æœ€æ‚ªã‚±ãƒ¼ã‚¹:</strong> {worst_risk_pct:.1f}%</p>
                            <p><strong>é«˜ãƒªã‚¹ã‚¯ç¢ºç‡:</strong> {prob_high_risk*100:.0f}%</p>
                            <p><strong>ãƒªã‚¹ã‚¯è©•ä¾¡:</strong> {"æ¥µé«˜" if mean_risk > 0.8 else "é«˜" if mean_risk > 0.6 else "ä¸­" if mean_risk > 0.3 else "ä½"}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        risk_level = "EXTREME" if mean_risk > 0.8 else "HIGH" if mean_risk > 0.6 else "MEDIUM" if mean_risk > 0.3 else "LOW"
                        st.markdown(f"""
                        <div class="risk-card {card_class}">
                            <h4>{icon} {scenario_name}</h4>
                            <p><strong>Average Risk:</strong> {avg_risk_pct:.1f}%</p>
                            <p><strong>Worst Case:</strong> {worst_risk_pct:.1f}%</p>
                            <p><strong>High Risk Probability:</strong> {prob_high_risk*100:.0f}%</p>
                            <p><strong>Risk Level:</strong> {risk_level}</p>
                        </div>
                        """, unsafe_allow_html=True)
            
            st.markdown("#### ğŸ“Š Risk Distribution Comparison" if lang == 'en' else "#### ğŸ“Š ãƒªã‚¹ã‚¯åˆ†å¸ƒæ¯”è¼ƒ")
            
            fig = go.Figure()
            
            scenarios = []
            low_risks = []    # 25th percentile
            avg_risks = []    # Mean
            high_risks = []   # 75th percentile
            extreme_risks = [] # 95th percentile
            
            for scenario_type, results in scenario_results.items():
                scenarios.append(scenario_names[scenario_type])
                
                mean_risk = results['mean_risk']
                std_risk = results['std_risk']
                
                low_risk = max(0, mean_risk - std_risk)
                high_risk = mean_risk + std_risk
                extreme_risk = results['var_95']
                
                low_risks.append(low_risk * 100)
                avg_risks.append(mean_risk * 100)
                high_risks.append(high_risk * 100)
                extreme_risks.append(min(150, extreme_risk * 100))  
            
            fig.add_trace(go.Bar(
                name='Low Risk Range' if lang == 'en' else 'ä½ãƒªã‚¹ã‚¯ç¯„å›²',
                x=scenarios,
                y=low_risks,
                marker_color=THEME_COLORS['success'],
                opacity=0.7
            ))
            
            fig.add_trace(go.Bar(
                name='Average Risk' if lang == 'en' else 'å¹³å‡ãƒªã‚¹ã‚¯',
                x=scenarios,
                y=[avg - low for avg, low in zip(avg_risks, low_risks)],
                base=low_risks,
                marker_color=THEME_COLORS['info'],
                opacity=0.8
            ))
            
            fig.add_trace(go.Bar(
                name='High Risk Range' if lang == 'en' else 'é«˜ãƒªã‚¹ã‚¯ç¯„å›²',
                x=scenarios,
                y=[high - avg for high, avg in zip(high_risks, avg_risks)],
                base=avg_risks,
                marker_color=THEME_COLORS['secondary'],
                opacity=0.8
            ))
            
            fig.add_trace(go.Bar(
                name='Extreme Risk (95%)' if lang == 'en' else 'æ¥µç«¯ãƒªã‚¹ã‚¯ (95%)',
                x=scenarios,
                y=[ext - high for ext, high in zip(extreme_risks, high_risks)],
                base=high_risks,
                marker_color=THEME_COLORS['warning'],
                opacity=0.9
            ))
            
            fig.update_layout(
                title="Risk Level Ranges by Scenario" if lang == 'en' else "ã‚·ãƒŠãƒªã‚ªåˆ¥ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ç¯„å›²",
                xaxis_title="Scenario" if lang == 'en' else "ã‚·ãƒŠãƒªã‚ª",
                yaxis_title="Risk Level %" if lang == 'en' else "ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ« %",
                barmode='stack',
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color=THEME_COLORS['text_primary'],
                height=400,
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("#### ğŸ¯ Key Insights" if lang == 'en' else "#### ğŸ¯ é‡è¦ãªæ´å¯Ÿ")
            
            risks_sorted = sorted(scenario_results.items(), key=lambda x: x[1]['mean_risk'])
            safest_scenario = scenario_names[risks_sorted[0][0]]
            riskiest_scenario = scenario_names[risks_sorted[-1][0]]
            
            col1, col2 = st.columns(2)
            
            with col1:
                if lang == 'jp':
                    st.markdown(f"""
                    **ğŸ“ˆ ãƒªã‚¹ã‚¯åˆ†æçµæœ:**
                    - **æœ€ã‚‚å®‰å…¨:** {safest_scenario} ({risks_sorted[0][1]['mean_risk']*100:.1f}%)
                    - **æœ€ã‚‚å±é™º:** {riskiest_scenario} ({risks_sorted[-1][1]['mean_risk']*100:.1f}%)
                    - **ãƒªã‚¹ã‚¯å€ç‡:** {risks_sorted[-1][1]['mean_risk']/risks_sorted[0][1]['mean_risk']:.1f}å€
                    """)
                else:
                    st.markdown(f"""
                    **ğŸ“ˆ Risk Analysis Results:**
                    - **Safest Scenario:** {safest_scenario} ({risks_sorted[0][1]['mean_risk']*100:.1f}%)
                    - **Riskiest Scenario:** {riskiest_scenario} ({risks_sorted[-1][1]['mean_risk']*100:.1f}%)
                    - **Risk Multiplier:** {risks_sorted[-1][1]['mean_risk']/risks_sorted[0][1]['mean_risk']:.1f}x
                    """)
            
            with col2:
                avg_high_risk_prob = np.mean([r['probability_high_risk'] for r in scenario_results.values()])
                
                if lang == 'jp':
                    st.markdown(f"""
                    **âš ï¸ ãƒªã‚¹ã‚¯è­¦å‘Š:**
                    - **é«˜ãƒªã‚¹ã‚¯å¹³å‡ç¢ºç‡:** {avg_high_risk_prob*100:.0f}%
                    - **è¤‡åˆå±æ©Ÿã§ã®é«˜ãƒªã‚¹ã‚¯ç¢ºç‡:** {scenario_results['combined_crisis']['probability_high_risk']*100:.0f}%
                    - **æ¨å¥¨:** {"ãƒªã‚¹ã‚¯è»½æ¸›ç­–ã‚’å®Ÿæ–½" if avg_high_risk_prob > 0.3 else "ç¾çŠ¶ç›£è¦–ã‚’ç¶™ç¶š"}
                    """)
                else:
                    recommendation = "Implement risk mitigation" if avg_high_risk_prob > 0.3 else "Continue monitoring"
                    st.markdown(f"""
                    **âš ï¸ Risk Warning:**
                    - **Average High Risk Probability:** {avg_high_risk_prob*100:.0f}%
                    - **Combined Crisis High Risk:** {scenario_results['combined_crisis']['probability_high_risk']*100:.0f}%
                    - **Recommendation:** {recommendation}
                    """)
        
        st.markdown("---")
        st.markdown("#### ğŸ’¡ Insights & Recommendations" if lang == 'en' else "#### ğŸ’¡ æ´å¯Ÿã¨æ¨å¥¨äº‹é …")
        
        insights_col1, insights_col2 = st.columns(2)
        
        with insights_col1:
            if lang == 'jp':
                st.markdown("""
                **ğŸ“ˆ äºˆæ¸¬åˆ†æã®æ´å¯Ÿ:**
                - åœ°éœ‡æ´»å‹•ã¨å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«ã¯ç›¸é–¢é–¢ä¿‚ãŒã‚ã‚Šã¾ã™
                - é€±æœ«å‰ã®é‡‘æ›œæ—¥ã«ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™
                - è¤‡åˆå±æ©Ÿã‚·ãƒŠãƒªã‚ªã§ã¯æå¤±ãŒéç·šå½¢ã«å¢—åŠ ã—ã¾ã™
                - æ—©æœŸè­¦å‘Šã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šäº‹å‰å¯¾ç­–ãŒå¯èƒ½ã§ã™
                """)
            else:
                st.markdown("""
                **ğŸ“ˆ Predictive Analytics Insights:**
                - Seismic activity correlates with market volatility spikes
                - Risk tends to increase on Fridays before weekends
                - Combined crisis scenarios show non-linear loss amplification
                - Early warning systems enable proactive risk management
                """)
        
        with insights_col2:
            current_risk = forecast_results['current_risk_prediction']
            
            if current_risk > 0.7:
                if lang == 'jp':
                    recommendations = [
                        "ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºã‚’50%å‰Šæ¸›",
                        "ãƒ˜ãƒƒã‚¸æˆ¦ç•¥ã‚’å¼·åŒ–",
                        "æµå‹•æ€§ã‚’ç¢ºä¿",
                        "ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹æ³¨æ–‡ã‚’è¨­å®š"
                    ]
                else:
                    recommendations = [
                        "Reduce position sizes by 50%",
                        "Strengthen hedging strategies",
                        "Ensure adequate liquidity",
                        "Set stop-loss orders"
                    ]
            elif current_risk > 0.4:
                if lang == 'jp':
                    recommendations = [
                        "ãƒªã‚¹ã‚¯ç›£è¦–ã‚’å¼·åŒ–",
                        "åˆ†æ•£æŠ•è³‡ã‚’æ¤œè¨",
                        "ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å¯¾ç­–ã‚’æº–å‚™",
                        "å®šæœŸçš„ãªãƒªãƒãƒ©ãƒ³ã‚¹"
                    ]
                else:
                    recommendations = [
                        "Enhanced risk monitoring",
                        "Consider diversification",
                        "Prepare volatility strategies",
                        "Regular portfolio rebalancing"
                    ]
            else:
                if lang == 'jp':
                    recommendations = [
                        "é€šå¸¸ã®æŠ•è³‡æˆ¦ç•¥ã‚’ç¶™ç¶š",
                        "æ©Ÿä¼šã‚’ç©æ¥µçš„ã«æ¢ç´¢",
                        "ãƒªã‚¹ã‚¯äºˆç®—ã‚’æ´»ç”¨",
                        "æ–°è¦ãƒã‚¸ã‚·ãƒ§ãƒ³æ¤œè¨"
                    ]
                else:
                    recommendations = [
                        "Continue normal investment strategy",
                        "Actively seek opportunities",
                        "Utilize risk budget",
                        "Consider new positions"
                    ]
            
            st.markdown("**ğŸ¯ Recommended Actions:**" if lang == 'en' else "**ğŸ¯ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**")
            for rec in recommendations:
                st.markdown(f"â€¢ {rec}")

    def run(self):
        self.render_header()
        self.render_sidebar()
        self.render_alerts()
        self.render_overview_metrics()
        self.render_main_tabs()
        
        if st.session_state.auto_refresh:
            time.sleep(1)
            if (datetime.now() - st.session_state.last_update).seconds > 300:  
                st.session_state.last_update = datetime.now()
                st.rerun()

if __name__ == "__main__":
    dashboard = TokyoMarketDashboard()
    dashboard.run() 